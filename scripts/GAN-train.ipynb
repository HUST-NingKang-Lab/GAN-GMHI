{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.core.frame import DataFrame\n",
    "from typing import List\n",
    "from collections import OrderedDict\n",
    "import random\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from annoy import AnnoyIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = 'batch'\n",
    "n_epochs = 150\n",
    "num_workers=0\n",
    "lr = 0.0005\n",
    "b1 = 0.5\n",
    "b2 = 0.999\n",
    "latent_dim = 256\n",
    "n_critic = 5\n",
    "lambda_co = 3\n",
    "lambda_rc = 1\n",
    "seed = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "setup_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.dataset = []\n",
    "        self.variable = None\n",
    "        self.labels = None\n",
    "        self.transform = None\n",
    "        self.sample = None\n",
    "        self.trees = []\n",
    "\n",
    "    def __len__(self):\n",
    "        return 10 * 1024\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        dataset_samples = []\n",
    "        for j, dataset in enumerate(self.dataset):\n",
    "            rindex1 = np.random.randint(len(dataset))\n",
    "            rindex2 = np.random.randint(len(dataset))\n",
    "            alpha = np.random.uniform(0, 1)\n",
    "            sample = alpha*dataset[rindex1] + (1-alpha)*dataset[rindex2]\n",
    "            dataset_samples.append(sample)\n",
    "        return dataset_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(data_size, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            Mish(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            Mish(),\n",
    "            nn.Linear(512, latent_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.encoder(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, latent_dim):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            Mish(),\n",
    "            nn.Linear(512, 1024),\n",
    "            Mish(),\n",
    "            nn.Linear(1024, data_size),\n",
    "        )\n",
    "        self.decoder2 = nn.Sequential(\n",
    "            nn.Linear(n_classes, 512),\n",
    "            Mish(),\n",
    "            nn.Linear(512, 1024),\n",
    "            Mish(),\n",
    "            nn.Linear(1024, data_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, ec, es):\n",
    "        return self.relu(self.decoder(torch.cat((ec, es), dim=-1))+self.decoder2(es))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mish(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.tanh(F.softplus(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find(\"Linear\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find(\"BatchNorm\") != -1:\n",
    "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias.data, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_data(data_A: np.float32, data_B: np.float32, labels: List[List[int]]=None):\n",
    "    data = np.r_[data_A, data_B]\n",
    "    if labels is None:\n",
    "        label = np.zeros(len(data_A)+len(data_B))\n",
    "        label[-len(data_B):] = 1\n",
    "        label = np.array([label]).T\n",
    "    else:\n",
    "        label = np.r_[labels[0], labels[1]]\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s__Abiotrophia_defectiva</th>\n",
       "      <th>s__Acetobacter_unclassified</th>\n",
       "      <th>s__Achromobacter_piechaudii</th>\n",
       "      <th>s__Achromobacter_unclassified</th>\n",
       "      <th>s__Achromobacter_xylosoxidans</th>\n",
       "      <th>s__Acidaminococcus_fermentans</th>\n",
       "      <th>s__Acidaminococcus_intestini</th>\n",
       "      <th>s__Acidaminococcus_sp_BV3L6</th>\n",
       "      <th>s__Acidaminococcus_sp_D21</th>\n",
       "      <th>s__Acidaminococcus_sp_HPA0509</th>\n",
       "      <th>...</th>\n",
       "      <th>s__Vibrio_furnissii</th>\n",
       "      <th>s__Vibrio_kanaloae</th>\n",
       "      <th>s__Weissella_cibaria</th>\n",
       "      <th>s__Weissella_confusa</th>\n",
       "      <th>s__Weissella_halotolerans</th>\n",
       "      <th>s__Weissella_koreensis</th>\n",
       "      <th>s__Weissella_paramesenteroides</th>\n",
       "      <th>s__Weissella_unclassified</th>\n",
       "      <th>s__Wohlfahrtiimonas_chitiniclastica</th>\n",
       "      <th>s__Yersinia_enterocolitica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ACVD_1</th>\n",
       "      <td>0.01142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.31613</td>\n",
       "      <td>0.11288</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACVD_2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.06002</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACVD_3</th>\n",
       "      <td>0.00088</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACVD_4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACVD_5</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Underweight_4343</th>\n",
       "      <td>0.00031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Underweight_4344</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Underweight_4345</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Underweight_4346</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Underweight_4347</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00077</td>\n",
       "      <td>0.00818</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4347 rows Ã— 903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  s__Abiotrophia_defectiva  s__Acetobacter_unclassified  \\\n",
       "ACVD_1                             0.01142                          0.0   \n",
       "ACVD_2                             0.00000                          0.0   \n",
       "ACVD_3                             0.00088                          0.0   \n",
       "ACVD_4                             0.00000                          0.0   \n",
       "ACVD_5                             0.00000                          0.0   \n",
       "...                                    ...                          ...   \n",
       "Underweight_4343                   0.00031                          0.0   \n",
       "Underweight_4344                   0.00000                          0.0   \n",
       "Underweight_4345                   0.00000                          0.0   \n",
       "Underweight_4346                   0.00000                          0.0   \n",
       "Underweight_4347                   0.00000                          0.0   \n",
       "\n",
       "                  s__Achromobacter_piechaudii  s__Achromobacter_unclassified  \\\n",
       "ACVD_1                                    0.0                            0.0   \n",
       "ACVD_2                                    0.0                            0.0   \n",
       "ACVD_3                                    0.0                            0.0   \n",
       "ACVD_4                                    0.0                            0.0   \n",
       "ACVD_5                                    0.0                            0.0   \n",
       "...                                       ...                            ...   \n",
       "Underweight_4343                          0.0                            0.0   \n",
       "Underweight_4344                          0.0                            0.0   \n",
       "Underweight_4345                          0.0                            0.0   \n",
       "Underweight_4346                          0.0                            0.0   \n",
       "Underweight_4347                          0.0                            0.0   \n",
       "\n",
       "                  s__Achromobacter_xylosoxidans  \\\n",
       "ACVD_1                                      0.0   \n",
       "ACVD_2                                      0.0   \n",
       "ACVD_3                                      0.0   \n",
       "ACVD_4                                      0.0   \n",
       "ACVD_5                                      0.0   \n",
       "...                                         ...   \n",
       "Underweight_4343                            0.0   \n",
       "Underweight_4344                            0.0   \n",
       "Underweight_4345                            0.0   \n",
       "Underweight_4346                            0.0   \n",
       "Underweight_4347                            0.0   \n",
       "\n",
       "                  s__Acidaminococcus_fermentans  s__Acidaminococcus_intestini  \\\n",
       "ACVD_1                                  0.00000                       0.00000   \n",
       "ACVD_2                                  0.06002                       0.00000   \n",
       "ACVD_3                                  0.00000                       0.00000   \n",
       "ACVD_4                                  0.00000                       0.00000   \n",
       "ACVD_5                                  0.00000                       0.00000   \n",
       "...                                         ...                           ...   \n",
       "Underweight_4343                        0.00000                       0.00000   \n",
       "Underweight_4344                        0.00000                       0.00000   \n",
       "Underweight_4345                        0.00000                       0.00000   \n",
       "Underweight_4346                        0.00000                       0.00000   \n",
       "Underweight_4347                        0.00077                       0.00818   \n",
       "\n",
       "                  s__Acidaminococcus_sp_BV3L6  s__Acidaminococcus_sp_D21  \\\n",
       "ACVD_1                                    0.0                        0.0   \n",
       "ACVD_2                                    0.0                        0.0   \n",
       "ACVD_3                                    0.0                        0.0   \n",
       "ACVD_4                                    0.0                        0.0   \n",
       "ACVD_5                                    0.0                        0.0   \n",
       "...                                       ...                        ...   \n",
       "Underweight_4343                          0.0                        0.0   \n",
       "Underweight_4344                          0.0                        0.0   \n",
       "Underweight_4345                          0.0                        0.0   \n",
       "Underweight_4346                          0.0                        0.0   \n",
       "Underweight_4347                          0.0                        0.0   \n",
       "\n",
       "                  s__Acidaminococcus_sp_HPA0509  ...  s__Vibrio_furnissii  \\\n",
       "ACVD_1                                      0.0  ...                  0.0   \n",
       "ACVD_2                                      0.0  ...                  0.0   \n",
       "ACVD_3                                      0.0  ...                  0.0   \n",
       "ACVD_4                                      0.0  ...                  0.0   \n",
       "ACVD_5                                      0.0  ...                  0.0   \n",
       "...                                         ...  ...                  ...   \n",
       "Underweight_4343                            0.0  ...                  0.0   \n",
       "Underweight_4344                            0.0  ...                  0.0   \n",
       "Underweight_4345                            0.0  ...                  0.0   \n",
       "Underweight_4346                            0.0  ...                  0.0   \n",
       "Underweight_4347                            0.0  ...                  0.0   \n",
       "\n",
       "                  s__Vibrio_kanaloae  s__Weissella_cibaria  \\\n",
       "ACVD_1                           0.0               0.31613   \n",
       "ACVD_2                           0.0               0.00000   \n",
       "ACVD_3                           0.0               0.00000   \n",
       "ACVD_4                           0.0               0.00000   \n",
       "ACVD_5                           0.0               0.00000   \n",
       "...                              ...                   ...   \n",
       "Underweight_4343                 0.0               0.00000   \n",
       "Underweight_4344                 0.0               0.00000   \n",
       "Underweight_4345                 0.0               0.00000   \n",
       "Underweight_4346                 0.0               0.00000   \n",
       "Underweight_4347                 0.0               0.00000   \n",
       "\n",
       "                  s__Weissella_confusa  s__Weissella_halotolerans  \\\n",
       "ACVD_1                         0.11288                        0.0   \n",
       "ACVD_2                         0.00000                        0.0   \n",
       "ACVD_3                         0.00000                        0.0   \n",
       "ACVD_4                         0.00058                        0.0   \n",
       "ACVD_5                         0.00000                        0.0   \n",
       "...                                ...                        ...   \n",
       "Underweight_4343               0.00000                        0.0   \n",
       "Underweight_4344               0.00000                        0.0   \n",
       "Underweight_4345               0.00000                        0.0   \n",
       "Underweight_4346               0.00000                        0.0   \n",
       "Underweight_4347               0.00000                        0.0   \n",
       "\n",
       "                  s__Weissella_koreensis  s__Weissella_paramesenteroides  \\\n",
       "ACVD_1                               0.0                             0.0   \n",
       "ACVD_2                               0.0                             0.0   \n",
       "ACVD_3                               0.0                             0.0   \n",
       "ACVD_4                               0.0                             0.0   \n",
       "ACVD_5                               0.0                             0.0   \n",
       "...                                  ...                             ...   \n",
       "Underweight_4343                     0.0                             0.0   \n",
       "Underweight_4344                     0.0                             0.0   \n",
       "Underweight_4345                     0.0                             0.0   \n",
       "Underweight_4346                     0.0                             0.0   \n",
       "Underweight_4347                     0.0                             0.0   \n",
       "\n",
       "                  s__Weissella_unclassified  \\\n",
       "ACVD_1                                  0.0   \n",
       "ACVD_2                                  0.0   \n",
       "ACVD_3                                  0.0   \n",
       "ACVD_4                                  0.0   \n",
       "ACVD_5                                  0.0   \n",
       "...                                     ...   \n",
       "Underweight_4343                        0.0   \n",
       "Underweight_4344                        0.0   \n",
       "Underweight_4345                        0.0   \n",
       "Underweight_4346                        0.0   \n",
       "Underweight_4347                        0.0   \n",
       "\n",
       "                  s__Wohlfahrtiimonas_chitiniclastica  \\\n",
       "ACVD_1                                            0.0   \n",
       "ACVD_2                                            0.0   \n",
       "ACVD_3                                            0.0   \n",
       "ACVD_4                                            0.0   \n",
       "ACVD_5                                            0.0   \n",
       "...                                               ...   \n",
       "Underweight_4343                                  0.0   \n",
       "Underweight_4344                                  0.0   \n",
       "Underweight_4345                                  0.0   \n",
       "Underweight_4346                                  0.0   \n",
       "Underweight_4347                                  0.0   \n",
       "\n",
       "                  s__Yersinia_enterocolitica  \n",
       "ACVD_1                                   0.0  \n",
       "ACVD_2                                   0.0  \n",
       "ACVD_3                                   0.0  \n",
       "ACVD_4                                   0.0  \n",
       "ACVD_5                                   0.0  \n",
       "...                                      ...  \n",
       "Underweight_4343                         0.0  \n",
       "Underweight_4344                         0.0  \n",
       "Underweight_4345                         0.0  \n",
       "Underweight_4346                         0.0  \n",
       "Underweight_4347                         0.0  \n",
       "\n",
       "[4347 rows x 903 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('./4347_final_relative_abundances.txt',sep='\\t',index_col=0).T\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biodb/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608,609,610,611,612,613,614,615,616,617,618,619,620,621,622,623,624,625,626,627,628,629,630,631,632,633,634,635,636,637,638,639,640,641,642,643,644,645,646,647,648,649,650,651,652,653,654,655,656,657,658,659,660,661,662,663,664,665,666,667,668,669,670,671,672,673,674,675,676,677,678,679,680,681,682,683,684,685,686,687,688,689,690,691,692,693,694,695,696,697,698,699,700,701,702,703,704,705,706,707,708,709,710,711,712,713,714,715,716,717,718,719,720,721,722,723,724,725,726,727,728,729,730,731,732,733,734,735,736,737,738,739,740,741,742,743,744,745,746,747,748,749,750,751,752,753,754,755,756,757,758,759,760,761,762,763,764,765,766,767,768,769,770,771,772,773,774,775,776,777,778,779,780,781,782,783,784,785,786,787,788,789,790,791,792,793,794,795,796,797,798,799,800,801,802,803,804,805,806,807,808,809,810,811,812,813,814,815,816,817,818,819,820,821,822,823,824,825,826,827,828,829,830,831,832,833,834,835,836,837,838,839,840,841,842,843,844,845,846,847,848,849,850,851,852,853,854,855,856,857,858,859,860,861,862,863,864,865,866,867,868,869,870,871,872,873,874,875,876,877,878,879,880,881,882,883,884,885,886,887,888,889,890,891,892,893,894,895,896,897,898,899,900,901,902,903,904,905,906,907,908,909,910,911,912,913,914,915,916,917,918,919,920,921,922,923,924,925,926,927,928,929,930,931,932,933,934,935,936,937,938,939,940,941,942,943,944,945,946,947,948,949,950,951,952,953,954,955,956,957,958,959,960,961,962,963,964,965,966,967,968,969,970,971,972,973,974,975,976,977,978,979,980,981,982,983,984,985,986,987,988,989,990,991,992,993,994,995,996,997,998,999,1000,1001,1002,1003,1004,1005,1006,1007,1008,1009,1010,1011,1012,1013,1014,1015,1016,1017,1018,1019,1020,1021,1022,1023,1024,1025,1026,1027,1028,1029,1030,1031,1032,1033,1034,1035,1036,1037,1038,1039,1040,1041,1042,1043,1044,1045,1046,1047,1048,1049,1050,1051,1052,1053,1054,1055,1056,1057,1058,1059,1060,1061,1062,1063,1064,1065,1066,1067,1068,1069,1070,1071,1072,1073,1074,1075,1076,1077,1078,1079,1080,1081,1082,1083,1084,1085,1086,1087,1088,1089,1090,1091,1092,1093,1094,1095,1096,1097,1098,1099,1100,1101,1102,1103,1104,1105,1106,1107,1108,1109,1110,1111,1112,1113,1114,1115,1116,1117,1118,1119,1120,1121,1122,1123,1124,1125,1126,1127,1128,1129,1130,1131,1132,1133,1134,1135,1136,1137,1138,1139,1140,1141,1142,1143,1144,1145,1146,1147,1148,1149,1150,1151,1152,1153,1154,1155,1156,1157,1158,1159,1160,1161,1162,1163,1164,1165,1166,1167,1168,1169,1170,1171,1172,1173,1174,1175,1176,1177,1178,1179,1180,1181,1182,1183,1184,1185,1186,1187,1188,1189,1190,1191,1192,1193,1194,1195,1196,1197,1198,1199,1200,1201,1202,1203,1204,1205,1206,1207,1208,1209,1210,1211,1212,1213,1214,1215,1216,1217,1218,1219,1220,1221,1222,1223,1224,1225,1226,1227,1228,1229,1230,1231,1232,1233,1234,1235,1236,1237,1238,1239,1240,1241,1242,1243,1244,1245,1246,1247,1248,1249,1250,1251,1252,1253,1254,1255,1256,1257,1258,1259,1260,1261,1262,1263,1264,1265,1266,1267,1268,1269,1270,1271,1272,1273,1274,1275,1276,1277,1278,1279,1280,1281,1282,1283,1284,1285,1286,1287,1288,1289,1290,1291,1292,1293,1294,1295,1296,1297,1298,1299,1300,1301,1302,1303,1304,1305,1306,1307,1308,1309,1310,1311,1312,1313,1314,1315,1316,1317,1318,1319,1320,1321,1322,1323,1324,1325,1326,1327,1328,1329,1330,1331,1332,1333,1334,1335,1336,1337,1338,1339,1340,1341,1342,1343,1344,1345,1346,1347,1348,1349,1350,1351,1352,1353,1354,1355,1356,1357,1358,1359,1360,1361,1362,1363,1364,1365,1366,1367,1368,1369,1370,1371,1372,1373,1374,1375,1376,1377,1378,1379,1380,1381,1382,1383,1384,1385,1386,1387,1388,1389,1390,1391,1392,1393,1394,1395,1396,1397,1398,1399,1400,1401,1402,1403,1404,1405,1406,1407,1408,1409,1410,1411,1412,1413,1414,1415,1416,1417,1418,1419,1420,1421,1422,1423,1424,1425,1426,1427,1428,1429,1430,1431,1432,1433,1434,1435,1436,1437,1438,1439,1440,1441,1442,1443,1444,1445,1446,1447,1448,1449,1450,1451,1452,1453,1454,1455,1456,1457,1458,1459,1460,1461,1462,1463,1464,1465,1466,1467,1468,1469,1470,1471,1472,1473,1474,1475,1476,1477,1478,1479,1480,1481,1482,1483,1484,1485,1486,1487,1488,1489,1490,1491,1492,1493,1494,1495,1496,1497,1498,1499,1500,1501,1502,1503,1504,1505,1506,1507,1508,1509,1510,1511,1512,1513,1514,1515,1516,1517,1518,1519,1520,1521,1522,1523,1524,1525,1526,1527,1528,1529,1530,1531,1532,1533,1534,1535,1536,1537,1538,1539,1540,1541,1542,1543,1544,1545,1546,1547,1548,1549,1550,1551,1552,1553,1554,1555,1556,1557,1558,1559,1560,1561,1562,1563,1564,1565,1566,1567,1568,1569,1570,1571,1572,1573,1574,1575,1576,1577,1578,1579,1580,1581,1582,1583,1584,1585,1586,1587,1588,1589,1590,1591,1592,1593,1594,1595,1596,1597,1598,1599,1600,1601,1602,1603,1604,1605,1606,1607,1608,1609,1610,1611,1612,1613,1614,1615,1616,1617,1618,1619,1620,1621,1622,1623,1624,1625,1626,1627,1628,1629,1630,1631,1632,1633,1634,1635,1636,1637,1638,1639,1640,1641,1642,1643,1644,1645,1646,1647,1648,1649,1650,1651,1652,1653,1654,1655,1656,1657,1658,1659,1660,1661,1662,1663,1664,1665,1666,1667,1668,1669,1670,1671,1672,1673,1674,1675,1676,1677,1678,1679,1680,1681,1682,1683,1684,1685,1686,1687,1688,1689,1690,1691,1692,1693,1694,1695,1696,1697,1698,1699,1700,1701,1702,1703,1704,1705,1706,1707,1708,1709,1710,1711,1712,1713,1714,1715,1716,1717,1718,1719,1720,1721,1722,1723,1724,1725,1726,1727,1728,1729,1730,1731,1732,1733,1734,1735,1736,1737,1738,1739,1740,1741,1742,1743,1744,1745,1746,1747,1748,1749,1750,1751,1752,1753,1754,1755,1756,1757,1758,1759,1760,1761,1762,1763,1764,1765,1766,1767,1768,1769,1770,1771,1772,1773,1774,1775,1776,1777,1778,1779,1780,1781,1782,1783,1784,1785,1786,1787,1788,1789,1790,1791,1792,1793,1794,1795,1796,1797,1798,1799,1800,1801,1802,1803,1804,1805,1806,1807,1808,1809,1810,1811,1812,1813,1814,1815,1816,1817,1818,1819,1820,1821,1822,1823,1824,1825,1826,1827,1828,1829,1830,1831,1832,1833,1834,1835,1836,1837,1838,1839,1840,1841,1842,1843,1844,1845,1846,1847,1848,1849,1850,1851,1852,1853,1854,1855,1856,1857,1858,1859,1860,1861,1862,1863,1864,1865,1866,1867,1868,1869,1870,1871,1872,1873,1874,1875,1876,1877,1878,1879,1880,1881,1882,1883,1884,1885,1886,1887,1888,1889,1890,1891,1892,1893,1894,1895,1896,1897,1898,1899,1900,1901,1902,1903,1904,1905,1906,1907,1908,1909,1910,1911,1912,1913,1914,1915,1916,1917,1918,1919,1920,1921,1922,1923,1924,1925,1926,1927,1928,1929,1930,1931,1932,1933,1934,1935,1936,1937,1938,1939,1940,1941,1942,1943,1944,1945,1946,1947,1948,1949,1950,1951,1952,1953,1954,1955,1956,1957,1958,1959,1960,1961,1962,1963,1964,1965,1966,1967,1968,1969,1970,1971,1972,1973,1974,1975,1976,1977,1978,1979,1980,1981,1982,1983,1984,1985,1986,1987,1988,1989,1990,1991,1992,1993,1994,1995,1996,1997,1998,1999,2000,2001,2002,2003,2004,2005,2006,2007,2008,2009,2010,2011,2012,2013,2014,2015,2016,2017,2018,2019,2020,2021,2022,2023,2024,2025,2026,2027,2028,2029,2030,2031,2032,2033,2034,2035,2036,2037,2038,2039,2040,2041,2042,2043,2044,2045,2046,2047,2048,2049,2050,2051,2052,2053,2054,2055,2056,2057,2058,2059,2060,2061,2062,2063,2064,2065,2066,2067,2068,2069,2070,2071,2072,2073,2074,2075,2076,2077,2078,2079,2080,2081,2082,2083,2084,2085,2086,2087,2088,2089,2090,2091,2092,2093,2094,2095,2096,2097,2098,2099,2100,2101,2102,2103,2104,2105,2106,2107,2108,2109,2110,2111,2112,2113,2114,2115,2116,2117,2118,2119,2120,2121,2122,2123,2124,2125,2126,2127,2128,2129,2130,2131,2132,2133,2134,2135,2136,2137,2138,2139,2140,2141,2142,2143,2144,2145,2146,2147,2148,2149,2150,2151,2152,2153,2154,2155,2156,2157,2158,2159,2160,2161,2162,2163,2164,2165,2166,2167,2168,2169,2170,2171,2172,2173,2174,2175,2176,2177,2178,2179,2180,2181,2182,2183,2184,2185,2186,2187,2188,2189,2190,2191,2192,2193,2194,2195,2196,2197,2198,2199,2200,2201,2202,2203,2204,2205,2206,2207,2208,2209,2210,2211,2212,2213,2214,2215,2216,2217,2218,2219,2220,2221,2222,2223,2224,2225,2226,2227,2228,2229,2230,2231,2232,2233,2234,2235,2236,2237,2238,2239,2240,2241,2242,2243,2244,2245,2246,2247,2248,2249,2250,2251,2252,2253,2254,2255,2256,2257,2258,2259,2260,2261,2262,2263,2264,2265,2266,2267,2268,2269,2270,2271,2272,2273,2274,2275,2276,2277,2278,2279,2280,2281,2282,2283,2284,2285,2286,2287,2288,2289,2290,2291,2292,2293,2294,2295,2296,2297,2298,2299,2300,2301,2302,2303,2304,2305,2306,2307,2308,2309,2310,2311,2312,2313,2314,2315,2316,2317,2318,2319,2320,2321,2322,2323,2324,2325,2326,2327,2328,2329,2330,2331,2332,2333,2334,2335,2336,2337,2338,2339,2340,2341,2342,2343,2344,2345,2346,2347,2348,2349,2350,2351,2352,2353,2354,2355,2356,2357,2358,2359,2360,2361,2362,2363,2364,2365,2366,2367,2368,2369,2370,2371,2372,2373,2374,2375,2376,2377,2378,2379,2380,2381,2382,2383,2384,2385,2386,2387,2388,2389,2390,2391,2392,2393,2394,2395,2396,2397,2398,2399,2400,2401,2402,2403,2404,2405,2406,2407,2408,2409,2410,2411,2412,2413,2414,2415,2416,2417,2418,2419,2420,2421,2422,2423,2424,2425,2426,2427,2428,2429,2430,2431,2432,2433,2434,2435,2436,2437,2438,2439,2440,2441,2442,2443,2444,2445,2446,2447,2448,2449,2450,2451,2452,2453,2454,2455,2456,2457,2458,2459,2460,2461,2462,2463,2464,2465,2466,2467,2468,2469,2470,2471,2472,2473,2474,2475,2476,2477,2478,2479,2480,2481,2482,2483,2484,2485,2486,2487,2488,2489,2490,2491,2492,2493,2494,2495,2496,2497,2498,2499,2500,2501,2502,2503,2504,2505,2506,2507,2508,2509,2510,2511,2512,2513,2514,2515,2516,2517,2518,2519,2520,2521,2522,2523,2524,2525,2526,2527,2528,2529,2530,2531,2532,2533,2534,2535,2536,2537,2538,2539,2540,2541,2542,2543,2544,2545,2546,2547,2548,2549,2550,2551,2552,2553,2554,2555,2556,2557,2558,2559,2560,2561,2562,2563,2564,2565,2566,2567,2568,2569,2570,2571,2572,2573,2574,2575,2576,2577,2578,2579,2580,2581,2582,2583,2584,2585,2586,2587,2588,2589,2590,2591,2592,2593,2594,2595,2596,2597,2598,2599,2600,2601,2602,2603,2604,2605,2606,2607,2608,2609,2610,2611,2612,2613,2614,2615,2616,2617,2618,2619,2620,2621,2622,2623,2624,2625,2626,2627,2628,2629,2630,2631,2632,2633,2634,2635,2636,2637,2638,2639,2640,2641,2642,2643,2644,2645,2646,2647,2648,2649,2650,2651,2652,2653,2654,2655,2656,2657,2658,2659,2660,2661,2662,2663,2664,2665,2666,2667,2668,2669,2670,2671,2672,2673,2674,2675,2676,2677,2678,2679,2680,2681,2682,2683,2684,2685,2686,2687,2688,2689,2690,2691,2692,2693,2694,2695,2696,2697,2698,2699,2700,2701,2702,2703,2704,2705,2706,2707,2708,2709,2710,2711,2712,2713,2714,2715,2716,2717,2718,2719,2720,2721,2722,2723,2724,2725,2726,2727,2728,2729,2730,2731,2732,2733,2734,2735,2736,2737,2738,2739,2740,2741,2742,2743,2744,2745,2746,2747,2748,2749,2750,2751,2752,2753,2754,2755,2756,2757,2758,2759,2760,2761,2762,2763,2764,2765,2766,2767,2768,2769,2770,2771,2772,2773,2774,2775,2776,2777,2778,2779,2780,2781,2782,2783,2784,2785,2786,2787,2788,2789,2790,2791,2792,2793,2794,2795,2796,2797,2798,2799,2800,2801,2802,2803,2804,2805,2806,2807,2808,2809,2810,2811,2812,2813,2814,2815,2816,2817,2818,2819,2820,2821,2822,2823,2824,2825,2826,2827,2828,2829,2830,2831,2832,2833,2834,2835,2836,2837,2838,2839,2840,2841,2842,2843,2844,2845,2846,2847,2848,2849,2850,2851,2852,2853,2854,2855,2856,2857,2858,2859,2860,2861,2862,2863,2864,2865,2866,2867,2868,2869,2870,2871,2872,2873,2874,2875,2876,2877,2878,2879,2880,2881,2882,2883,2884,2885,2886,2887,2888,2889,2890,2891,2892,2893,2894,2895,2896,2897,2898,2899,2900,2901,2902,2903,2904,2905,2906,2907,2908,2909,2910,2911,2912,2913,2914,2915,2916,2917,2918,2919,2920,2921,2922,2923,2924,2925,2926,2927,2928,2929,2930,2931,2932,2933,2934,2935,2936,2937,2938,2939,2940,2941,2942,2943,2944,2945,2946,2947,2948,2949,2950,2951,2952,2953,2954,2955,2956,2957,2958,2959,2960,2961,2962,2963,2964,2965,2966,2967,2968,2969,2970,2971,2972,2973,2974,2975,2976,2977,2978,2979,2980,2981,2982,2983,2984,2985,2986,2987,2988,2989,2990,2991,2992,2993,2994,2995,2996,2997,2998,2999,3000,3001,3002,3003,3004,3005,3006,3007,3008,3009,3010,3011,3012,3013,3014,3015,3016,3017,3018,3019,3020,3021,3022,3023,3024,3025,3026,3027,3028,3029,3030,3031,3032,3033,3034,3035,3036,3037,3038,3039,3040,3041,3042,3043,3044,3045,3046,3047,3048,3049,3050,3051,3052,3053,3054,3055,3056,3057,3058,3059,3060,3061,3062,3063,3064,3065,3066,3067,3068,3069,3070,3071,3072,3073,3074,3075,3076,3077,3078,3079,3080,3081,3082,3083,3084,3085,3086,3087,3088,3089,3090,3091,3092,3093,3094,3095,3096,3097,3098,3099,3100,3101,3102,3103,3104,3105,3106,3107,3108,3109,3110,3111,3112,3113,3114,3115,3116,3117,3118,3119,3120,3121,3122,3123,3124,3125,3126,3127,3128,3129,3130,3131,3132,3133,3134,3135,3136,3137,3138,3139,3140,3141,3142,3143,3144,3145,3146,3147,3148,3149,3150,3151,3152,3153,3154,3155,3156,3157,3158,3159,3160,3161,3162,3163,3164,3165,3166,3167,3168,3169,3170,3171,3172,3173,3174,3175,3176,3177,3178,3179,3180,3181,3182,3183,3184,3185,3186,3187,3188,3189,3190,3191,3192,3193,3194,3195,3196,3197,3198,3199,3200,3201,3202,3203,3204,3205,3206,3207,3208,3209,3210,3211,3212,3213,3214,3215,3216,3217,3218,3219,3220,3221,3222,3223,3224,3225,3226,3227,3228,3229,3230,3231,3232,3233,3234,3235,3236,3237,3238,3239,3240,3241,3242,3243,3244,3245,3246,3247,3248,3249,3250,3251,3252,3253,3254,3255,3256,3257,3258,3259,3260,3261,3262,3263,3264,3265,3266,3267,3268,3269,3270,3271,3272,3273,3274,3275,3276,3277,3278,3279,3280,3281,3282,3283,3284,3285,3286,3287,3288,3289,3290,3291,3292,3293,3294,3295,3296,3297,3298,3299,3300,3301,3302,3303,3304,3305,3306,3307,3308,3309,3310,3311,3312,3313,3314,3315,3316,3317,3318,3319,3320,3321,3322,3323,3324,3325,3326,3327,3328,3329,3330,3331,3332,3333,3334,3335,3336,3337,3338,3339,3340,3341,3342,3343,3344,3345,3346,3347,3348,3349,3350,3351,3352,3353,3354,3355,3356,3357,3358,3359,3360,3361,3362,3363,3364,3365,3366,3367,3368,3369,3370,3371,3372,3373,3374,3375,3376,3377,3378,3379,3380,3381,3382,3383,3384,3385,3386,3387,3388,3389,3390,3391,3392,3393,3394,3395,3396,3397,3398,3399,3400,3401,3402,3403,3404,3405,3406,3407,3408,3409,3410,3411,3412,3413,3414,3415,3416,3417,3418,3419,3420,3421,3422,3423,3424,3425,3426,3427,3428,3429,3430,3431,3432,3433,3434,3435,3436,3437,3438,3439,3440,3441,3442,3443,3444,3445,3446,3447,3448,3449,3450,3451,3452,3453,3454,3455,3456,3457,3458,3459,3460,3461,3462,3463,3464,3465,3466,3467,3468,3469,3470,3471,3472,3473,3474,3475,3476,3477,3478,3479,3480,3481,3482,3483,3484,3485,3486,3487,3488,3489,3490,3491,3492,3493,3494,3495,3496,3497,3498,3499,3500,3501,3502,3503,3504,3505,3506,3507,3508,3509,3510,3511,3512,3513,3514,3515,3516,3517,3518,3519,3520,3521,3522,3523,3524,3525,3526,3527,3528,3529,3530,3531,3532,3533,3534,3535,3536,3537,3538,3539,3540,3541,3542,3543,3544,3545,3546,3547,3548,3549,3550,3551,3552,3553,3554,3555,3556,3557,3558,3559,3560,3561,3562,3563,3564,3565,3566,3567,3568,3569,3570,3571,3572,3573,3574,3575,3576,3577,3578,3579,3580,3581,3582,3583,3584,3585,3586,3587,3588,3589,3590,3591,3592,3593,3594,3595,3596,3597,3598,3599,3600,3601,3602,3603,3604,3605,3606,3607,3608,3609,3610,3611,3612,3613,3614,3615,3616,3617,3618,3619,3620,3621,3622,3623,3624,3625,3626,3627,3628,3629,3630,3631,3632,3633,3634,3635,3636,3637,3638,3639,3640,3641,3642,3643,3644,3645,3646,3647,3648,3649,3650,3651,3652,3653,3654,3655,3656,3657,3658,3659,3660,3661,3662,3663,3664,3665,3666,3667,3668,3669,3670,3671,3672,3673,3674,3675,3676,3677,3678,3679,3680,3681,3682,3683,3684,3685,3686,3687,3688,3689,3690,3691,3692,3693,3694,3695,3696,3697,3698,3699,3700,3701,3702,3703,3704,3705,3706,3707,3708,3709,3710,3711,3712,3713,3714,3715,3716,3717,3718,3719,3720,3721,3722,3723,3724,3725,3726,3727,3728,3729,3730,3731,3732,3733,3734,3735,3736,3737,3738,3739,3740,3741,3742,3743,3744,3745,3746,3747,3748,3749,3750,3751,3752,3753,3754,3755,3756,3757,3758,3759,3760,3761,3762,3763,3764,3765,3766,3767,3768,3769,3770,3771,3772,3773,3774,3775,3776,3777,3778,3779,3780,3781,3782,3783,3784,3785,3786,3787,3788,3789,3790,3791,3792,3793,3794,3795,3796,3797,3798,3799,3800,3801,3802,3803,3804,3805,3806,3807,3808,3809,3810,3811,3812,3813,3814,3815,3816,3817,3818,3819,3820,3821,3822,3823,3824,3825,3826,3827,3828,3829,3830,3831,3832,3833,3834,3835,3836,3837,3838,3839,3840,3841,3842,3843,3844,3845,3846,3847,3848,3849,3850,3851,3852,3853,3854,3855,3856,3857,3858,3859,3860,3861,3862,3863,3864,3865,3866,3867,3868,3869,3870,3871,3872,3873,3874,3875,3876,3877,3878,3879,3880,3881,3882,3883,3884,3885,3886,3887,3888,3889,3890,3891,3892,3893,3894,3895,3896,3897,3898,3899,3900,3901,3902,3903,3904,3905,3906,3907,3908,3909,3910,3911,3912,3913,3914,3915,3916,3917,3918,3919,3920,3921,3922,3923,3924,3925,3926,3927,3928,3929,3930,3931,3932,3933,3934,3935,3936,3937,3938,3939,3940,3941,3942,3943,3944,3945,3946,3947,3948,3949,3950,3951,3952,3953,3954,3955,3956,3957,3958,3959,3960,3961,3962,3963,3964,3965,3966,3967,3968,3969,3970,3971,3972,3973,3974,3975,3976,3977,3978,3979,3980,3981,3982,3983,3984,3985,3986,3987,3988,3989,3990,3991,3992,3993,3994,3995,3996,3997,3998,3999,4000,4001,4002,4003,4004,4005,4006,4007,4008,4009,4010,4011,4012,4013,4014,4015,4016,4017,4018,4019,4020,4021,4022,4023,4024,4025,4026,4027,4028,4029,4030,4031,4032,4033,4034,4035,4036,4037,4038,4039,4040,4041,4042,4043,4044,4045,4046,4047,4048,4049,4050,4051,4052,4053,4054,4055,4056,4057,4058,4059,4060,4061,4062,4063,4064,4065,4066,4067,4068,4069,4070,4071,4072,4073,4074,4075,4076,4077,4078,4079,4080,4081,4082,4083,4084,4085,4086,4087,4088,4089,4090,4091,4092,4093,4094,4095,4096,4097,4098,4099,4100,4101,4102,4103,4104,4105,4106,4107,4108,4109,4110,4111,4112,4113,4114,4115,4116,4117,4118,4119,4120,4121,4122,4123,4124,4125,4126,4127,4128,4129,4130,4131,4132,4133,4134,4135,4136,4137,4138,4139,4140,4141,4142,4143,4144,4145,4146,4147,4148,4149,4150,4151,4152,4153,4154,4155,4156,4157,4158,4159,4160,4161,4162,4163,4164,4165,4166,4167,4168,4169,4170,4171,4172,4173,4174,4175,4176,4177,4178,4179,4180,4181,4182,4183,4184,4185,4186,4187,4188,4189,4190,4191,4192,4193,4194,4195,4196,4197,4198,4199,4200,4201,4202,4203,4204,4205,4206,4207,4208,4209,4210,4211,4212,4213,4214,4215,4216,4217,4218,4219,4220,4221,4222,4223,4224,4225,4226,4227,4228,4229,4230,4231,4232,4233,4234,4235,4236,4237,4238,4239,4240,4241,4242,4243,4244,4245,4246,4247,4248,4249,4250,4251,4252,4253,4254,4255,4256,4257,4258,4259,4260,4261,4262,4263,4264,4265,4266,4267,4268,4269,4270,4271,4272,4273,4274,4275,4276,4277,4278,4279,4280,4281,4282,4283,4284,4285,4286,4287,4288,4289,4290,4291,4292,4293,4294,4295,4296,4297,4298,4299,4300,4301,4302,4303,4304,4305,4306,4307,4308,4309,4310,4311,4312,4313,4314,4315,4316,4317,4318,4319,4320,4321,4322,4323,4324,4325,4326,4327,4328,4329,4330,4331,4332,4333,4334,4335,4336,4337,4338,4339,4340,4341,4342,4343,4344,4345,4346,4347) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "metadata = pd.read_csv('./Final_metadata_4347.csv',index_col=0).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>study</th>\n",
       "      <th>study</th>\n",
       "      <th>Study No. (From VG sheet (V-*) from SB sheet (S-*))</th>\n",
       "      <th>Title of Paper</th>\n",
       "      <th>Author (year)</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Study Accession</th>\n",
       "      <th>Sample Accession or Sample ID</th>\n",
       "      <th>Sample title (ENA/SRA)</th>\n",
       "      <th>Sample title (Paper)</th>\n",
       "      <th>Subject Id (If available)</th>\n",
       "      <th>...</th>\n",
       "      <th>s__Subdoligranulum_variabile</th>\n",
       "      <th>s__Succinatimonas_hippei</th>\n",
       "      <th>s__Sutterella_wadsworthensis</th>\n",
       "      <th>s__Turicibacter_sanguinis</th>\n",
       "      <th>s__Varibaculum_cambriense</th>\n",
       "      <th>s__Veillonella_atypica</th>\n",
       "      <th>s__Veillonella_dispar</th>\n",
       "      <th>s__Veillonella_parvula</th>\n",
       "      <th>s__Weissella_cibaria</th>\n",
       "      <th>s__Weissella_confusa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>V-2_ACVD</th>\n",
       "      <td>V-2_ACVD</td>\n",
       "      <td>V-2</td>\n",
       "      <td>The gut microbiome in atherosclerotic cardiova...</td>\n",
       "      <td>Jie (2017)</td>\n",
       "      <td>Nature communications</td>\n",
       "      <td>PRJEB21528</td>\n",
       "      <td>SAMEA104142287</td>\n",
       "      <td>ZSL-004</td>\n",
       "      <td>ZSL-004</td>\n",
       "      <td>ZSL-004</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000501901</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0313742</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00342788</td>\n",
       "      <td>0.00199693</td>\n",
       "      <td>0.134307</td>\n",
       "      <td>0.337587</td>\n",
       "      <td>0.120542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V-2_ACVD.1</th>\n",
       "      <td>V-2_ACVD</td>\n",
       "      <td>V-2</td>\n",
       "      <td>The gut microbiome in atherosclerotic cardiova...</td>\n",
       "      <td>Jie (2017)</td>\n",
       "      <td>Nature communications</td>\n",
       "      <td>PRJEB21528</td>\n",
       "      <td>SAMEA104142288</td>\n",
       "      <td>ZSL-007</td>\n",
       "      <td>ZSL-007</td>\n",
       "      <td>ZSL-007</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00354857</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.50212</td>\n",
       "      <td>0.122268</td>\n",
       "      <td>1.75344</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V-2_ACVD.2</th>\n",
       "      <td>V-2_ACVD</td>\n",
       "      <td>V-2</td>\n",
       "      <td>The gut microbiome in atherosclerotic cardiova...</td>\n",
       "      <td>Jie (2017)</td>\n",
       "      <td>Nature communications</td>\n",
       "      <td>PRJEB21528</td>\n",
       "      <td>SAMEA104142293</td>\n",
       "      <td>ZSL-010</td>\n",
       "      <td>ZSL-010</td>\n",
       "      <td>ZSL-010</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00401139</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V-2_ACVD.3</th>\n",
       "      <td>V-2_ACVD</td>\n",
       "      <td>V-2</td>\n",
       "      <td>The gut microbiome in atherosclerotic cardiova...</td>\n",
       "      <td>Jie (2017)</td>\n",
       "      <td>Nature communications</td>\n",
       "      <td>PRJEB21528</td>\n",
       "      <td>SAMEA104142291</td>\n",
       "      <td>ZSL-011</td>\n",
       "      <td>ZSL-011</td>\n",
       "      <td>ZSL-011</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00139602</td>\n",
       "      <td>0.00176556</td>\n",
       "      <td>0.145084</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000595363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V-2_ACVD.4</th>\n",
       "      <td>V-2_ACVD</td>\n",
       "      <td>V-2</td>\n",
       "      <td>The gut microbiome in atherosclerotic cardiova...</td>\n",
       "      <td>Jie (2017)</td>\n",
       "      <td>Nature communications</td>\n",
       "      <td>PRJEB21528</td>\n",
       "      <td>SAMEA104142284</td>\n",
       "      <td>ZSL-019</td>\n",
       "      <td>ZSL-019</td>\n",
       "      <td>ZSL-019</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00126287</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0129392</td>\n",
       "      <td>0.000238082</td>\n",
       "      <td>0.0163449</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S-7_Underweight</th>\n",
       "      <td>S-7_Underweight</td>\n",
       "      <td>S-7</td>\n",
       "      <td>Two distinct metacommunities characterize the ...</td>\n",
       "      <td>He (2017)</td>\n",
       "      <td>Gigascience</td>\n",
       "      <td>PRJEB15371</td>\n",
       "      <td>SAMEA4431948</td>\n",
       "      <td>SZAXPI029564-74</td>\n",
       "      <td>SZAXPI029564-74</td>\n",
       "      <td>GZCT014</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.16279</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0322849</td>\n",
       "      <td>0.0587168</td>\n",
       "      <td>0.10368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S-7_Underweight.1</th>\n",
       "      <td>S-7_Underweight</td>\n",
       "      <td>S-7</td>\n",
       "      <td>Two distinct metacommunities characterize the ...</td>\n",
       "      <td>He (2017)</td>\n",
       "      <td>Gigascience</td>\n",
       "      <td>PRJEB15371</td>\n",
       "      <td>SAMEA4431949</td>\n",
       "      <td>SZAXPI029565-77</td>\n",
       "      <td>SZAXPI029565-77</td>\n",
       "      <td>GZCT015</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00125461</td>\n",
       "      <td>0.312764</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S-7_Underweight.2</th>\n",
       "      <td>S-7_Underweight</td>\n",
       "      <td>S-7</td>\n",
       "      <td>Two distinct metacommunities characterize the ...</td>\n",
       "      <td>He (2017)</td>\n",
       "      <td>Gigascience</td>\n",
       "      <td>PRJEB15371</td>\n",
       "      <td>SAMEA4431951</td>\n",
       "      <td>SZAXPI029567-80</td>\n",
       "      <td>SZAXPI029567-80</td>\n",
       "      <td>GZCT017</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00115932</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0865797</td>\n",
       "      <td>0.0366468</td>\n",
       "      <td>0.0827324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S-7_Underweight.3</th>\n",
       "      <td>S-7_Underweight</td>\n",
       "      <td>S-7</td>\n",
       "      <td>Two distinct metacommunities characterize the ...</td>\n",
       "      <td>He (2017)</td>\n",
       "      <td>Gigascience</td>\n",
       "      <td>PRJEB15371</td>\n",
       "      <td>SAMEA4431964</td>\n",
       "      <td>SZAXPI029580-98</td>\n",
       "      <td>SZAXPI029580-98</td>\n",
       "      <td>GZCT030</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00855007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S-7_Underweight.4</th>\n",
       "      <td>S-7_Underweight</td>\n",
       "      <td>S-7</td>\n",
       "      <td>Two distinct metacommunities characterize the ...</td>\n",
       "      <td>He (2017)</td>\n",
       "      <td>Gigascience</td>\n",
       "      <td>PRJEB15371</td>\n",
       "      <td>SAMEA4431982</td>\n",
       "      <td>SZAXPI029597-158</td>\n",
       "      <td>SZAXPI029597-158</td>\n",
       "      <td>GZCT049</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0167338</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4347 rows Ã— 345 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "study                        study  \\\n",
       "V-2_ACVD                  V-2_ACVD   \n",
       "V-2_ACVD.1                V-2_ACVD   \n",
       "V-2_ACVD.2                V-2_ACVD   \n",
       "V-2_ACVD.3                V-2_ACVD   \n",
       "V-2_ACVD.4                V-2_ACVD   \n",
       "...                            ...   \n",
       "S-7_Underweight    S-7_Underweight   \n",
       "S-7_Underweight.1  S-7_Underweight   \n",
       "S-7_Underweight.2  S-7_Underweight   \n",
       "S-7_Underweight.3  S-7_Underweight   \n",
       "S-7_Underweight.4  S-7_Underweight   \n",
       "\n",
       "study             Study No. (From VG sheet (V-*) from SB sheet (S-*))  \\\n",
       "V-2_ACVD                                                         V-2    \n",
       "V-2_ACVD.1                                                       V-2    \n",
       "V-2_ACVD.2                                                       V-2    \n",
       "V-2_ACVD.3                                                       V-2    \n",
       "V-2_ACVD.4                                                       V-2    \n",
       "...                                                              ...    \n",
       "S-7_Underweight                                                  S-7    \n",
       "S-7_Underweight.1                                                S-7    \n",
       "S-7_Underweight.2                                                S-7    \n",
       "S-7_Underweight.3                                                S-7    \n",
       "S-7_Underweight.4                                                S-7    \n",
       "\n",
       "study                                                 Title of Paper  \\\n",
       "V-2_ACVD           The gut microbiome in atherosclerotic cardiova...   \n",
       "V-2_ACVD.1         The gut microbiome in atherosclerotic cardiova...   \n",
       "V-2_ACVD.2         The gut microbiome in atherosclerotic cardiova...   \n",
       "V-2_ACVD.3         The gut microbiome in atherosclerotic cardiova...   \n",
       "V-2_ACVD.4         The gut microbiome in atherosclerotic cardiova...   \n",
       "...                                                              ...   \n",
       "S-7_Underweight    Two distinct metacommunities characterize the ...   \n",
       "S-7_Underweight.1  Two distinct metacommunities characterize the ...   \n",
       "S-7_Underweight.2  Two distinct metacommunities characterize the ...   \n",
       "S-7_Underweight.3  Two distinct metacommunities characterize the ...   \n",
       "S-7_Underweight.4  Two distinct metacommunities characterize the ...   \n",
       "\n",
       "study             Author (year)                Journal Study Accession  \\\n",
       "V-2_ACVD             Jie (2017)  Nature communications      PRJEB21528   \n",
       "V-2_ACVD.1           Jie (2017)  Nature communications      PRJEB21528   \n",
       "V-2_ACVD.2           Jie (2017)  Nature communications      PRJEB21528   \n",
       "V-2_ACVD.3           Jie (2017)  Nature communications      PRJEB21528   \n",
       "V-2_ACVD.4           Jie (2017)  Nature communications      PRJEB21528   \n",
       "...                         ...                    ...             ...   \n",
       "S-7_Underweight       He (2017)            Gigascience      PRJEB15371   \n",
       "S-7_Underweight.1     He (2017)            Gigascience      PRJEB15371   \n",
       "S-7_Underweight.2     He (2017)            Gigascience      PRJEB15371   \n",
       "S-7_Underweight.3     He (2017)            Gigascience      PRJEB15371   \n",
       "S-7_Underweight.4     He (2017)            Gigascience      PRJEB15371   \n",
       "\n",
       "study             Sample Accession or Sample ID Sample title (ENA/SRA)  \\\n",
       "V-2_ACVD                         SAMEA104142287                ZSL-004   \n",
       "V-2_ACVD.1                       SAMEA104142288                ZSL-007   \n",
       "V-2_ACVD.2                       SAMEA104142293                ZSL-010   \n",
       "V-2_ACVD.3                       SAMEA104142291                ZSL-011   \n",
       "V-2_ACVD.4                       SAMEA104142284                ZSL-019   \n",
       "...                                         ...                    ...   \n",
       "S-7_Underweight                    SAMEA4431948        SZAXPI029564-74   \n",
       "S-7_Underweight.1                  SAMEA4431949        SZAXPI029565-77   \n",
       "S-7_Underweight.2                  SAMEA4431951        SZAXPI029567-80   \n",
       "S-7_Underweight.3                  SAMEA4431964        SZAXPI029580-98   \n",
       "S-7_Underweight.4                  SAMEA4431982       SZAXPI029597-158   \n",
       "\n",
       "study             Sample title (Paper) Subject Id (If available)  ...  \\\n",
       "V-2_ACVD                       ZSL-004                   ZSL-004  ...   \n",
       "V-2_ACVD.1                     ZSL-007                   ZSL-007  ...   \n",
       "V-2_ACVD.2                     ZSL-010                   ZSL-010  ...   \n",
       "V-2_ACVD.3                     ZSL-011                   ZSL-011  ...   \n",
       "V-2_ACVD.4                     ZSL-019                   ZSL-019  ...   \n",
       "...                                ...                       ...  ...   \n",
       "S-7_Underweight        SZAXPI029564-74                   GZCT014  ...   \n",
       "S-7_Underweight.1      SZAXPI029565-77                   GZCT015  ...   \n",
       "S-7_Underweight.2      SZAXPI029567-80                   GZCT017  ...   \n",
       "S-7_Underweight.3      SZAXPI029580-98                   GZCT030  ...   \n",
       "S-7_Underweight.4     SZAXPI029597-158                   GZCT049  ...   \n",
       "\n",
       "study             s__Subdoligranulum_variabile s__Succinatimonas_hippei  \\\n",
       "V-2_ACVD                           0.000501901                        0   \n",
       "V-2_ACVD.1                          0.00354857                        0   \n",
       "V-2_ACVD.2                                   0                        0   \n",
       "V-2_ACVD.3                                   0                        0   \n",
       "V-2_ACVD.4                          0.00126287                        0   \n",
       "...                                        ...                      ...   \n",
       "S-7_Underweight                              0                        0   \n",
       "S-7_Underweight.1                            0                        0   \n",
       "S-7_Underweight.2                   0.00115932                        0   \n",
       "S-7_Underweight.3                            0                        0   \n",
       "S-7_Underweight.4                            0                        0   \n",
       "\n",
       "study             s__Sutterella_wadsworthensis s__Turicibacter_sanguinis  \\\n",
       "V-2_ACVD                             0.0313742                         0   \n",
       "V-2_ACVD.1                                   0                         0   \n",
       "V-2_ACVD.2                                   0                         0   \n",
       "V-2_ACVD.3                                   0                         0   \n",
       "V-2_ACVD.4                                   0                         0   \n",
       "...                                        ...                       ...   \n",
       "S-7_Underweight                        0.16279                         0   \n",
       "S-7_Underweight.1                            0                         0   \n",
       "S-7_Underweight.2                            0                         0   \n",
       "S-7_Underweight.3                            0                         0   \n",
       "S-7_Underweight.4                            0                         0   \n",
       "\n",
       "study             s__Varibaculum_cambriense s__Veillonella_atypica  \\\n",
       "V-2_ACVD                                  0             0.00342788   \n",
       "V-2_ACVD.1                                0                4.50212   \n",
       "V-2_ACVD.2                                0                      0   \n",
       "V-2_ACVD.3                                0             0.00139602   \n",
       "V-2_ACVD.4                                0              0.0129392   \n",
       "...                                     ...                    ...   \n",
       "S-7_Underweight                           0              0.0322849   \n",
       "S-7_Underweight.1                         0                      0   \n",
       "S-7_Underweight.2                         0              0.0865797   \n",
       "S-7_Underweight.3                         0                      0   \n",
       "S-7_Underweight.4                         0                      0   \n",
       "\n",
       "study             s__Veillonella_dispar s__Veillonella_parvula  \\\n",
       "V-2_ACVD                     0.00199693               0.134307   \n",
       "V-2_ACVD.1                     0.122268                1.75344   \n",
       "V-2_ACVD.2                            0             0.00401139   \n",
       "V-2_ACVD.3                   0.00176556               0.145084   \n",
       "V-2_ACVD.4                  0.000238082              0.0163449   \n",
       "...                                 ...                    ...   \n",
       "S-7_Underweight               0.0587168                0.10368   \n",
       "S-7_Underweight.1            0.00125461               0.312764   \n",
       "S-7_Underweight.2             0.0366468              0.0827324   \n",
       "S-7_Underweight.3                     0             0.00855007   \n",
       "S-7_Underweight.4                     0              0.0167338   \n",
       "\n",
       "study             s__Weissella_cibaria s__Weissella_confusa  \n",
       "V-2_ACVD                      0.337587             0.120542  \n",
       "V-2_ACVD.1                           0                    0  \n",
       "V-2_ACVD.2                           0                    0  \n",
       "V-2_ACVD.3                           0          0.000595363  \n",
       "V-2_ACVD.4                           0                    0  \n",
       "...                                ...                  ...  \n",
       "S-7_Underweight                      0                    0  \n",
       "S-7_Underweight.1                    0                    0  \n",
       "S-7_Underweight.2                    0                    0  \n",
       "S-7_Underweight.3                    0                    0  \n",
       "S-7_Underweight.4                    0                    0  \n",
       "\n",
       "[4347 rows x 345 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.insert(0,'batch',metadata['Author (year)'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.insert(0,'Type','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['Type']=pd.Series(train.index.values).str.split('_',expand=True)[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = train[train['Type']=='']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>batch</th>\n",
       "      <th>s__Abiotrophia_defectiva</th>\n",
       "      <th>s__Acetobacter_unclassified</th>\n",
       "      <th>s__Achromobacter_piechaudii</th>\n",
       "      <th>s__Achromobacter_unclassified</th>\n",
       "      <th>s__Achromobacter_xylosoxidans</th>\n",
       "      <th>s__Acidaminococcus_fermentans</th>\n",
       "      <th>s__Acidaminococcus_intestini</th>\n",
       "      <th>s__Acidaminococcus_sp_BV3L6</th>\n",
       "      <th>...</th>\n",
       "      <th>s__Vibrio_furnissii</th>\n",
       "      <th>s__Vibrio_kanaloae</th>\n",
       "      <th>s__Weissella_cibaria</th>\n",
       "      <th>s__Weissella_confusa</th>\n",
       "      <th>s__Weissella_halotolerans</th>\n",
       "      <th>s__Weissella_koreensis</th>\n",
       "      <th>s__Weissella_paramesenteroides</th>\n",
       "      <th>s__Weissella_unclassified</th>\n",
       "      <th>s__Wohlfahrtiimonas_chitiniclastica</th>\n",
       "      <th>s__Yersinia_enterocolitica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overweight_3579</th>\n",
       "      <td>Overweight</td>\n",
       "      <td>Jie (2017)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3580</th>\n",
       "      <td>Overweight</td>\n",
       "      <td>Jie (2017)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3581</th>\n",
       "      <td>Overweight</td>\n",
       "      <td>Jie (2017)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02384</td>\n",
       "      <td>0.10129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3582</th>\n",
       "      <td>Overweight</td>\n",
       "      <td>Jie (2017)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3583</th>\n",
       "      <td>Overweight</td>\n",
       "      <td>Jie (2017)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3812</th>\n",
       "      <td>Overweight</td>\n",
       "      <td>Obregon-Tito (2015)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3813</th>\n",
       "      <td>Overweight</td>\n",
       "      <td>Obregon-Tito (2015)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3814</th>\n",
       "      <td>Overweight</td>\n",
       "      <td>Obregon-Tito (2015)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3815</th>\n",
       "      <td>Overweight</td>\n",
       "      <td>Obregon-Tito (2015)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3816</th>\n",
       "      <td>Overweight</td>\n",
       "      <td>Obregon-Tito (2015)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01592</td>\n",
       "      <td>0.04262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows Ã— 905 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Type                batch  s__Abiotrophia_defectiva  \\\n",
       "Overweight_3579  Overweight           Jie (2017)                       0.0   \n",
       "Overweight_3580  Overweight           Jie (2017)                       0.0   \n",
       "Overweight_3581  Overweight           Jie (2017)                       0.0   \n",
       "Overweight_3582  Overweight           Jie (2017)                       0.0   \n",
       "Overweight_3583  Overweight           Jie (2017)                       0.0   \n",
       "...                     ...                  ...                       ...   \n",
       "Overweight_3812  Overweight  Obregon-Tito (2015)                       0.0   \n",
       "Overweight_3813  Overweight  Obregon-Tito (2015)                       0.0   \n",
       "Overweight_3814  Overweight  Obregon-Tito (2015)                       0.0   \n",
       "Overweight_3815  Overweight  Obregon-Tito (2015)                       0.0   \n",
       "Overweight_3816  Overweight  Obregon-Tito (2015)                       0.0   \n",
       "\n",
       "                 s__Acetobacter_unclassified  s__Achromobacter_piechaudii  \\\n",
       "Overweight_3579                          0.0                          0.0   \n",
       "Overweight_3580                          0.0                          0.0   \n",
       "Overweight_3581                          0.0                          0.0   \n",
       "Overweight_3582                          0.0                          0.0   \n",
       "Overweight_3583                          0.0                          0.0   \n",
       "...                                      ...                          ...   \n",
       "Overweight_3812                          0.0                          0.0   \n",
       "Overweight_3813                          0.0                          0.0   \n",
       "Overweight_3814                          0.0                          0.0   \n",
       "Overweight_3815                          0.0                          0.0   \n",
       "Overweight_3816                          0.0                          0.0   \n",
       "\n",
       "                 s__Achromobacter_unclassified  s__Achromobacter_xylosoxidans  \\\n",
       "Overweight_3579                            0.0                            0.0   \n",
       "Overweight_3580                            0.0                            0.0   \n",
       "Overweight_3581                            0.0                            0.0   \n",
       "Overweight_3582                            0.0                            0.0   \n",
       "Overweight_3583                            0.0                            0.0   \n",
       "...                                        ...                            ...   \n",
       "Overweight_3812                            0.0                            0.0   \n",
       "Overweight_3813                            0.0                            0.0   \n",
       "Overweight_3814                            0.0                            0.0   \n",
       "Overweight_3815                            0.0                            0.0   \n",
       "Overweight_3816                            0.0                            0.0   \n",
       "\n",
       "                 s__Acidaminococcus_fermentans  s__Acidaminococcus_intestini  \\\n",
       "Overweight_3579                            0.0                       0.00000   \n",
       "Overweight_3580                            0.0                       0.00653   \n",
       "Overweight_3581                            0.0                       0.00000   \n",
       "Overweight_3582                            0.0                       0.00000   \n",
       "Overweight_3583                            0.0                       0.00000   \n",
       "...                                        ...                           ...   \n",
       "Overweight_3812                            0.0                       0.00000   \n",
       "Overweight_3813                            0.0                       0.00000   \n",
       "Overweight_3814                            0.0                       0.00000   \n",
       "Overweight_3815                            0.0                       0.00000   \n",
       "Overweight_3816                            0.0                       0.00000   \n",
       "\n",
       "                 s__Acidaminococcus_sp_BV3L6  ...  s__Vibrio_furnissii  \\\n",
       "Overweight_3579                          0.0  ...                  0.0   \n",
       "Overweight_3580                          0.0  ...                  0.0   \n",
       "Overweight_3581                          0.0  ...                  0.0   \n",
       "Overweight_3582                          0.0  ...                  0.0   \n",
       "Overweight_3583                          0.0  ...                  0.0   \n",
       "...                                      ...  ...                  ...   \n",
       "Overweight_3812                          0.0  ...                  0.0   \n",
       "Overweight_3813                          0.0  ...                  0.0   \n",
       "Overweight_3814                          0.0  ...                  0.0   \n",
       "Overweight_3815                          0.0  ...                  0.0   \n",
       "Overweight_3816                          0.0  ...                  0.0   \n",
       "\n",
       "                 s__Vibrio_kanaloae  s__Weissella_cibaria  \\\n",
       "Overweight_3579                 0.0               0.00000   \n",
       "Overweight_3580                 0.0               0.00000   \n",
       "Overweight_3581                 0.0               0.02384   \n",
       "Overweight_3582                 0.0               0.00000   \n",
       "Overweight_3583                 0.0               0.00000   \n",
       "...                             ...                   ...   \n",
       "Overweight_3812                 0.0               0.00000   \n",
       "Overweight_3813                 0.0               0.00000   \n",
       "Overweight_3814                 0.0               0.00000   \n",
       "Overweight_3815                 0.0               0.00000   \n",
       "Overweight_3816                 0.0               0.01592   \n",
       "\n",
       "                 s__Weissella_confusa  s__Weissella_halotolerans  \\\n",
       "Overweight_3579               0.00000                        0.0   \n",
       "Overweight_3580               0.00000                        0.0   \n",
       "Overweight_3581               0.10129                        0.0   \n",
       "Overweight_3582               0.00000                        0.0   \n",
       "Overweight_3583               0.00000                        0.0   \n",
       "...                               ...                        ...   \n",
       "Overweight_3812               0.00000                        0.0   \n",
       "Overweight_3813               0.00000                        0.0   \n",
       "Overweight_3814               0.00000                        0.0   \n",
       "Overweight_3815               0.00000                        0.0   \n",
       "Overweight_3816               0.04262                        0.0   \n",
       "\n",
       "                 s__Weissella_koreensis  s__Weissella_paramesenteroides  \\\n",
       "Overweight_3579                     0.0                             0.0   \n",
       "Overweight_3580                     0.0                             0.0   \n",
       "Overweight_3581                     0.0                             0.0   \n",
       "Overweight_3582                     0.0                             0.0   \n",
       "Overweight_3583                     0.0                             0.0   \n",
       "...                                 ...                             ...   \n",
       "Overweight_3812                     0.0                             0.0   \n",
       "Overweight_3813                     0.0                             0.0   \n",
       "Overweight_3814                     0.0                             0.0   \n",
       "Overweight_3815                     0.0                             0.0   \n",
       "Overweight_3816                     0.0                             0.0   \n",
       "\n",
       "                 s__Weissella_unclassified  \\\n",
       "Overweight_3579                    0.00000   \n",
       "Overweight_3580                    0.00000   \n",
       "Overweight_3581                    0.00000   \n",
       "Overweight_3582                    0.00000   \n",
       "Overweight_3583                    0.00000   \n",
       "...                                    ...   \n",
       "Overweight_3812                    0.00000   \n",
       "Overweight_3813                    0.00000   \n",
       "Overweight_3814                    0.00000   \n",
       "Overweight_3815                    0.00000   \n",
       "Overweight_3816                    0.01816   \n",
       "\n",
       "                 s__Wohlfahrtiimonas_chitiniclastica  \\\n",
       "Overweight_3579                                  0.0   \n",
       "Overweight_3580                                  0.0   \n",
       "Overweight_3581                                  0.0   \n",
       "Overweight_3582                                  0.0   \n",
       "Overweight_3583                                  0.0   \n",
       "...                                              ...   \n",
       "Overweight_3812                                  0.0   \n",
       "Overweight_3813                                  0.0   \n",
       "Overweight_3814                                  0.0   \n",
       "Overweight_3815                                  0.0   \n",
       "Overweight_3816                                  0.0   \n",
       "\n",
       "                 s__Yersinia_enterocolitica  \n",
       "Overweight_3579                         0.0  \n",
       "Overweight_3580                         0.0  \n",
       "Overweight_3581                         0.0  \n",
       "Overweight_3582                         0.0  \n",
       "Overweight_3583                         0.0  \n",
       "...                                     ...  \n",
       "Overweight_3812                         0.0  \n",
       "Overweight_3813                         0.0  \n",
       "Overweight_3814                         0.0  \n",
       "Overweight_3815                         0.0  \n",
       "Overweight_3816                         0.0  \n",
       "\n",
       "[238 rows x 905 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = sorted(list(set(train['batch'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Qin (2012)                 48\n",
       "Jie (2017)                 40\n",
       "Zhang (2015)               27\n",
       "Feng (2015)                20\n",
       "Nielsen (2014)             19\n",
       "Karlsson (2013)            17\n",
       "Vogtmann (2016)            12\n",
       "Zeller (2014)              12\n",
       "Obregon-Tito (2015)         9\n",
       "Qin (2014)                  7\n",
       "He (2017)                   7\n",
       "Sankaranarayanan (2015)     4\n",
       "Le Chatelier (2013)         4\n",
       "Raymond (2015)              4\n",
       "Karlsson (2012)             3\n",
       "Guthrie (2017)              3\n",
       "Nishijima (2016)            2\n",
       "Name: batch, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p['batch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Vogtmann (2016)', 'Zeller (2014)', 'Obregon-Tito (2015)', 'Qin (2014)',\n",
       "       'He (2017)', 'Sankaranarayanan (2015)', 'Le Chatelier (2013)',\n",
       "       'Raymond (2015)', 'Karlsson (2012)', 'Guthrie (2017)',\n",
       "       'Nishijima (2016)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p['batch'].value_counts()[6:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches_list = [ 'Other' if batch in set(train_p['batch'].value_counts()[6:].index) else batch for batch in train_p['batch'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = sorted(list(set(batches_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feng (2015)',\n",
       " 'Jie (2017)',\n",
       " 'Karlsson (2013)',\n",
       " 'Nielsen (2014)',\n",
       " 'Other',\n",
       " 'Qin (2012)',\n",
       " 'Zhang (2015)']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = train_p['batch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biodb/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_p['batch'] = batches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd = ScDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd.variable = np.array(train_p.columns.tolist()[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_values = [[train_p[train_p['batch']==batch].iloc[:,2:].values][0] for batch in batches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_ = [np.sum(np.std(item, axis=0)) for item in adata_values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 5, 1, 6, 0, 3, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = np.argsort(std_)[::-1]\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_names = [np.array( train_p[train_p['batch']== batch].index.tolist()) for batch in batches ]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['Overweight_3722', 'Overweight_3723', 'Overweight_3724',\n",
       "        'Overweight_3725', 'Overweight_3726', 'Overweight_3727',\n",
       "        'Overweight_3728', 'Overweight_3729', 'Overweight_3730',\n",
       "        'Overweight_3731', 'Overweight_3732', 'Overweight_3733',\n",
       "        'Overweight_3734', 'Overweight_3735', 'Overweight_3736',\n",
       "        'Overweight_3737', 'Overweight_3738', 'Overweight_3739',\n",
       "        'Overweight_3740', 'Overweight_3741'], dtype='<U15'),\n",
       " array(['Overweight_3579', 'Overweight_3580', 'Overweight_3581',\n",
       "        'Overweight_3582', 'Overweight_3583', 'Overweight_3584',\n",
       "        'Overweight_3585', 'Overweight_3586', 'Overweight_3587',\n",
       "        'Overweight_3588', 'Overweight_3589', 'Overweight_3590',\n",
       "        'Overweight_3591', 'Overweight_3592', 'Overweight_3593',\n",
       "        'Overweight_3594', 'Overweight_3595', 'Overweight_3596',\n",
       "        'Overweight_3597', 'Overweight_3598', 'Overweight_3599',\n",
       "        'Overweight_3600', 'Overweight_3601', 'Overweight_3602',\n",
       "        'Overweight_3603', 'Overweight_3604', 'Overweight_3605',\n",
       "        'Overweight_3606', 'Overweight_3607', 'Overweight_3608',\n",
       "        'Overweight_3609', 'Overweight_3610', 'Overweight_3611',\n",
       "        'Overweight_3612', 'Overweight_3613', 'Overweight_3614',\n",
       "        'Overweight_3615', 'Overweight_3616', 'Overweight_3617',\n",
       "        'Overweight_3618'], dtype='<U15'),\n",
       " array(['Overweight_3679', 'Overweight_3680', 'Overweight_3681',\n",
       "        'Overweight_3682', 'Overweight_3683', 'Overweight_3684',\n",
       "        'Overweight_3685', 'Overweight_3686', 'Overweight_3687',\n",
       "        'Overweight_3688', 'Overweight_3689', 'Overweight_3690',\n",
       "        'Overweight_3691', 'Overweight_3692', 'Overweight_3693',\n",
       "        'Overweight_3694', 'Overweight_3695'], dtype='<U15'),\n",
       " array(['Overweight_3703', 'Overweight_3704', 'Overweight_3705',\n",
       "        'Overweight_3706', 'Overweight_3707', 'Overweight_3708',\n",
       "        'Overweight_3709', 'Overweight_3710', 'Overweight_3711',\n",
       "        'Overweight_3712', 'Overweight_3713', 'Overweight_3714',\n",
       "        'Overweight_3715', 'Overweight_3716', 'Overweight_3717',\n",
       "        'Overweight_3718', 'Overweight_3719', 'Overweight_3720',\n",
       "        'Overweight_3721'], dtype='<U15'),\n",
       " array(['Overweight_3619', 'Overweight_3620', 'Overweight_3621',\n",
       "        'Overweight_3622', 'Overweight_3623', 'Overweight_3624',\n",
       "        'Overweight_3625', 'Overweight_3626', 'Overweight_3627',\n",
       "        'Overweight_3628', 'Overweight_3629', 'Overweight_3630',\n",
       "        'Overweight_3696', 'Overweight_3697', 'Overweight_3698',\n",
       "        'Overweight_3699', 'Overweight_3700', 'Overweight_3701',\n",
       "        'Overweight_3702', 'Overweight_3769', 'Overweight_3770',\n",
       "        'Overweight_3771', 'Overweight_3772', 'Overweight_3773',\n",
       "        'Overweight_3774', 'Overweight_3775', 'Overweight_3776',\n",
       "        'Overweight_3777', 'Overweight_3778', 'Overweight_3779',\n",
       "        'Overweight_3780', 'Overweight_3781', 'Overweight_3782',\n",
       "        'Overweight_3783', 'Overweight_3784', 'Overweight_3785',\n",
       "        'Overweight_3786', 'Overweight_3787', 'Overweight_3788',\n",
       "        'Overweight_3789', 'Overweight_3790', 'Overweight_3791',\n",
       "        'Overweight_3792', 'Overweight_3793', 'Overweight_3794',\n",
       "        'Overweight_3795', 'Overweight_3796', 'Overweight_3797',\n",
       "        'Overweight_3798', 'Overweight_3799', 'Overweight_3800',\n",
       "        'Overweight_3801', 'Overweight_3802', 'Overweight_3803',\n",
       "        'Overweight_3804', 'Overweight_3805', 'Overweight_3806',\n",
       "        'Overweight_3807', 'Overweight_3808', 'Overweight_3809',\n",
       "        'Overweight_3810', 'Overweight_3811', 'Overweight_3812',\n",
       "        'Overweight_3813', 'Overweight_3814', 'Overweight_3815',\n",
       "        'Overweight_3816'], dtype='<U15'),\n",
       " array(['Overweight_3631', 'Overweight_3632', 'Overweight_3633',\n",
       "        'Overweight_3634', 'Overweight_3635', 'Overweight_3636',\n",
       "        'Overweight_3637', 'Overweight_3638', 'Overweight_3639',\n",
       "        'Overweight_3640', 'Overweight_3641', 'Overweight_3642',\n",
       "        'Overweight_3643', 'Overweight_3644', 'Overweight_3645',\n",
       "        'Overweight_3646', 'Overweight_3647', 'Overweight_3648',\n",
       "        'Overweight_3649', 'Overweight_3650', 'Overweight_3651',\n",
       "        'Overweight_3652', 'Overweight_3653', 'Overweight_3654',\n",
       "        'Overweight_3655', 'Overweight_3656', 'Overweight_3657',\n",
       "        'Overweight_3658', 'Overweight_3659', 'Overweight_3660',\n",
       "        'Overweight_3661', 'Overweight_3662', 'Overweight_3663',\n",
       "        'Overweight_3664', 'Overweight_3665', 'Overweight_3666',\n",
       "        'Overweight_3667', 'Overweight_3668', 'Overweight_3669',\n",
       "        'Overweight_3670', 'Overweight_3671', 'Overweight_3672',\n",
       "        'Overweight_3673', 'Overweight_3674', 'Overweight_3675',\n",
       "        'Overweight_3676', 'Overweight_3677', 'Overweight_3678'],\n",
       "       dtype='<U15'),\n",
       " array(['Overweight_3742', 'Overweight_3743', 'Overweight_3744',\n",
       "        'Overweight_3745', 'Overweight_3746', 'Overweight_3747',\n",
       "        'Overweight_3748', 'Overweight_3749', 'Overweight_3750',\n",
       "        'Overweight_3751', 'Overweight_3752', 'Overweight_3753',\n",
       "        'Overweight_3754', 'Overweight_3755', 'Overweight_3756',\n",
       "        'Overweight_3757', 'Overweight_3758', 'Overweight_3759',\n",
       "        'Overweight_3760', 'Overweight_3761', 'Overweight_3762',\n",
       "        'Overweight_3763', 'Overweight_3764', 'Overweight_3765',\n",
       "        'Overweight_3766', 'Overweight_3767', 'Overweight_3768'],\n",
       "       dtype='<U15')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ec_obs_names = None\n",
    "for item in orders:\n",
    "    if ec_obs_names is None:\n",
    "        ec_obs_names = obs_names[item]\n",
    "    else:\n",
    "        ec_obs_names = np.r_[ec_obs_names, obs_names[item]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Overweight_3619', 'Overweight_3620', 'Overweight_3621',\n",
       "       'Overweight_3622', 'Overweight_3623', 'Overweight_3624',\n",
       "       'Overweight_3625', 'Overweight_3626', 'Overweight_3627',\n",
       "       'Overweight_3628', 'Overweight_3629', 'Overweight_3630',\n",
       "       'Overweight_3696', 'Overweight_3697', 'Overweight_3698',\n",
       "       'Overweight_3699', 'Overweight_3700', 'Overweight_3701',\n",
       "       'Overweight_3702', 'Overweight_3769', 'Overweight_3770',\n",
       "       'Overweight_3771', 'Overweight_3772', 'Overweight_3773',\n",
       "       'Overweight_3774', 'Overweight_3775', 'Overweight_3776',\n",
       "       'Overweight_3777', 'Overweight_3778', 'Overweight_3779',\n",
       "       'Overweight_3780', 'Overweight_3781', 'Overweight_3782',\n",
       "       'Overweight_3783', 'Overweight_3784', 'Overweight_3785',\n",
       "       'Overweight_3786', 'Overweight_3787', 'Overweight_3788',\n",
       "       'Overweight_3789', 'Overweight_3790', 'Overweight_3791',\n",
       "       'Overweight_3792', 'Overweight_3793', 'Overweight_3794',\n",
       "       'Overweight_3795', 'Overweight_3796', 'Overweight_3797',\n",
       "       'Overweight_3798', 'Overweight_3799', 'Overweight_3800',\n",
       "       'Overweight_3801', 'Overweight_3802', 'Overweight_3803',\n",
       "       'Overweight_3804', 'Overweight_3805', 'Overweight_3806',\n",
       "       'Overweight_3807', 'Overweight_3808', 'Overweight_3809',\n",
       "       'Overweight_3810', 'Overweight_3811', 'Overweight_3812',\n",
       "       'Overweight_3813', 'Overweight_3814', 'Overweight_3815',\n",
       "       'Overweight_3816', 'Overweight_3631', 'Overweight_3632',\n",
       "       'Overweight_3633', 'Overweight_3634', 'Overweight_3635',\n",
       "       'Overweight_3636', 'Overweight_3637', 'Overweight_3638',\n",
       "       'Overweight_3639', 'Overweight_3640', 'Overweight_3641',\n",
       "       'Overweight_3642', 'Overweight_3643', 'Overweight_3644',\n",
       "       'Overweight_3645', 'Overweight_3646', 'Overweight_3647',\n",
       "       'Overweight_3648', 'Overweight_3649', 'Overweight_3650',\n",
       "       'Overweight_3651', 'Overweight_3652', 'Overweight_3653',\n",
       "       'Overweight_3654', 'Overweight_3655', 'Overweight_3656',\n",
       "       'Overweight_3657', 'Overweight_3658', 'Overweight_3659',\n",
       "       'Overweight_3660', 'Overweight_3661', 'Overweight_3662',\n",
       "       'Overweight_3663', 'Overweight_3664', 'Overweight_3665',\n",
       "       'Overweight_3666', 'Overweight_3667', 'Overweight_3668',\n",
       "       'Overweight_3669', 'Overweight_3670', 'Overweight_3671',\n",
       "       'Overweight_3672', 'Overweight_3673', 'Overweight_3674',\n",
       "       'Overweight_3675', 'Overweight_3676', 'Overweight_3677',\n",
       "       'Overweight_3678', 'Overweight_3579', 'Overweight_3580',\n",
       "       'Overweight_3581', 'Overweight_3582', 'Overweight_3583',\n",
       "       'Overweight_3584', 'Overweight_3585', 'Overweight_3586',\n",
       "       'Overweight_3587', 'Overweight_3588', 'Overweight_3589',\n",
       "       'Overweight_3590', 'Overweight_3591', 'Overweight_3592',\n",
       "       'Overweight_3593', 'Overweight_3594', 'Overweight_3595',\n",
       "       'Overweight_3596', 'Overweight_3597', 'Overweight_3598',\n",
       "       'Overweight_3599', 'Overweight_3600', 'Overweight_3601',\n",
       "       'Overweight_3602', 'Overweight_3603', 'Overweight_3604',\n",
       "       'Overweight_3605', 'Overweight_3606', 'Overweight_3607',\n",
       "       'Overweight_3608', 'Overweight_3609', 'Overweight_3610',\n",
       "       'Overweight_3611', 'Overweight_3612', 'Overweight_3613',\n",
       "       'Overweight_3614', 'Overweight_3615', 'Overweight_3616',\n",
       "       'Overweight_3617', 'Overweight_3618', 'Overweight_3742',\n",
       "       'Overweight_3743', 'Overweight_3744', 'Overweight_3745',\n",
       "       'Overweight_3746', 'Overweight_3747', 'Overweight_3748',\n",
       "       'Overweight_3749', 'Overweight_3750', 'Overweight_3751',\n",
       "       'Overweight_3752', 'Overweight_3753', 'Overweight_3754',\n",
       "       'Overweight_3755', 'Overweight_3756', 'Overweight_3757',\n",
       "       'Overweight_3758', 'Overweight_3759', 'Overweight_3760',\n",
       "       'Overweight_3761', 'Overweight_3762', 'Overweight_3763',\n",
       "       'Overweight_3764', 'Overweight_3765', 'Overweight_3766',\n",
       "       'Overweight_3767', 'Overweight_3768', 'Overweight_3722',\n",
       "       'Overweight_3723', 'Overweight_3724', 'Overweight_3725',\n",
       "       'Overweight_3726', 'Overweight_3727', 'Overweight_3728',\n",
       "       'Overweight_3729', 'Overweight_3730', 'Overweight_3731',\n",
       "       'Overweight_3732', 'Overweight_3733', 'Overweight_3734',\n",
       "       'Overweight_3735', 'Overweight_3736', 'Overweight_3737',\n",
       "       'Overweight_3738', 'Overweight_3739', 'Overweight_3740',\n",
       "       'Overweight_3741', 'Overweight_3703', 'Overweight_3704',\n",
       "       'Overweight_3705', 'Overweight_3706', 'Overweight_3707',\n",
       "       'Overweight_3708', 'Overweight_3709', 'Overweight_3710',\n",
       "       'Overweight_3711', 'Overweight_3712', 'Overweight_3713',\n",
       "       'Overweight_3714', 'Overweight_3715', 'Overweight_3716',\n",
       "       'Overweight_3717', 'Overweight_3718', 'Overweight_3719',\n",
       "       'Overweight_3720', 'Overweight_3721', 'Overweight_3679',\n",
       "       'Overweight_3680', 'Overweight_3681', 'Overweight_3682',\n",
       "       'Overweight_3683', 'Overweight_3684', 'Overweight_3685',\n",
       "       'Overweight_3686', 'Overweight_3687', 'Overweight_3688',\n",
       "       'Overweight_3689', 'Overweight_3690', 'Overweight_3691',\n",
       "       'Overweight_3692', 'Overweight_3693', 'Overweight_3694',\n",
       "       'Overweight_3695'], dtype='<U15')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ec_obs_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd.dataset = [adata_values[i] for i in orders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(\n",
    "        dataset = scd,\n",
    "        batch_size=512,\n",
    "        num_workers=num_workers,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "global data_size\n",
    "global n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_size = scd.dataset[0].shape[1]\n",
    "n_classes = len(scd.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "903"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "EC = Encoder(latent_dim)\n",
    "Dec = Decoder(latent_dim + n_classes)\n",
    "mse_loss = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=903, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Mish()\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Mish()\n",
       "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (relu): ReLU()\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=263, out_features=512, bias=True)\n",
       "    (1): Mish()\n",
       "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (3): Mish()\n",
       "    (4): Linear(in_features=1024, out_features=903, bias=True)\n",
       "  )\n",
       "  (decoder2): Sequential(\n",
       "    (0): Linear(in_features=7, out_features=512, bias=True)\n",
       "    (1): Mish()\n",
       "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (3): Mish()\n",
       "    (4): Linear(in_features=1024, out_features=903, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = True if torch.cuda.is_available() else False\n",
    "FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cuda:\n",
    "    EC.cuda()\n",
    "    Dec.cuda()\n",
    "    mse_loss.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=903, out_features=1024, bias=True)\n",
       "    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): Mish()\n",
       "    (3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (4): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): Mish()\n",
       "    (6): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EC.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (relu): ReLU()\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=263, out_features=512, bias=True)\n",
       "    (1): Mish()\n",
       "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (3): Mish()\n",
       "    (4): Linear(in_features=1024, out_features=903, bias=True)\n",
       "  )\n",
       "  (decoder2): Sequential(\n",
       "    (0): Linear(in_features=7, out_features=512, bias=True)\n",
       "    (1): Mish()\n",
       "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (3): Mish()\n",
       "    (4): Linear(in_features=1024, out_features=903, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dec.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_Dec = torch.optim.Adam(Dec.parameters(), lr=lr, betas=(b1, b2))\n",
    "optimizer_EC = torch.optim.Adam(EC.parameters(), lr=lr, betas=(b1, b2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Decoder(\n",
       "  (relu): ReLU()\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=263, out_features=512, bias=True)\n",
       "    (1): Mish()\n",
       "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (3): Mish()\n",
       "    (4): Linear(in_features=1024, out_features=903, bias=True)\n",
       "  )\n",
       "  (decoder2): Sequential(\n",
       "    (0): Linear(in_features=7, out_features=512, bias=True)\n",
       "    (1): Mish()\n",
       "    (2): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (3): Mish()\n",
       "    (4): Linear(in_features=1024, out_features=903, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dec.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/150] [Reconstruction loss: 0.846651] [Cotent loss: 0.005998]\n",
      "[Epoch 2/150] [Reconstruction loss: 0.708342] [Cotent loss: 0.014234]\n",
      "[Epoch 3/150] [Reconstruction loss: 0.451807] [Cotent loss: 0.005853]\n",
      "[Epoch 4/150] [Reconstruction loss: 0.366602] [Cotent loss: 0.003486]\n",
      "[Epoch 5/150] [Reconstruction loss: 0.342170] [Cotent loss: 0.002818]\n",
      "[Epoch 6/150] [Reconstruction loss: 0.323349] [Cotent loss: 0.005186]\n",
      "[Epoch 7/150] [Reconstruction loss: 0.302919] [Cotent loss: 0.005173]\n",
      "[Epoch 8/150] [Reconstruction loss: 0.281084] [Cotent loss: 0.003649]\n",
      "[Epoch 9/150] [Reconstruction loss: 0.252270] [Cotent loss: 0.003011]\n",
      "[Epoch 10/150] [Reconstruction loss: 0.242686] [Cotent loss: 0.002927]\n",
      "[Epoch 11/150] [Reconstruction loss: 0.223873] [Cotent loss: 0.002698]\n",
      "[Epoch 12/150] [Reconstruction loss: 0.219147] [Cotent loss: 0.002932]\n",
      "[Epoch 13/150] [Reconstruction loss: 0.208345] [Cotent loss: 0.002996]\n",
      "[Epoch 14/150] [Reconstruction loss: 0.175432] [Cotent loss: 0.002670]\n",
      "[Epoch 15/150] [Reconstruction loss: 0.160716] [Cotent loss: 0.002924]\n",
      "[Epoch 16/150] [Reconstruction loss: 0.141415] [Cotent loss: 0.002288]\n",
      "[Epoch 17/150] [Reconstruction loss: 0.138425] [Cotent loss: 0.002636]\n",
      "[Epoch 18/150] [Reconstruction loss: 0.136280] [Cotent loss: 0.002857]\n",
      "[Epoch 19/150] [Reconstruction loss: 0.129149] [Cotent loss: 0.002391]\n",
      "[Epoch 20/150] [Reconstruction loss: 0.122684] [Cotent loss: 0.002106]\n",
      "[Epoch 21/150] [Reconstruction loss: 0.126967] [Cotent loss: 0.002838]\n",
      "[Epoch 22/150] [Reconstruction loss: 0.115757] [Cotent loss: 0.002041]\n",
      "[Epoch 23/150] [Reconstruction loss: 0.115902] [Cotent loss: 0.002405]\n",
      "[Epoch 24/150] [Reconstruction loss: 0.113192] [Cotent loss: 0.002303]\n",
      "[Epoch 25/150] [Reconstruction loss: 0.111887] [Cotent loss: 0.002471]\n",
      "[Epoch 26/150] [Reconstruction loss: 0.106800] [Cotent loss: 0.002266]\n",
      "[Epoch 27/150] [Reconstruction loss: 0.103661] [Cotent loss: 0.002426]\n",
      "[Epoch 28/150] [Reconstruction loss: 0.104444] [Cotent loss: 0.002177]\n",
      "[Epoch 29/150] [Reconstruction loss: 0.098244] [Cotent loss: 0.002168]\n",
      "[Epoch 30/150] [Reconstruction loss: 0.097903] [Cotent loss: 0.002022]\n",
      "[Epoch 31/150] [Reconstruction loss: 0.096687] [Cotent loss: 0.002187]\n",
      "[Epoch 32/150] [Reconstruction loss: 0.096756] [Cotent loss: 0.002165]\n",
      "[Epoch 33/150] [Reconstruction loss: 0.092274] [Cotent loss: 0.001821]\n",
      "[Epoch 34/150] [Reconstruction loss: 0.090322] [Cotent loss: 0.001677]\n",
      "[Epoch 35/150] [Reconstruction loss: 0.091788] [Cotent loss: 0.001800]\n",
      "[Epoch 36/150] [Reconstruction loss: 0.092619] [Cotent loss: 0.002045]\n",
      "[Epoch 37/150] [Reconstruction loss: 0.085120] [Cotent loss: 0.001863]\n",
      "[Epoch 38/150] [Reconstruction loss: 0.085551] [Cotent loss: 0.001636]\n",
      "[Epoch 39/150] [Reconstruction loss: 0.087513] [Cotent loss: 0.001772]\n",
      "[Epoch 40/150] [Reconstruction loss: 0.078252] [Cotent loss: 0.001519]\n",
      "[Epoch 41/150] [Reconstruction loss: 0.081795] [Cotent loss: 0.001534]\n",
      "[Epoch 42/150] [Reconstruction loss: 0.078842] [Cotent loss: 0.001619]\n",
      "[Epoch 43/150] [Reconstruction loss: 0.080375] [Cotent loss: 0.001398]\n",
      "[Epoch 44/150] [Reconstruction loss: 0.081515] [Cotent loss: 0.001381]\n",
      "[Epoch 45/150] [Reconstruction loss: 0.078679] [Cotent loss: 0.001358]\n",
      "[Epoch 46/150] [Reconstruction loss: 0.078201] [Cotent loss: 0.001448]\n",
      "[Epoch 47/150] [Reconstruction loss: 0.074892] [Cotent loss: 0.001376]\n",
      "[Epoch 48/150] [Reconstruction loss: 0.076776] [Cotent loss: 0.001295]\n",
      "[Epoch 49/150] [Reconstruction loss: 0.076843] [Cotent loss: 0.001346]\n",
      "[Epoch 50/150] [Reconstruction loss: 0.073407] [Cotent loss: 0.001185]\n",
      "[Epoch 51/150] [Reconstruction loss: 0.071882] [Cotent loss: 0.001184]\n",
      "[Epoch 52/150] [Reconstruction loss: 0.070156] [Cotent loss: 0.001171]\n",
      "[Epoch 53/150] [Reconstruction loss: 0.070861] [Cotent loss: 0.001210]\n",
      "[Epoch 54/150] [Reconstruction loss: 0.069905] [Cotent loss: 0.001183]\n",
      "[Epoch 55/150] [Reconstruction loss: 0.068867] [Cotent loss: 0.001156]\n",
      "[Epoch 56/150] [Reconstruction loss: 0.070619] [Cotent loss: 0.001130]\n",
      "[Epoch 57/150] [Reconstruction loss: 0.069709] [Cotent loss: 0.001156]\n",
      "[Epoch 58/150] [Reconstruction loss: 0.069540] [Cotent loss: 0.001019]\n",
      "[Epoch 59/150] [Reconstruction loss: 0.066861] [Cotent loss: 0.001006]\n",
      "[Epoch 60/150] [Reconstruction loss: 0.067986] [Cotent loss: 0.001093]\n",
      "[Epoch 61/150] [Reconstruction loss: 0.067782] [Cotent loss: 0.001147]\n",
      "[Epoch 62/150] [Reconstruction loss: 0.067836] [Cotent loss: 0.001089]\n",
      "[Epoch 63/150] [Reconstruction loss: 0.066358] [Cotent loss: 0.001003]\n",
      "[Epoch 64/150] [Reconstruction loss: 0.065522] [Cotent loss: 0.001024]\n",
      "[Epoch 65/150] [Reconstruction loss: 0.065318] [Cotent loss: 0.001110]\n",
      "[Epoch 66/150] [Reconstruction loss: 0.067177] [Cotent loss: 0.001011]\n",
      "[Epoch 67/150] [Reconstruction loss: 0.066540] [Cotent loss: 0.001141]\n",
      "[Epoch 68/150] [Reconstruction loss: 0.066320] [Cotent loss: 0.001016]\n",
      "[Epoch 69/150] [Reconstruction loss: 0.063833] [Cotent loss: 0.001142]\n",
      "[Epoch 70/150] [Reconstruction loss: 0.063595] [Cotent loss: 0.001040]\n",
      "[Epoch 71/150] [Reconstruction loss: 0.062488] [Cotent loss: 0.001157]\n",
      "[Epoch 72/150] [Reconstruction loss: 0.061320] [Cotent loss: 0.001006]\n",
      "[Epoch 73/150] [Reconstruction loss: 0.060660] [Cotent loss: 0.000904]\n",
      "[Epoch 74/150] [Reconstruction loss: 0.061720] [Cotent loss: 0.000889]\n",
      "[Epoch 75/150] [Reconstruction loss: 0.060726] [Cotent loss: 0.000933]\n",
      "[Epoch 76/150] [Reconstruction loss: 0.061053] [Cotent loss: 0.001052]\n",
      "[Epoch 77/150] [Reconstruction loss: 0.059900] [Cotent loss: 0.000981]\n",
      "[Epoch 78/150] [Reconstruction loss: 0.062297] [Cotent loss: 0.000997]\n",
      "[Epoch 79/150] [Reconstruction loss: 0.060671] [Cotent loss: 0.000853]\n",
      "[Epoch 80/150] [Reconstruction loss: 0.056755] [Cotent loss: 0.000953]\n",
      "[Epoch 81/150] [Reconstruction loss: 0.056773] [Cotent loss: 0.000815]\n",
      "[Epoch 82/150] [Reconstruction loss: 0.062032] [Cotent loss: 0.000899]\n",
      "[Epoch 83/150] [Reconstruction loss: 0.060478] [Cotent loss: 0.000796]\n",
      "[Epoch 84/150] [Reconstruction loss: 0.059014] [Cotent loss: 0.000855]\n",
      "[Epoch 85/150] [Reconstruction loss: 0.057381] [Cotent loss: 0.000852]\n",
      "[Epoch 86/150] [Reconstruction loss: 0.056320] [Cotent loss: 0.000895]\n",
      "[Epoch 87/150] [Reconstruction loss: 0.055639] [Cotent loss: 0.000731]\n",
      "[Epoch 88/150] [Reconstruction loss: 0.053418] [Cotent loss: 0.000732]\n",
      "[Epoch 89/150] [Reconstruction loss: 0.055786] [Cotent loss: 0.000714]\n",
      "[Epoch 90/150] [Reconstruction loss: 0.054524] [Cotent loss: 0.000707]\n",
      "[Epoch 91/150] [Reconstruction loss: 0.055738] [Cotent loss: 0.000858]\n",
      "[Epoch 92/150] [Reconstruction loss: 0.054901] [Cotent loss: 0.000717]\n",
      "[Epoch 93/150] [Reconstruction loss: 0.053635] [Cotent loss: 0.000640]\n",
      "[Epoch 94/150] [Reconstruction loss: 0.052975] [Cotent loss: 0.000724]\n",
      "[Epoch 95/150] [Reconstruction loss: 0.054677] [Cotent loss: 0.000699]\n",
      "[Epoch 96/150] [Reconstruction loss: 0.054499] [Cotent loss: 0.000759]\n",
      "[Epoch 97/150] [Reconstruction loss: 0.052317] [Cotent loss: 0.000687]\n",
      "[Epoch 98/150] [Reconstruction loss: 0.052598] [Cotent loss: 0.000652]\n",
      "[Epoch 99/150] [Reconstruction loss: 0.052830] [Cotent loss: 0.000669]\n",
      "[Epoch 100/150] [Reconstruction loss: 0.054175] [Cotent loss: 0.000669]\n",
      "[Epoch 101/150] [Reconstruction loss: 0.055021] [Cotent loss: 0.000722]\n",
      "[Epoch 102/150] [Reconstruction loss: 0.052367] [Cotent loss: 0.000721]\n",
      "[Epoch 103/150] [Reconstruction loss: 0.054999] [Cotent loss: 0.000756]\n",
      "[Epoch 104/150] [Reconstruction loss: 0.050516] [Cotent loss: 0.000645]\n",
      "[Epoch 105/150] [Reconstruction loss: 0.052320] [Cotent loss: 0.000733]\n",
      "[Epoch 106/150] [Reconstruction loss: 0.052008] [Cotent loss: 0.000592]\n",
      "[Epoch 107/150] [Reconstruction loss: 0.049989] [Cotent loss: 0.000589]\n",
      "[Epoch 108/150] [Reconstruction loss: 0.053850] [Cotent loss: 0.000694]\n",
      "[Epoch 109/150] [Reconstruction loss: 0.050976] [Cotent loss: 0.000548]\n",
      "[Epoch 110/150] [Reconstruction loss: 0.050045] [Cotent loss: 0.000583]\n",
      "[Epoch 111/150] [Reconstruction loss: 0.048748] [Cotent loss: 0.000613]\n",
      "[Epoch 112/150] [Reconstruction loss: 0.052271] [Cotent loss: 0.000710]\n",
      "[Epoch 113/150] [Reconstruction loss: 0.051452] [Cotent loss: 0.000571]\n",
      "[Epoch 114/150] [Reconstruction loss: 0.050451] [Cotent loss: 0.000639]\n",
      "[Epoch 115/150] [Reconstruction loss: 0.050016] [Cotent loss: 0.000646]\n",
      "[Epoch 116/150] [Reconstruction loss: 0.050645] [Cotent loss: 0.000707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 117/150] [Reconstruction loss: 0.052600] [Cotent loss: 0.000572]\n",
      "[Epoch 118/150] [Reconstruction loss: 0.050767] [Cotent loss: 0.000545]\n",
      "[Epoch 119/150] [Reconstruction loss: 0.048986] [Cotent loss: 0.000624]\n",
      "[Epoch 120/150] [Reconstruction loss: 0.048873] [Cotent loss: 0.000549]\n",
      "[Epoch 121/150] [Reconstruction loss: 0.048319] [Cotent loss: 0.000572]\n",
      "[Epoch 122/150] [Reconstruction loss: 0.048933] [Cotent loss: 0.000537]\n",
      "[Epoch 123/150] [Reconstruction loss: 0.048944] [Cotent loss: 0.000541]\n",
      "[Epoch 124/150] [Reconstruction loss: 0.048938] [Cotent loss: 0.000567]\n",
      "[Epoch 125/150] [Reconstruction loss: 0.047996] [Cotent loss: 0.000553]\n",
      "[Epoch 126/150] [Reconstruction loss: 0.046778] [Cotent loss: 0.000639]\n",
      "[Epoch 127/150] [Reconstruction loss: 0.046458] [Cotent loss: 0.000600]\n",
      "[Epoch 128/150] [Reconstruction loss: 0.047169] [Cotent loss: 0.000555]\n",
      "[Epoch 129/150] [Reconstruction loss: 0.048502] [Cotent loss: 0.000533]\n",
      "[Epoch 130/150] [Reconstruction loss: 0.048079] [Cotent loss: 0.000609]\n",
      "[Epoch 131/150] [Reconstruction loss: 0.045128] [Cotent loss: 0.000521]\n",
      "[Epoch 132/150] [Reconstruction loss: 0.047414] [Cotent loss: 0.000524]\n",
      "[Epoch 133/150] [Reconstruction loss: 0.047164] [Cotent loss: 0.000523]\n",
      "[Epoch 134/150] [Reconstruction loss: 0.047355] [Cotent loss: 0.000582]\n",
      "[Epoch 135/150] [Reconstruction loss: 0.046846] [Cotent loss: 0.000584]\n",
      "[Epoch 136/150] [Reconstruction loss: 0.048102] [Cotent loss: 0.000490]\n",
      "[Epoch 137/150] [Reconstruction loss: 0.041680] [Cotent loss: 0.000532]\n",
      "[Epoch 138/150] [Reconstruction loss: 0.047515] [Cotent loss: 0.000557]\n",
      "[Epoch 139/150] [Reconstruction loss: 0.046490] [Cotent loss: 0.000464]\n",
      "[Epoch 140/150] [Reconstruction loss: 0.045877] [Cotent loss: 0.000549]\n",
      "[Epoch 141/150] [Reconstruction loss: 0.043189] [Cotent loss: 0.000486]\n",
      "[Epoch 142/150] [Reconstruction loss: 0.044855] [Cotent loss: 0.000436]\n",
      "[Epoch 143/150] [Reconstruction loss: 0.048792] [Cotent loss: 0.000513]\n",
      "[Epoch 144/150] [Reconstruction loss: 0.047060] [Cotent loss: 0.000475]\n",
      "[Epoch 145/150] [Reconstruction loss: 0.046015] [Cotent loss: 0.000439]\n",
      "[Epoch 146/150] [Reconstruction loss: 0.044010] [Cotent loss: 0.000543]\n",
      "[Epoch 147/150] [Reconstruction loss: 0.047718] [Cotent loss: 0.000586]\n",
      "[Epoch 148/150] [Reconstruction loss: 0.045060] [Cotent loss: 0.000482]\n",
      "[Epoch 149/150] [Reconstruction loss: 0.048519] [Cotent loss: 0.000583]\n",
      "[Epoch 150/150] [Reconstruction loss: 0.042555] [Cotent loss: 0.000445]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    Dec.train()\n",
    "    EC.train()\n",
    "\n",
    "    for i, data in enumerate(dataloader):\n",
    "        datum = [Variable(item.type(FloatTensor)) for item in data]\n",
    "        batch_size = datum[0].shape[0]\n",
    "\n",
    "        ES_data1 = -np.zeros((n_classes * batch_size, n_classes))\n",
    "        for j in range(n_classes):\n",
    "            ES_data1[j*batch_size:(j+1)*batch_size, j] = 1\n",
    "        ES_data1 = Variable(torch.tensor(ES_data1).type(FloatTensor))\n",
    "        ES_data2 = -np.zeros((n_classes * batch_size, n_classes))\n",
    "        ES_data2[np.arange(n_classes*batch_size),np.random.randint(n_classes, size=n_classes*batch_size)] = 1\n",
    "        ES_data2 = Variable(torch.tensor(ES_data2).type(FloatTensor))\n",
    "\n",
    "        optimizer_Dec.zero_grad()\n",
    "        optimizer_EC.zero_grad()\n",
    "\n",
    "        loss1_data1 = torch.cat(datum, dim=0)\n",
    "        loss4 = mse_loss(EC(loss1_data1), EC(Dec(EC(loss1_data1), ES_data2)))\n",
    "        ae_loss = mse_loss(Dec(EC(loss1_data1), ES_data1), loss1_data1)\n",
    "\n",
    "        all_loss = (lambda_co * loss4) + (lambda_rc * ae_loss)\n",
    "        all_loss.backward()\n",
    "\n",
    "        optimizer_Dec.step()\n",
    "        optimizer_EC.step()\n",
    "\n",
    "    print(\n",
    "        \"[Epoch %d/%d] [Reconstruction loss: %f] [Cotent loss: %f]\"\n",
    "        % (epoch+1, n_epochs,\n",
    "           ae_loss.item(),\n",
    "           loss4.item(),\n",
    "          )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dec.eval()\n",
    "EC.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    data = Variable(FloatTensor(scd.dataset[0]))\n",
    "    label = np.full((len(scd.dataset[0]),1), batches[orders[0]])\n",
    "    static_sample = EC(data)\n",
    "    transform_data = static_sample.cpu().detach().numpy()\n",
    "    for j in range(1, len(scd.dataset)):\n",
    "        data = Variable(FloatTensor(scd.dataset[j]))\n",
    "        static_sample = EC(data)\n",
    "        fake_data = static_sample.cpu().detach().numpy()\n",
    "        fake_label = np.full((len(scd.dataset[j]),1), batches[orders[j]])\n",
    "        transform_data, label = cat_data(transform_data, fake_data, [label, fake_label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(238, 256)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient_penalty(real_data, fake_data, D):\n",
    "    eta = torch.FloatTensor(real_data.size(0),1).uniform_(0,1)\n",
    "    eta = eta.expand(real_data.size(0), real_data.size(1))\n",
    "    cuda = True if torch.cuda.is_available() else False\n",
    "    if cuda:\n",
    "        eta = eta.cuda()\n",
    "    else:\n",
    "        eta = eta\n",
    "\n",
    "    interpolated = eta * real_data + ((1 - eta) * fake_data)\n",
    "\n",
    "    if cuda:\n",
    "        interpolated = interpolated.cuda()\n",
    "    else:\n",
    "        interpolated = interpolated\n",
    "\n",
    "    # define it to calculate gradient\n",
    "    interpolated = Variable(interpolated, requires_grad=True)\n",
    "\n",
    "    # calculate probability of interpolated examples\n",
    "    prob_interpolated = D(interpolated)\n",
    "\n",
    "    # calculate gradients of probabilities with respect to examples\n",
    "    gradients = autograd.grad(outputs=prob_interpolated, inputs=interpolated,\n",
    "                           grad_outputs=torch.ones(\n",
    "                               prob_interpolated.size()).cuda() if cuda else torch.ones(\n",
    "                               prob_interpolated.size()),\n",
    "                           create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "    grad_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return grad_penalty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data: np.float32) -> np.float32:\n",
    "    norm = data#(np.exp2(data)-1)\n",
    "    return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire_pairs(X, Y, k, metric):\n",
    "    X = normalize(X)\n",
    "    Y = normalize(Y)\n",
    "\n",
    "    f = X.shape[1]\n",
    "    t1 = AnnoyIndex(f, metric)\n",
    "    t2 = AnnoyIndex(f, metric)\n",
    "    for i in range(len(X)):\n",
    "        t1.add_item(i, X[i])\n",
    "    for i in range(len(Y)):\n",
    "        t2.add_item(i, Y[i])\n",
    "    t1.build(10)\n",
    "    t2.build(10)\n",
    "\n",
    "    mnn_mat = np.bool8(np.zeros((len(X), len(Y))))\n",
    "    sorted_mat = np.array([t2.get_nns_by_vector(item, k) for item in X])\n",
    "    for i in range(len(sorted_mat)):\n",
    "        mnn_mat[i,sorted_mat[i]] = True\n",
    "    _ = np.bool8(np.zeros((len(X), len(Y))))\n",
    "    sorted_mat = np.array([t1.get_nns_by_vector(item, k) for item in Y])\n",
    "    for i in range(len(sorted_mat)):\n",
    "        _[sorted_mat[i],i] = True\n",
    "    mnn_mat = np.logical_and(_, mnn_mat)\n",
    "    pairs = [(x, y) for x, y in zip(*np.where(mnn_mat>0))]\n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs_dict(pairs):\n",
    "    pairs_dict = {}\n",
    "    for x,y in pairs:\n",
    "        if x not in pairs_dict.keys():\n",
    "            pairs_dict[x] = [y]\n",
    "        else:\n",
    "            pairs_dict[x].append(y)\n",
    "    return pairs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScDataset(Dataset):\n",
    "    def __init__(self, n_sample=3000):\n",
    "        self.dataset = []\n",
    "        self.cali_dataset = []\n",
    "        self.variable = None\n",
    "        self.anchor_index = 0\n",
    "        self.query_index = 1\n",
    "        self.pairs = None\n",
    "        self.labels = None\n",
    "        self.transform = None\n",
    "        self.sample = None\n",
    "        self.metric = 'euclidean'\n",
    "        self.k1 = None\n",
    "        self.k2 = None\n",
    "        self.n_sample = n_sample\n",
    "\n",
    "\n",
    "    def change_dataset(self, index: int=1):\n",
    "        self.query_index = index\n",
    "\n",
    "\n",
    "    def acquire_anchor(self, index: int=0):\n",
    "        self.anchor_index = index\n",
    "\n",
    "\n",
    "    def calculate_mnn_pairs(self):\n",
    "        tmp = np.arange(len(self.dataset[self.anchor_index]))\n",
    "        np.random.shuffle(tmp)\n",
    "        self.sample = self.cali_dataset[self.anchor_index][tmp[:self.n_sample]]\n",
    "        ####\n",
    "        tmp2 = np.arange(len(self.dataset[self.query_index]))\n",
    "        np.random.shuffle(tmp2)\n",
    "        self.query_sample = self.cali_dataset[self.query_index][tmp2[:self.n_sample]]\n",
    "        ####\n",
    "        \n",
    "        if (self.k1 is None) or (self.k2 is None):\n",
    "            self.k2 = int(min(len(self.sample), len(self.query_sample))/100)\n",
    "            self.k1 = max(int(self.k2/2), 1)\n",
    "        \n",
    "        print('Calculating Anchor Pairs...')\n",
    "        anchor_pairs = acquire_pairs(self.sample, self.sample, self.k1, self.metric)\n",
    "        print('Calculating Query Pairs...')\n",
    "        query_pairs = acquire_pairs(self.query_sample, self.query_sample, self.k1, self.metric)\n",
    "        print('Calculating KNN Pairs...')\n",
    "        pairs = acquire_pairs(self.sample, self.query_sample, self.k1, self.metric)\n",
    "        print('Calculating Random Walk Pairs...')\n",
    "        anchor_pairs_dict = create_pairs_dict(anchor_pairs)\n",
    "        query_pairs_dict = create_pairs_dict(query_pairs)\n",
    "        pair_plus = []\n",
    "        for x, y in pairs:\n",
    "            start = (x, y)\n",
    "            for i in range(50):\n",
    "                pair_plus.append(start)\n",
    "                start = (random.choice(anchor_pairs_dict[start[0]]), random.choice(query_pairs_dict[start[1]]))\n",
    "\n",
    "        self.datasetA = self.dataset[self.query_index][tmp2[:self.n_sample]][[y for x,y in pair_plus], :]\n",
    "        self.datasetB = self.dataset[self.anchor_index][tmp[:self.n_sample]][[x for x,y in pair_plus], :]\n",
    "        print('Done.')\n",
    "\n",
    "    def __len__(self):\n",
    "        return 10*1024\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return random.choice(self.datasetA), random.choice(self.datasetB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(scd, n_dataset, n_epochs):\n",
    "    scd.change_dataset(n_dataset)\n",
    "    scd.calculate_mnn_pairs()\n",
    "\n",
    "    n_epochs = n_epochs\n",
    "    n_classes = 2\n",
    "    data_size = scd.dataset[0].shape[1]\n",
    "    lr = 0.0002\n",
    "    b1 = 0.5\n",
    "    b2 = 0.999\n",
    "    latent_dim = 256\n",
    "    n_critic = 100\n",
    "\n",
    "\n",
    "    cuda = True if torch.cuda.is_available() else False\n",
    "    FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "    LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset = scd,\n",
    "        batch_size=1024,\n",
    "    )\n",
    "\n",
    "\n",
    "    class Generator(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Generator, self).__init__()\n",
    "            self.relu = nn.ReLU(inplace=True)\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Linear(data_size, 1024),\n",
    "                nn.BatchNorm1d(1024),\n",
    "                Mish(),\n",
    "                nn.Linear(1024, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                Mish(),\n",
    "                nn.Linear(512, latent_dim),\n",
    "                nn.BatchNorm1d(latent_dim),\n",
    "            )\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Linear(latent_dim, 512),\n",
    "                nn.BatchNorm1d(512),\n",
    "                Mish(),\n",
    "                nn.Linear(512, 1024),\n",
    "                nn.BatchNorm1d(1024),\n",
    "                Mish(),\n",
    "                nn.Linear(1024, data_size),\n",
    "            )\n",
    "\n",
    "        def forward(self, x):\n",
    "            latent_data = self.encoder(x)\n",
    "            gen_data = self.decoder(latent_data)\n",
    "            return self.relu(gen_data + x)\n",
    "\n",
    "\n",
    "    class Discriminator(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(Discriminator, self).__init__()\n",
    "            self.model = nn.Sequential(\n",
    "                nn.Linear(data_size, 512),\n",
    "                Mish(),\n",
    "                nn.Linear(512, 512),\n",
    "                Mish(),\n",
    "            )\n",
    "\n",
    "            # Output layers\n",
    "            self.adv_layer = nn.Sequential(nn.Linear(512, 1))\n",
    "\n",
    "        def forward(self, data):\n",
    "            out = self.model(data)\n",
    "            validity = self.adv_layer(out)\n",
    "            return validity\n",
    "\n",
    "    # Initialize generator and discriminator\n",
    "    G_AB = Generator()\n",
    "    D_B = Discriminator()\n",
    "\n",
    "    if cuda:\n",
    "        G_AB.cuda()\n",
    "        D_B.cuda()\n",
    "\n",
    "    # Initialize weights\n",
    "    G_AB.apply(weights_init_normal)\n",
    "    D_B.apply(weights_init_normal)\n",
    "\n",
    "    optimizer_G_AB = torch.optim.Adam(G_AB.parameters(), lr=lr, betas=(b1, b2))\n",
    "    optimizer_D_B = torch.optim.Adam(D_B.parameters(), lr=lr, betas=(b1, b2))\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        G_AB.train()\n",
    "        for i, (data_A, data_B) in enumerate(dataloader):\n",
    "            batch_size = data_A.shape[0]\n",
    "\n",
    "            # Configure input\n",
    "            real_data = Variable(data_B.type(FloatTensor))\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "            optimizer_D_B.zero_grad()\n",
    "            z = Variable(data_A.type(FloatTensor))\n",
    "            gen_data = G_AB(z)\n",
    "\n",
    "\n",
    "            # Loss for real images\n",
    "            real_validity  = D_B(real_data)\n",
    "            fake_validity  = D_B(gen_data)\n",
    "\n",
    "\n",
    "            # Compute W-div gradient penalty\n",
    "            div_gp = calculate_gradient_penalty(real_data, gen_data, D_B)\n",
    "\n",
    "            # Adversarial loss\n",
    "            db_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + 10*div_gp\n",
    "            db_loss.backward()\n",
    "            optimizer_D_B.step()\n",
    "\n",
    "\n",
    "            # -----------------\n",
    "            #  Train Generator\n",
    "            # -----------------\n",
    "\n",
    "            if i % n_critic == 0:\n",
    "                optimizer_G_AB.zero_grad()\n",
    "                z = Variable(data_A.type(FloatTensor), requires_grad=True)\n",
    "                gen_data = G_AB(z)\n",
    "                fake_validity = D_B(gen_data)\n",
    "                gab_loss = -torch.mean(fake_validity)\n",
    "                gab_loss.backward()\n",
    "\n",
    "                optimizer_G_AB.step()\n",
    "\n",
    "\n",
    "        # --------------\n",
    "        # Log Progress\n",
    "        # --------------\n",
    "\n",
    "        print(\n",
    "            \"[Epoch %d/%d] [D loss: %f] [G loss: %f]\"\n",
    "            % (epoch+1, n_epochs,\n",
    "               db_loss.item(),\n",
    "               gab_loss.item(),\n",
    "              )\n",
    "        )\n",
    "\n",
    "\n",
    "    G_AB.eval()\n",
    "    with torch.no_grad():\n",
    "        z = Variable(FloatTensor(scd.dataset[scd.query_index]))\n",
    "        static_sample = G_AB(z)\n",
    "        fake_data = static_sample.cpu().detach().numpy()\n",
    "    return fake_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_batches = sorted(list(set(label.T[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd1 = scd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label.T[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd = ScDataset(len(label.T[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd.metric = 'angular'\n",
    "scd.k1 = None\n",
    "scd.k2 = None\n",
    "scd.variable = scd1.variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders: Other<-Qin (2012)<-Jie (2017)<-Zhang (2015)<-Feng (2015)<-Nielsen (2014)<-Karlsson (2013)\n"
     ]
    }
   ],
   "source": [
    "print('Orders:','<-'.join(batches[i] for i in orders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd.dataset = [adata_values[i] for i in orders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>batch</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "      <th>253</th>\n",
       "      <th>254</th>\n",
       "      <th>255</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Other</td>\n",
       "      <td>-0.085109</td>\n",
       "      <td>-0.134151</td>\n",
       "      <td>0.562397</td>\n",
       "      <td>0.178173</td>\n",
       "      <td>0.503652</td>\n",
       "      <td>0.152453</td>\n",
       "      <td>1.004732</td>\n",
       "      <td>-0.494178</td>\n",
       "      <td>0.846799</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.206212</td>\n",
       "      <td>-0.292491</td>\n",
       "      <td>0.938009</td>\n",
       "      <td>-0.198684</td>\n",
       "      <td>0.148335</td>\n",
       "      <td>-0.127635</td>\n",
       "      <td>-0.475556</td>\n",
       "      <td>-0.245269</td>\n",
       "      <td>0.212345</td>\n",
       "      <td>-0.058509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Other</td>\n",
       "      <td>-0.066880</td>\n",
       "      <td>0.033022</td>\n",
       "      <td>0.451024</td>\n",
       "      <td>-0.130119</td>\n",
       "      <td>0.366637</td>\n",
       "      <td>0.132086</td>\n",
       "      <td>0.814253</td>\n",
       "      <td>-0.420701</td>\n",
       "      <td>0.477716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.184468</td>\n",
       "      <td>-0.061697</td>\n",
       "      <td>0.521373</td>\n",
       "      <td>-0.030952</td>\n",
       "      <td>0.058610</td>\n",
       "      <td>-0.096027</td>\n",
       "      <td>-0.416868</td>\n",
       "      <td>-0.291197</td>\n",
       "      <td>0.256635</td>\n",
       "      <td>0.010130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.131742</td>\n",
       "      <td>0.205865</td>\n",
       "      <td>0.154822</td>\n",
       "      <td>-0.044801</td>\n",
       "      <td>0.363387</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.033453</td>\n",
       "      <td>-0.095347</td>\n",
       "      <td>0.352739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.426277</td>\n",
       "      <td>0.131419</td>\n",
       "      <td>0.643652</td>\n",
       "      <td>-0.103064</td>\n",
       "      <td>-0.056633</td>\n",
       "      <td>0.062488</td>\n",
       "      <td>-0.118545</td>\n",
       "      <td>-0.042113</td>\n",
       "      <td>0.321148</td>\n",
       "      <td>-0.249054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Other</td>\n",
       "      <td>0.440696</td>\n",
       "      <td>0.207748</td>\n",
       "      <td>0.015435</td>\n",
       "      <td>0.314654</td>\n",
       "      <td>0.415750</td>\n",
       "      <td>0.116383</td>\n",
       "      <td>-0.178496</td>\n",
       "      <td>0.954549</td>\n",
       "      <td>-0.210281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153311</td>\n",
       "      <td>0.486356</td>\n",
       "      <td>-0.465357</td>\n",
       "      <td>0.027676</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>-0.515607</td>\n",
       "      <td>-0.315821</td>\n",
       "      <td>0.166881</td>\n",
       "      <td>-0.616933</td>\n",
       "      <td>-0.133195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Other</td>\n",
       "      <td>-0.039332</td>\n",
       "      <td>0.469693</td>\n",
       "      <td>-0.258113</td>\n",
       "      <td>-0.486127</td>\n",
       "      <td>0.570958</td>\n",
       "      <td>0.008927</td>\n",
       "      <td>0.070328</td>\n",
       "      <td>0.222047</td>\n",
       "      <td>-0.225921</td>\n",
       "      <td>...</td>\n",
       "      <td>0.318291</td>\n",
       "      <td>0.134490</td>\n",
       "      <td>-0.485869</td>\n",
       "      <td>0.106637</td>\n",
       "      <td>0.025186</td>\n",
       "      <td>-0.305881</td>\n",
       "      <td>-0.149542</td>\n",
       "      <td>0.202563</td>\n",
       "      <td>-0.011708</td>\n",
       "      <td>-0.427119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Karlsson (2013)</td>\n",
       "      <td>-0.054899</td>\n",
       "      <td>-0.114295</td>\n",
       "      <td>-0.299255</td>\n",
       "      <td>-0.344850</td>\n",
       "      <td>0.778089</td>\n",
       "      <td>-0.352746</td>\n",
       "      <td>0.421063</td>\n",
       "      <td>-0.019471</td>\n",
       "      <td>-0.538001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.243075</td>\n",
       "      <td>0.257538</td>\n",
       "      <td>-0.435933</td>\n",
       "      <td>0.257206</td>\n",
       "      <td>0.388614</td>\n",
       "      <td>-0.607854</td>\n",
       "      <td>-0.632491</td>\n",
       "      <td>0.204100</td>\n",
       "      <td>-0.513940</td>\n",
       "      <td>-0.393637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Karlsson (2013)</td>\n",
       "      <td>-0.143413</td>\n",
       "      <td>0.367240</td>\n",
       "      <td>-0.059782</td>\n",
       "      <td>-0.095537</td>\n",
       "      <td>0.402280</td>\n",
       "      <td>0.330589</td>\n",
       "      <td>0.441663</td>\n",
       "      <td>-0.357425</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.389118</td>\n",
       "      <td>0.032960</td>\n",
       "      <td>0.339075</td>\n",
       "      <td>0.154442</td>\n",
       "      <td>0.070765</td>\n",
       "      <td>0.136696</td>\n",
       "      <td>-0.065614</td>\n",
       "      <td>-0.429427</td>\n",
       "      <td>-0.005799</td>\n",
       "      <td>-0.199758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Karlsson (2013)</td>\n",
       "      <td>-0.352752</td>\n",
       "      <td>0.053045</td>\n",
       "      <td>0.308048</td>\n",
       "      <td>-0.242014</td>\n",
       "      <td>0.201634</td>\n",
       "      <td>0.339689</td>\n",
       "      <td>0.982311</td>\n",
       "      <td>-0.282756</td>\n",
       "      <td>0.772103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.304490</td>\n",
       "      <td>0.122337</td>\n",
       "      <td>0.465672</td>\n",
       "      <td>-0.062403</td>\n",
       "      <td>0.029476</td>\n",
       "      <td>-0.279917</td>\n",
       "      <td>-0.033707</td>\n",
       "      <td>-0.193340</td>\n",
       "      <td>-0.043484</td>\n",
       "      <td>-0.154153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Karlsson (2013)</td>\n",
       "      <td>0.132263</td>\n",
       "      <td>0.278398</td>\n",
       "      <td>0.445930</td>\n",
       "      <td>0.102948</td>\n",
       "      <td>0.127591</td>\n",
       "      <td>0.989901</td>\n",
       "      <td>1.062595</td>\n",
       "      <td>0.128021</td>\n",
       "      <td>0.807491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.877912</td>\n",
       "      <td>0.613692</td>\n",
       "      <td>-0.180695</td>\n",
       "      <td>-0.038836</td>\n",
       "      <td>-0.797772</td>\n",
       "      <td>-0.438369</td>\n",
       "      <td>-0.494734</td>\n",
       "      <td>0.132233</td>\n",
       "      <td>-0.355499</td>\n",
       "      <td>-0.171551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Karlsson (2013)</td>\n",
       "      <td>-0.325434</td>\n",
       "      <td>-0.402035</td>\n",
       "      <td>-0.052991</td>\n",
       "      <td>-0.297602</td>\n",
       "      <td>0.267741</td>\n",
       "      <td>-0.122498</td>\n",
       "      <td>0.481642</td>\n",
       "      <td>-0.509276</td>\n",
       "      <td>0.076649</td>\n",
       "      <td>...</td>\n",
       "      <td>0.097245</td>\n",
       "      <td>-0.012262</td>\n",
       "      <td>-0.145230</td>\n",
       "      <td>-0.132817</td>\n",
       "      <td>-0.060857</td>\n",
       "      <td>-0.045591</td>\n",
       "      <td>-0.422480</td>\n",
       "      <td>0.060378</td>\n",
       "      <td>-0.057760</td>\n",
       "      <td>-0.048275</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows Ã— 257 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               batch         0         1         2         3         4  \\\n",
       "0              Other -0.085109 -0.134151  0.562397  0.178173  0.503652   \n",
       "1              Other -0.066880  0.033022  0.451024 -0.130119  0.366637   \n",
       "2              Other  0.131742  0.205865  0.154822 -0.044801  0.363387   \n",
       "3              Other  0.440696  0.207748  0.015435  0.314654  0.415750   \n",
       "4              Other -0.039332  0.469693 -0.258113 -0.486127  0.570958   \n",
       "..               ...       ...       ...       ...       ...       ...   \n",
       "233  Karlsson (2013) -0.054899 -0.114295 -0.299255 -0.344850  0.778089   \n",
       "234  Karlsson (2013) -0.143413  0.367240 -0.059782 -0.095537  0.402280   \n",
       "235  Karlsson (2013) -0.352752  0.053045  0.308048 -0.242014  0.201634   \n",
       "236  Karlsson (2013)  0.132263  0.278398  0.445930  0.102948  0.127591   \n",
       "237  Karlsson (2013) -0.325434 -0.402035 -0.052991 -0.297602  0.267741   \n",
       "\n",
       "            5         6         7         8  ...       246       247  \\\n",
       "0    0.152453  1.004732 -0.494178  0.846799  ... -0.206212 -0.292491   \n",
       "1    0.132086  0.814253 -0.420701  0.477716  ... -0.184468 -0.061697   \n",
       "2    0.645000  0.033453 -0.095347  0.352739  ... -0.426277  0.131419   \n",
       "3    0.116383 -0.178496  0.954549 -0.210281  ...  0.153311  0.486356   \n",
       "4    0.008927  0.070328  0.222047 -0.225921  ...  0.318291  0.134490   \n",
       "..        ...       ...       ...       ...  ...       ...       ...   \n",
       "233 -0.352746  0.421063 -0.019471 -0.538001  ...  0.243075  0.257538   \n",
       "234  0.330589  0.441663 -0.357425  0.011872  ... -0.389118  0.032960   \n",
       "235  0.339689  0.982311 -0.282756  0.772103  ... -0.304490  0.122337   \n",
       "236  0.989901  1.062595  0.128021  0.807491  ... -0.877912  0.613692   \n",
       "237 -0.122498  0.481642 -0.509276  0.076649  ...  0.097245 -0.012262   \n",
       "\n",
       "          248       249       250       251       252       253       254  \\\n",
       "0    0.938009 -0.198684  0.148335 -0.127635 -0.475556 -0.245269  0.212345   \n",
       "1    0.521373 -0.030952  0.058610 -0.096027 -0.416868 -0.291197  0.256635   \n",
       "2    0.643652 -0.103064 -0.056633  0.062488 -0.118545 -0.042113  0.321148   \n",
       "3   -0.465357  0.027676  0.003930 -0.515607 -0.315821  0.166881 -0.616933   \n",
       "4   -0.485869  0.106637  0.025186 -0.305881 -0.149542  0.202563 -0.011708   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "233 -0.435933  0.257206  0.388614 -0.607854 -0.632491  0.204100 -0.513940   \n",
       "234  0.339075  0.154442  0.070765  0.136696 -0.065614 -0.429427 -0.005799   \n",
       "235  0.465672 -0.062403  0.029476 -0.279917 -0.033707 -0.193340 -0.043484   \n",
       "236 -0.180695 -0.038836 -0.797772 -0.438369 -0.494734  0.132233 -0.355499   \n",
       "237 -0.145230 -0.132817 -0.060857 -0.045591 -0.422480  0.060378 -0.057760   \n",
       "\n",
       "          255  \n",
       "0   -0.058509  \n",
       "1    0.010130  \n",
       "2   -0.249054  \n",
       "3   -0.133195  \n",
       "4   -0.427119  \n",
       "..        ...  \n",
       "233 -0.393637  \n",
       "234 -0.199758  \n",
       "235 -0.154153  \n",
       "236 -0.171551  \n",
       "237 -0.048275  \n",
       "\n",
       "[238 rows x 257 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cali_adata = pd.DataFrame(transform_data)\n",
    "cali_adata.insert(0,'batch',label.T[0])\n",
    "cali_adata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_adata_values = [np.array(cali_adata[cali_adata['batch'] == batch].iloc[:,1:]) for batch in batches]\n",
    "cali_orders = orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd.cali_dataset = [cali_adata_values[i] for i in cali_orders]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "scd.transform = np.copy(scd.dataset[scd.anchor_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merging dataset Qin (2012) to Other\n",
      "Calculating Anchor Pairs...\n",
      "Calculating Query Pairs...\n",
      "Calculating KNN Pairs...\n",
      "Calculating Random Walk Pairs...\n",
      "Done.\n",
      "[Epoch 1/150] [D loss: 2.533240] [G loss: 0.098595]\n",
      "[Epoch 2/150] [D loss: -4.233782] [G loss: 1.347926]\n",
      "[Epoch 3/150] [D loss: -7.419712] [G loss: 5.422555]\n",
      "[Epoch 4/150] [D loss: -9.769296] [G loss: 8.705208]\n",
      "[Epoch 5/150] [D loss: -11.873896] [G loss: 10.311496]\n",
      "[Epoch 6/150] [D loss: -13.678122] [G loss: 10.984254]\n",
      "[Epoch 7/150] [D loss: -16.513418] [G loss: 12.402990]\n",
      "[Epoch 8/150] [D loss: -19.464573] [G loss: 12.753711]\n",
      "[Epoch 9/150] [D loss: -25.382742] [G loss: 14.984046]\n",
      "[Epoch 10/150] [D loss: -28.204611] [G loss: 17.044416]\n",
      "[Epoch 11/150] [D loss: -29.211567] [G loss: 16.691614]\n",
      "[Epoch 12/150] [D loss: -30.491737] [G loss: 18.537552]\n",
      "[Epoch 13/150] [D loss: -29.508541] [G loss: 16.139851]\n",
      "[Epoch 14/150] [D loss: -28.974674] [G loss: 15.310011]\n",
      "[Epoch 15/150] [D loss: -29.769655] [G loss: 14.738556]\n",
      "[Epoch 16/150] [D loss: -27.885059] [G loss: 13.592895]\n",
      "[Epoch 17/150] [D loss: -27.756886] [G loss: 12.085594]\n",
      "[Epoch 18/150] [D loss: -27.333496] [G loss: 11.591081]\n",
      "[Epoch 19/150] [D loss: -25.404816] [G loss: 9.384533]\n",
      "[Epoch 20/150] [D loss: -24.754658] [G loss: 8.929941]\n",
      "[Epoch 21/150] [D loss: -25.912338] [G loss: 7.629322]\n",
      "[Epoch 22/150] [D loss: -23.953684] [G loss: 7.338966]\n",
      "[Epoch 23/150] [D loss: -24.116264] [G loss: 5.463171]\n",
      "[Epoch 24/150] [D loss: -24.281397] [G loss: 6.316519]\n",
      "[Epoch 25/150] [D loss: -24.443485] [G loss: 4.966684]\n",
      "[Epoch 26/150] [D loss: -23.701366] [G loss: 4.999045]\n",
      "[Epoch 27/150] [D loss: -24.377401] [G loss: 5.577686]\n",
      "[Epoch 28/150] [D loss: -23.428867] [G loss: 5.026245]\n",
      "[Epoch 29/150] [D loss: -23.161556] [G loss: 5.151200]\n",
      "[Epoch 30/150] [D loss: -22.812849] [G loss: 4.645215]\n",
      "[Epoch 31/150] [D loss: -22.689898] [G loss: 3.153513]\n",
      "[Epoch 32/150] [D loss: -22.318626] [G loss: 1.251646]\n",
      "[Epoch 33/150] [D loss: -23.205521] [G loss: 2.733203]\n",
      "[Epoch 34/150] [D loss: -22.061636] [G loss: 2.301760]\n",
      "[Epoch 35/150] [D loss: -19.995176] [G loss: 1.945013]\n",
      "[Epoch 36/150] [D loss: -21.674904] [G loss: 2.192948]\n",
      "[Epoch 37/150] [D loss: -20.592335] [G loss: 0.879054]\n",
      "[Epoch 38/150] [D loss: -20.097740] [G loss: 0.391260]\n",
      "[Epoch 39/150] [D loss: -19.647146] [G loss: 0.303924]\n",
      "[Epoch 40/150] [D loss: -19.157516] [G loss: 0.562848]\n",
      "[Epoch 41/150] [D loss: -19.743563] [G loss: -1.300676]\n",
      "[Epoch 42/150] [D loss: -19.946426] [G loss: -1.217274]\n",
      "[Epoch 43/150] [D loss: -18.850012] [G loss: -1.771619]\n",
      "[Epoch 44/150] [D loss: -19.320244] [G loss: -3.235577]\n",
      "[Epoch 45/150] [D loss: -18.891233] [G loss: -1.695637]\n",
      "[Epoch 46/150] [D loss: -17.645481] [G loss: -2.392691]\n",
      "[Epoch 47/150] [D loss: -17.519508] [G loss: -2.824952]\n",
      "[Epoch 48/150] [D loss: -17.451077] [G loss: -3.943553]\n",
      "[Epoch 49/150] [D loss: -16.257433] [G loss: -3.778034]\n",
      "[Epoch 50/150] [D loss: -17.062513] [G loss: -3.853003]\n",
      "[Epoch 51/150] [D loss: -15.799206] [G loss: -4.623381]\n",
      "[Epoch 52/150] [D loss: -16.080143] [G loss: -4.339296]\n",
      "[Epoch 53/150] [D loss: -14.542931] [G loss: -4.718330]\n",
      "[Epoch 54/150] [D loss: -15.172163] [G loss: -4.330243]\n",
      "[Epoch 55/150] [D loss: -13.292169] [G loss: -5.350219]\n",
      "[Epoch 56/150] [D loss: -14.093003] [G loss: -4.965472]\n",
      "[Epoch 57/150] [D loss: -12.297454] [G loss: -5.581772]\n",
      "[Epoch 58/150] [D loss: -12.731334] [G loss: -6.593550]\n",
      "[Epoch 59/150] [D loss: -12.978127] [G loss: -5.412436]\n",
      "[Epoch 60/150] [D loss: -13.205927] [G loss: -6.426604]\n",
      "[Epoch 61/150] [D loss: -12.276740] [G loss: -6.528648]\n",
      "[Epoch 62/150] [D loss: -12.739678] [G loss: -6.643602]\n",
      "[Epoch 63/150] [D loss: -12.088487] [G loss: -6.225081]\n",
      "[Epoch 64/150] [D loss: -11.556226] [G loss: -8.350565]\n",
      "[Epoch 65/150] [D loss: -11.427797] [G loss: -7.268745]\n",
      "[Epoch 66/150] [D loss: -11.377880] [G loss: -6.618864]\n",
      "[Epoch 67/150] [D loss: -9.904276] [G loss: -6.633276]\n",
      "[Epoch 68/150] [D loss: -10.188676] [G loss: -7.930958]\n",
      "[Epoch 69/150] [D loss: -10.413849] [G loss: -6.980104]\n",
      "[Epoch 70/150] [D loss: -9.465093] [G loss: -7.241066]\n",
      "[Epoch 71/150] [D loss: -9.763850] [G loss: -8.665441]\n",
      "[Epoch 72/150] [D loss: -8.110471] [G loss: -8.971100]\n",
      "[Epoch 73/150] [D loss: -8.055660] [G loss: -7.023445]\n",
      "[Epoch 74/150] [D loss: -8.910933] [G loss: -7.124953]\n",
      "[Epoch 75/150] [D loss: -8.758417] [G loss: -7.967709]\n",
      "[Epoch 76/150] [D loss: -7.815054] [G loss: -7.863953]\n",
      "[Epoch 77/150] [D loss: -6.627584] [G loss: -7.701014]\n",
      "[Epoch 78/150] [D loss: -6.898383] [G loss: -7.439159]\n",
      "[Epoch 79/150] [D loss: -7.075900] [G loss: -7.215397]\n",
      "[Epoch 80/150] [D loss: -6.703765] [G loss: -7.143572]\n",
      "[Epoch 81/150] [D loss: -6.482563] [G loss: -7.489778]\n",
      "[Epoch 82/150] [D loss: -5.639708] [G loss: -7.685094]\n",
      "[Epoch 83/150] [D loss: -6.000828] [G loss: -6.791465]\n",
      "[Epoch 84/150] [D loss: -5.102843] [G loss: -7.077603]\n",
      "[Epoch 85/150] [D loss: -4.226592] [G loss: -6.960300]\n",
      "[Epoch 86/150] [D loss: -4.040661] [G loss: -6.240994]\n",
      "[Epoch 87/150] [D loss: -4.050178] [G loss: -6.667247]\n",
      "[Epoch 88/150] [D loss: -4.107738] [G loss: -7.276762]\n",
      "[Epoch 89/150] [D loss: -3.430807] [G loss: -6.014993]\n",
      "[Epoch 90/150] [D loss: -3.664813] [G loss: -6.773616]\n",
      "[Epoch 91/150] [D loss: -3.576769] [G loss: -6.930407]\n",
      "[Epoch 92/150] [D loss: -3.161311] [G loss: -7.057962]\n",
      "[Epoch 93/150] [D loss: -3.468342] [G loss: -6.865861]\n",
      "[Epoch 94/150] [D loss: -3.641289] [G loss: -5.821839]\n",
      "[Epoch 95/150] [D loss: -3.675525] [G loss: -6.173050]\n",
      "[Epoch 96/150] [D loss: -3.338271] [G loss: -6.733519]\n",
      "[Epoch 97/150] [D loss: -3.016216] [G loss: -5.671504]\n",
      "[Epoch 98/150] [D loss: -3.251028] [G loss: -5.903949]\n",
      "[Epoch 99/150] [D loss: -4.065662] [G loss: -5.065228]\n",
      "[Epoch 100/150] [D loss: -3.093105] [G loss: -4.282868]\n",
      "[Epoch 101/150] [D loss: -3.195807] [G loss: -5.411158]\n",
      "[Epoch 102/150] [D loss: -3.292994] [G loss: -5.719626]\n",
      "[Epoch 103/150] [D loss: -2.880271] [G loss: -4.251462]\n",
      "[Epoch 104/150] [D loss: -2.993070] [G loss: -4.129327]\n",
      "[Epoch 105/150] [D loss: -3.159693] [G loss: -4.716148]\n",
      "[Epoch 106/150] [D loss: -3.125872] [G loss: -4.338746]\n",
      "[Epoch 107/150] [D loss: -3.034588] [G loss: -5.841459]\n",
      "[Epoch 108/150] [D loss: -2.741479] [G loss: -6.143118]\n",
      "[Epoch 109/150] [D loss: -2.650192] [G loss: -4.780953]\n",
      "[Epoch 110/150] [D loss: -2.516415] [G loss: -4.522655]\n",
      "[Epoch 111/150] [D loss: -3.070987] [G loss: -3.689774]\n",
      "[Epoch 112/150] [D loss: -2.663165] [G loss: -4.483012]\n",
      "[Epoch 113/150] [D loss: -3.210787] [G loss: -4.373209]\n",
      "[Epoch 114/150] [D loss: -2.877799] [G loss: -5.387708]\n",
      "[Epoch 115/150] [D loss: -3.188340] [G loss: -3.413445]\n",
      "[Epoch 116/150] [D loss: -3.014620] [G loss: -2.287431]\n",
      "[Epoch 117/150] [D loss: -2.988195] [G loss: -2.856085]\n",
      "[Epoch 118/150] [D loss: -3.193887] [G loss: -4.436528]\n",
      "[Epoch 119/150] [D loss: -3.084873] [G loss: -4.026597]\n",
      "[Epoch 120/150] [D loss: -3.029827] [G loss: -3.926580]\n",
      "[Epoch 121/150] [D loss: -2.834004] [G loss: -4.220506]\n",
      "[Epoch 122/150] [D loss: -2.945153] [G loss: -4.836270]\n",
      "[Epoch 123/150] [D loss: -2.874339] [G loss: -4.889503]\n",
      "[Epoch 124/150] [D loss: -2.662179] [G loss: -3.149923]\n",
      "[Epoch 125/150] [D loss: -2.493919] [G loss: -2.401904]\n",
      "[Epoch 126/150] [D loss: -3.062122] [G loss: -3.388492]\n",
      "[Epoch 127/150] [D loss: -2.621547] [G loss: -3.645013]\n",
      "[Epoch 128/150] [D loss: -2.832978] [G loss: -3.750060]\n",
      "[Epoch 129/150] [D loss: -2.984163] [G loss: -3.674417]\n",
      "[Epoch 130/150] [D loss: -2.796170] [G loss: -4.144013]\n",
      "[Epoch 131/150] [D loss: -2.730964] [G loss: -3.379798]\n",
      "[Epoch 132/150] [D loss: -2.754390] [G loss: -2.645707]\n",
      "[Epoch 133/150] [D loss: -2.730763] [G loss: -3.402548]\n",
      "[Epoch 134/150] [D loss: -2.780929] [G loss: -3.772721]\n",
      "[Epoch 135/150] [D loss: -3.092018] [G loss: -3.461716]\n",
      "[Epoch 136/150] [D loss: -2.911525] [G loss: -1.974332]\n",
      "[Epoch 137/150] [D loss: -2.990036] [G loss: -2.949762]\n",
      "[Epoch 138/150] [D loss: -3.101654] [G loss: -3.698247]\n",
      "[Epoch 139/150] [D loss: -2.883965] [G loss: -4.505913]\n",
      "[Epoch 140/150] [D loss: -2.635052] [G loss: -3.152880]\n",
      "[Epoch 141/150] [D loss: -3.002152] [G loss: -2.268130]\n",
      "[Epoch 142/150] [D loss: -3.157858] [G loss: -2.149292]\n",
      "[Epoch 143/150] [D loss: -3.161212] [G loss: -2.851486]\n",
      "[Epoch 144/150] [D loss: -2.928767] [G loss: -2.871578]\n",
      "[Epoch 145/150] [D loss: -2.708595] [G loss: -2.299830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 146/150] [D loss: -2.866333] [G loss: -2.647931]\n",
      "[Epoch 147/150] [D loss: -2.840258] [G loss: -3.156275]\n",
      "[Epoch 148/150] [D loss: -3.056214] [G loss: -3.244450]\n",
      "[Epoch 149/150] [D loss: -2.784029] [G loss: -3.209890]\n",
      "[Epoch 150/150] [D loss: -2.727530] [G loss: -2.559269]\n",
      "Merging dataset Jie (2017) to Other\n",
      "Calculating Anchor Pairs...\n",
      "Calculating Query Pairs...\n",
      "Calculating KNN Pairs...\n",
      "Calculating Random Walk Pairs...\n",
      "Done.\n",
      "[Epoch 1/150] [D loss: 2.689025] [G loss: 0.013690]\n",
      "[Epoch 2/150] [D loss: -3.373254] [G loss: 0.747743]\n",
      "[Epoch 3/150] [D loss: -5.885541] [G loss: 3.773993]\n",
      "[Epoch 4/150] [D loss: -7.500936] [G loss: 5.907306]\n",
      "[Epoch 5/150] [D loss: -8.758796] [G loss: 6.721192]\n",
      "[Epoch 6/150] [D loss: -10.825097] [G loss: 5.680718]\n",
      "[Epoch 7/150] [D loss: -12.718515] [G loss: 5.525244]\n",
      "[Epoch 8/150] [D loss: -16.577427] [G loss: 5.219119]\n",
      "[Epoch 9/150] [D loss: -19.577354] [G loss: 6.464717]\n",
      "[Epoch 10/150] [D loss: -24.283176] [G loss: 6.644366]\n",
      "[Epoch 11/150] [D loss: -23.198650] [G loss: 7.036807]\n",
      "[Epoch 12/150] [D loss: -24.062363] [G loss: 7.035010]\n",
      "[Epoch 13/150] [D loss: -23.124701] [G loss: 6.102982]\n",
      "[Epoch 14/150] [D loss: -22.556662] [G loss: 4.615915]\n",
      "[Epoch 15/150] [D loss: -22.946247] [G loss: 4.355167]\n",
      "[Epoch 16/150] [D loss: -21.720297] [G loss: 5.479631]\n",
      "[Epoch 17/150] [D loss: -22.315214] [G loss: 1.250726]\n",
      "[Epoch 18/150] [D loss: -21.241474] [G loss: 1.088298]\n",
      "[Epoch 19/150] [D loss: -20.513428] [G loss: 0.947682]\n",
      "[Epoch 20/150] [D loss: -21.904409] [G loss: 0.015941]\n",
      "[Epoch 21/150] [D loss: -20.923260] [G loss: -1.938615]\n",
      "[Epoch 22/150] [D loss: -19.021172] [G loss: -0.826315]\n",
      "[Epoch 23/150] [D loss: -18.773886] [G loss: -3.718608]\n",
      "[Epoch 24/150] [D loss: -17.591732] [G loss: -2.558497]\n",
      "[Epoch 25/150] [D loss: -17.138857] [G loss: -3.203746]\n",
      "[Epoch 26/150] [D loss: -16.878860] [G loss: -4.198092]\n",
      "[Epoch 27/150] [D loss: -17.361546] [G loss: -2.268922]\n",
      "[Epoch 28/150] [D loss: -17.349159] [G loss: -3.156418]\n",
      "[Epoch 29/150] [D loss: -15.820607] [G loss: -5.050030]\n",
      "[Epoch 30/150] [D loss: -14.992565] [G loss: -5.055444]\n",
      "[Epoch 31/150] [D loss: -16.016783] [G loss: -4.773407]\n",
      "[Epoch 32/150] [D loss: -15.123011] [G loss: -4.052854]\n",
      "[Epoch 33/150] [D loss: -14.753576] [G loss: -4.530888]\n",
      "[Epoch 34/150] [D loss: -14.874509] [G loss: -4.754541]\n",
      "[Epoch 35/150] [D loss: -13.945354] [G loss: -7.048330]\n",
      "[Epoch 36/150] [D loss: -13.947076] [G loss: -7.231760]\n",
      "[Epoch 37/150] [D loss: -13.510094] [G loss: -5.895313]\n",
      "[Epoch 38/150] [D loss: -12.093403] [G loss: -6.812105]\n",
      "[Epoch 39/150] [D loss: -14.523060] [G loss: -6.956076]\n",
      "[Epoch 40/150] [D loss: -12.734493] [G loss: -8.534157]\n",
      "[Epoch 41/150] [D loss: -12.892544] [G loss: -6.086061]\n",
      "[Epoch 42/150] [D loss: -12.219495] [G loss: -7.261531]\n",
      "[Epoch 43/150] [D loss: -11.626425] [G loss: -6.639503]\n",
      "[Epoch 44/150] [D loss: -11.053576] [G loss: -6.854802]\n",
      "[Epoch 45/150] [D loss: -11.757728] [G loss: -7.894823]\n",
      "[Epoch 46/150] [D loss: -12.420542] [G loss: -7.684551]\n",
      "[Epoch 47/150] [D loss: -11.485751] [G loss: -8.094773]\n",
      "[Epoch 48/150] [D loss: -10.074686] [G loss: -7.929616]\n",
      "[Epoch 49/150] [D loss: -8.971334] [G loss: -7.774903]\n",
      "[Epoch 50/150] [D loss: -8.482275] [G loss: -8.733253]\n",
      "[Epoch 51/150] [D loss: -9.250591] [G loss: -9.462919]\n",
      "[Epoch 52/150] [D loss: -9.783175] [G loss: -7.481041]\n",
      "[Epoch 53/150] [D loss: -9.240051] [G loss: -9.097547]\n",
      "[Epoch 54/150] [D loss: -7.816746] [G loss: -9.792117]\n",
      "[Epoch 55/150] [D loss: -7.869190] [G loss: -8.023455]\n",
      "[Epoch 56/150] [D loss: -8.737431] [G loss: -9.713525]\n",
      "[Epoch 57/150] [D loss: -7.771336] [G loss: -10.431861]\n",
      "[Epoch 58/150] [D loss: -7.083974] [G loss: -9.421001]\n",
      "[Epoch 59/150] [D loss: -7.701457] [G loss: -11.581225]\n",
      "[Epoch 60/150] [D loss: -6.210230] [G loss: -10.826161]\n",
      "[Epoch 61/150] [D loss: -5.729794] [G loss: -11.329501]\n",
      "[Epoch 62/150] [D loss: -6.176904] [G loss: -10.642223]\n",
      "[Epoch 63/150] [D loss: -6.959993] [G loss: -8.681624]\n",
      "[Epoch 64/150] [D loss: -5.134284] [G loss: -10.402602]\n",
      "[Epoch 65/150] [D loss: -5.433266] [G loss: -10.130488]\n",
      "[Epoch 66/150] [D loss: -8.411011] [G loss: -9.562992]\n",
      "[Epoch 67/150] [D loss: -6.211516] [G loss: -9.642438]\n",
      "[Epoch 68/150] [D loss: -7.428746] [G loss: -10.975786]\n",
      "[Epoch 69/150] [D loss: -5.767280] [G loss: -9.054953]\n",
      "[Epoch 70/150] [D loss: -4.751345] [G loss: -11.003584]\n",
      "[Epoch 71/150] [D loss: -5.048652] [G loss: -10.172274]\n",
      "[Epoch 72/150] [D loss: -4.568501] [G loss: -8.753349]\n",
      "[Epoch 73/150] [D loss: -5.487982] [G loss: -7.806326]\n",
      "[Epoch 74/150] [D loss: -5.005100] [G loss: -7.971117]\n",
      "[Epoch 75/150] [D loss: -5.760920] [G loss: -9.659861]\n",
      "[Epoch 76/150] [D loss: -4.255134] [G loss: -7.896657]\n",
      "[Epoch 77/150] [D loss: -3.638198] [G loss: -8.584751]\n",
      "[Epoch 78/150] [D loss: -6.057647] [G loss: -9.287575]\n",
      "[Epoch 79/150] [D loss: -5.033947] [G loss: -9.687051]\n",
      "[Epoch 80/150] [D loss: -4.186092] [G loss: -8.512169]\n",
      "[Epoch 81/150] [D loss: -4.429768] [G loss: -10.067167]\n",
      "[Epoch 82/150] [D loss: -5.882239] [G loss: -7.969678]\n",
      "[Epoch 83/150] [D loss: -4.657124] [G loss: -6.980657]\n",
      "[Epoch 84/150] [D loss: -3.724141] [G loss: -6.424827]\n",
      "[Epoch 85/150] [D loss: -4.682415] [G loss: -8.173817]\n",
      "[Epoch 86/150] [D loss: -4.455292] [G loss: -6.162781]\n",
      "[Epoch 87/150] [D loss: -4.204365] [G loss: -4.190977]\n",
      "[Epoch 88/150] [D loss: -4.872989] [G loss: -3.955709]\n",
      "[Epoch 89/150] [D loss: -4.678488] [G loss: -6.170109]\n",
      "[Epoch 90/150] [D loss: -4.812762] [G loss: -6.025630]\n",
      "[Epoch 91/150] [D loss: -4.177186] [G loss: -4.929523]\n",
      "[Epoch 92/150] [D loss: -4.084735] [G loss: -4.141797]\n",
      "[Epoch 93/150] [D loss: -4.011780] [G loss: -3.540059]\n",
      "[Epoch 94/150] [D loss: -4.882461] [G loss: -5.051155]\n",
      "[Epoch 95/150] [D loss: -4.576138] [G loss: -5.653190]\n",
      "[Epoch 96/150] [D loss: -4.846527] [G loss: -4.618608]\n",
      "[Epoch 97/150] [D loss: -4.906116] [G loss: -3.708666]\n",
      "[Epoch 98/150] [D loss: -4.968020] [G loss: -4.059432]\n",
      "[Epoch 99/150] [D loss: -4.738661] [G loss: -3.657766]\n",
      "[Epoch 100/150] [D loss: -5.018148] [G loss: -2.241158]\n",
      "[Epoch 101/150] [D loss: -5.168283] [G loss: -2.469663]\n",
      "[Epoch 102/150] [D loss: -4.887764] [G loss: -1.965724]\n",
      "[Epoch 103/150] [D loss: -4.603674] [G loss: -2.376052]\n",
      "[Epoch 104/150] [D loss: -4.535716] [G loss: -2.885194]\n",
      "[Epoch 105/150] [D loss: -4.784205] [G loss: -2.739497]\n",
      "[Epoch 106/150] [D loss: -4.675601] [G loss: -2.852083]\n",
      "[Epoch 107/150] [D loss: -3.903099] [G loss: -2.701236]\n",
      "[Epoch 108/150] [D loss: -4.785716] [G loss: -2.354493]\n",
      "[Epoch 109/150] [D loss: -4.284111] [G loss: -2.071813]\n",
      "[Epoch 110/150] [D loss: -4.228847] [G loss: -1.725845]\n",
      "[Epoch 111/150] [D loss: -4.802195] [G loss: -1.779565]\n",
      "[Epoch 112/150] [D loss: -4.282944] [G loss: -1.703614]\n",
      "[Epoch 113/150] [D loss: -4.581584] [G loss: -0.711441]\n",
      "[Epoch 114/150] [D loss: -4.391143] [G loss: 0.028427]\n",
      "[Epoch 115/150] [D loss: -4.397296] [G loss: -0.857699]\n",
      "[Epoch 116/150] [D loss: -5.077376] [G loss: -2.346138]\n",
      "[Epoch 117/150] [D loss: -4.599271] [G loss: -2.521345]\n",
      "[Epoch 118/150] [D loss: -4.986811] [G loss: -2.368850]\n",
      "[Epoch 119/150] [D loss: -5.118474] [G loss: -0.616021]\n",
      "[Epoch 120/150] [D loss: -5.162801] [G loss: -1.329864]\n",
      "[Epoch 121/150] [D loss: -4.822364] [G loss: -3.877588]\n",
      "[Epoch 122/150] [D loss: -5.140594] [G loss: -4.900264]\n",
      "[Epoch 123/150] [D loss: -5.149167] [G loss: -4.504045]\n",
      "[Epoch 124/150] [D loss: -5.141333] [G loss: -3.825119]\n",
      "[Epoch 125/150] [D loss: -5.037958] [G loss: -3.858228]\n",
      "[Epoch 126/150] [D loss: -5.491972] [G loss: -2.829399]\n",
      "[Epoch 127/150] [D loss: -5.079117] [G loss: -2.261085]\n",
      "[Epoch 128/150] [D loss: -5.558999] [G loss: -2.704653]\n",
      "[Epoch 129/150] [D loss: -5.614110] [G loss: -2.785774]\n",
      "[Epoch 130/150] [D loss: -5.170234] [G loss: -2.944881]\n",
      "[Epoch 131/150] [D loss: -5.634927] [G loss: -2.792290]\n",
      "[Epoch 132/150] [D loss: -5.778220] [G loss: -3.721105]\n",
      "[Epoch 133/150] [D loss: -5.229446] [G loss: -3.890025]\n",
      "[Epoch 134/150] [D loss: -5.409968] [G loss: -3.064921]\n",
      "[Epoch 135/150] [D loss: -5.052052] [G loss: -3.207609]\n",
      "[Epoch 136/150] [D loss: -5.250368] [G loss: -1.779937]\n",
      "[Epoch 137/150] [D loss: -5.322346] [G loss: -1.526055]\n",
      "[Epoch 138/150] [D loss: -5.158592] [G loss: -2.578881]\n",
      "[Epoch 139/150] [D loss: -5.805165] [G loss: -3.737591]\n",
      "[Epoch 140/150] [D loss: -5.418081] [G loss: -3.207823]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 141/150] [D loss: -4.905488] [G loss: -1.503639]\n",
      "[Epoch 142/150] [D loss: -5.471201] [G loss: -1.469045]\n",
      "[Epoch 143/150] [D loss: -6.076669] [G loss: -1.459521]\n",
      "[Epoch 144/150] [D loss: -5.422449] [G loss: -2.708526]\n",
      "[Epoch 145/150] [D loss: -5.371319] [G loss: -3.036574]\n",
      "[Epoch 146/150] [D loss: -5.499758] [G loss: -2.813015]\n",
      "[Epoch 147/150] [D loss: -5.046124] [G loss: -1.811972]\n",
      "[Epoch 148/150] [D loss: -5.286959] [G loss: -0.432054]\n",
      "[Epoch 149/150] [D loss: -5.205064] [G loss: 0.267814]\n",
      "[Epoch 150/150] [D loss: -4.561729] [G loss: -1.244957]\n",
      "Merging dataset Zhang (2015) to Other\n",
      "Calculating Anchor Pairs...\n",
      "Calculating Query Pairs...\n",
      "Calculating KNN Pairs...\n",
      "Calculating Random Walk Pairs...\n",
      "Done.\n",
      "[Epoch 1/150] [D loss: 2.334821] [G loss: -0.021755]\n",
      "[Epoch 2/150] [D loss: -3.830316] [G loss: 0.740123]\n",
      "[Epoch 3/150] [D loss: -6.736512] [G loss: 4.098629]\n",
      "[Epoch 4/150] [D loss: -8.365829] [G loss: 6.550574]\n",
      "[Epoch 5/150] [D loss: -10.246868] [G loss: 6.995980]\n",
      "[Epoch 6/150] [D loss: -11.921333] [G loss: 6.296370]\n",
      "[Epoch 7/150] [D loss: -14.094627] [G loss: 5.878651]\n",
      "[Epoch 8/150] [D loss: -18.354593] [G loss: 5.444755]\n",
      "[Epoch 9/150] [D loss: -20.479855] [G loss: 5.417787]\n",
      "[Epoch 10/150] [D loss: -23.461306] [G loss: 4.797004]\n",
      "[Epoch 11/150] [D loss: -25.107880] [G loss: 3.219070]\n",
      "[Epoch 12/150] [D loss: -23.829201] [G loss: 3.642277]\n",
      "[Epoch 13/150] [D loss: -24.415894] [G loss: 1.723898]\n",
      "[Epoch 14/150] [D loss: -22.191414] [G loss: 0.014510]\n",
      "[Epoch 15/150] [D loss: -23.389116] [G loss: -0.428978]\n",
      "[Epoch 16/150] [D loss: -23.176216] [G loss: -2.283434]\n",
      "[Epoch 17/150] [D loss: -22.270590] [G loss: -2.712157]\n",
      "[Epoch 18/150] [D loss: -21.533630] [G loss: -4.285964]\n",
      "[Epoch 19/150] [D loss: -20.331360] [G loss: -4.570876]\n",
      "[Epoch 20/150] [D loss: -18.940155] [G loss: -6.292758]\n",
      "[Epoch 21/150] [D loss: -18.819023] [G loss: -5.811253]\n",
      "[Epoch 22/150] [D loss: -20.886686] [G loss: -6.625795]\n",
      "[Epoch 23/150] [D loss: -18.704527] [G loss: -6.321366]\n",
      "[Epoch 24/150] [D loss: -18.814976] [G loss: -8.971257]\n",
      "[Epoch 25/150] [D loss: -17.756338] [G loss: -8.284227]\n",
      "[Epoch 26/150] [D loss: -17.209623] [G loss: -7.013935]\n",
      "[Epoch 27/150] [D loss: -16.852371] [G loss: -10.652926]\n",
      "[Epoch 28/150] [D loss: -17.056578] [G loss: -9.363671]\n",
      "[Epoch 29/150] [D loss: -15.336983] [G loss: -10.245501]\n",
      "[Epoch 30/150] [D loss: -15.858793] [G loss: -10.233702]\n",
      "[Epoch 31/150] [D loss: -15.396418] [G loss: -10.236230]\n",
      "[Epoch 32/150] [D loss: -16.331194] [G loss: -11.978577]\n",
      "[Epoch 33/150] [D loss: -14.500198] [G loss: -12.380179]\n",
      "[Epoch 34/150] [D loss: -13.617129] [G loss: -11.904808]\n",
      "[Epoch 35/150] [D loss: -13.939611] [G loss: -11.940391]\n",
      "[Epoch 36/150] [D loss: -12.975975] [G loss: -13.225860]\n",
      "[Epoch 37/150] [D loss: -13.244998] [G loss: -13.443329]\n",
      "[Epoch 38/150] [D loss: -12.333176] [G loss: -15.061395]\n",
      "[Epoch 39/150] [D loss: -12.384054] [G loss: -14.012477]\n",
      "[Epoch 40/150] [D loss: -10.752940] [G loss: -14.810345]\n",
      "[Epoch 41/150] [D loss: -11.616220] [G loss: -16.481104]\n",
      "[Epoch 42/150] [D loss: -10.544077] [G loss: -15.774715]\n",
      "[Epoch 43/150] [D loss: -9.536289] [G loss: -16.140209]\n",
      "[Epoch 44/150] [D loss: -11.324105] [G loss: -17.890488]\n",
      "[Epoch 45/150] [D loss: -10.544121] [G loss: -16.414024]\n",
      "[Epoch 46/150] [D loss: -8.812979] [G loss: -16.416954]\n",
      "[Epoch 47/150] [D loss: -9.318263] [G loss: -17.098480]\n",
      "[Epoch 48/150] [D loss: -9.721287] [G loss: -17.382053]\n",
      "[Epoch 49/150] [D loss: -8.677264] [G loss: -16.372623]\n",
      "[Epoch 50/150] [D loss: -8.394892] [G loss: -17.020473]\n",
      "[Epoch 51/150] [D loss: -10.167238] [G loss: -18.791824]\n",
      "[Epoch 52/150] [D loss: -7.757315] [G loss: -17.474970]\n",
      "[Epoch 53/150] [D loss: -7.979496] [G loss: -16.704826]\n",
      "[Epoch 54/150] [D loss: -8.037707] [G loss: -17.098484]\n",
      "[Epoch 55/150] [D loss: -8.177493] [G loss: -16.507847]\n",
      "[Epoch 56/150] [D loss: -7.913647] [G loss: -16.972076]\n",
      "[Epoch 57/150] [D loss: -7.611551] [G loss: -15.765100]\n",
      "[Epoch 58/150] [D loss: -7.930921] [G loss: -17.205889]\n",
      "[Epoch 59/150] [D loss: -8.362013] [G loss: -18.027273]\n",
      "[Epoch 60/150] [D loss: -7.258453] [G loss: -17.941128]\n",
      "[Epoch 61/150] [D loss: -7.171277] [G loss: -15.813185]\n",
      "[Epoch 62/150] [D loss: -6.819122] [G loss: -16.113350]\n",
      "[Epoch 63/150] [D loss: -7.190537] [G loss: -17.610210]\n",
      "[Epoch 64/150] [D loss: -5.783563] [G loss: -16.344339]\n",
      "[Epoch 65/150] [D loss: -6.574205] [G loss: -15.304956]\n",
      "[Epoch 66/150] [D loss: -6.818808] [G loss: -16.567829]\n",
      "[Epoch 67/150] [D loss: -6.430204] [G loss: -16.208933]\n",
      "[Epoch 68/150] [D loss: -6.489669] [G loss: -16.767035]\n",
      "[Epoch 69/150] [D loss: -7.299265] [G loss: -15.928151]\n",
      "[Epoch 70/150] [D loss: -5.324800] [G loss: -14.687346]\n",
      "[Epoch 71/150] [D loss: -6.359402] [G loss: -15.724097]\n",
      "[Epoch 72/150] [D loss: -6.676598] [G loss: -15.585986]\n",
      "[Epoch 73/150] [D loss: -6.296499] [G loss: -14.961046]\n",
      "[Epoch 74/150] [D loss: -4.992958] [G loss: -15.115371]\n",
      "[Epoch 75/150] [D loss: -6.236264] [G loss: -13.546160]\n",
      "[Epoch 76/150] [D loss: -5.608094] [G loss: -14.087201]\n",
      "[Epoch 77/150] [D loss: -6.255883] [G loss: -13.426682]\n",
      "[Epoch 78/150] [D loss: -5.880820] [G loss: -14.246174]\n",
      "[Epoch 79/150] [D loss: -5.912214] [G loss: -12.065299]\n",
      "[Epoch 80/150] [D loss: -5.326500] [G loss: -11.757275]\n",
      "[Epoch 81/150] [D loss: -5.105968] [G loss: -12.081167]\n",
      "[Epoch 82/150] [D loss: -6.621961] [G loss: -12.040129]\n",
      "[Epoch 83/150] [D loss: -5.081360] [G loss: -10.980882]\n",
      "[Epoch 84/150] [D loss: -5.182242] [G loss: -11.158588]\n",
      "[Epoch 85/150] [D loss: -5.334716] [G loss: -12.056326]\n",
      "[Epoch 86/150] [D loss: -4.284117] [G loss: -10.472771]\n",
      "[Epoch 87/150] [D loss: -4.212797] [G loss: -10.918391]\n",
      "[Epoch 88/150] [D loss: -4.690081] [G loss: -10.836823]\n",
      "[Epoch 89/150] [D loss: -4.613966] [G loss: -11.385293]\n",
      "[Epoch 90/150] [D loss: -3.712974] [G loss: -11.672142]\n",
      "[Epoch 91/150] [D loss: -4.215152] [G loss: -9.357252]\n",
      "[Epoch 92/150] [D loss: -4.452698] [G loss: -9.096580]\n",
      "[Epoch 93/150] [D loss: -4.606593] [G loss: -7.803800]\n",
      "[Epoch 94/150] [D loss: -4.106335] [G loss: -7.811177]\n",
      "[Epoch 95/150] [D loss: -4.663804] [G loss: -7.193846]\n",
      "[Epoch 96/150] [D loss: -4.522736] [G loss: -6.694998]\n",
      "[Epoch 97/150] [D loss: -4.621337] [G loss: -5.986117]\n",
      "[Epoch 98/150] [D loss: -4.554184] [G loss: -8.044423]\n",
      "[Epoch 99/150] [D loss: -4.509577] [G loss: -6.581468]\n",
      "[Epoch 100/150] [D loss: -4.281832] [G loss: -5.889840]\n",
      "[Epoch 101/150] [D loss: -4.354193] [G loss: -6.198586]\n",
      "[Epoch 102/150] [D loss: -4.235459] [G loss: -4.317665]\n",
      "[Epoch 103/150] [D loss: -4.429917] [G loss: -3.586285]\n",
      "[Epoch 104/150] [D loss: -4.652110] [G loss: -4.037544]\n",
      "[Epoch 105/150] [D loss: -4.763363] [G loss: -5.621166]\n",
      "[Epoch 106/150] [D loss: -4.274603] [G loss: -4.570242]\n",
      "[Epoch 107/150] [D loss: -4.827687] [G loss: -4.594848]\n",
      "[Epoch 108/150] [D loss: -4.665729] [G loss: -2.718199]\n",
      "[Epoch 109/150] [D loss: -4.816369] [G loss: -2.659013]\n",
      "[Epoch 110/150] [D loss: -4.969325] [G loss: -3.088959]\n",
      "[Epoch 111/150] [D loss: -4.651455] [G loss: -3.550712]\n",
      "[Epoch 112/150] [D loss: -4.706784] [G loss: -2.661056]\n",
      "[Epoch 113/150] [D loss: -4.633257] [G loss: -1.297962]\n",
      "[Epoch 114/150] [D loss: -4.569620] [G loss: -1.467444]\n",
      "[Epoch 115/150] [D loss: -4.943686] [G loss: -3.375024]\n",
      "[Epoch 116/150] [D loss: -4.479376] [G loss: -2.380262]\n",
      "[Epoch 117/150] [D loss: -4.788126] [G loss: -3.711212]\n",
      "[Epoch 118/150] [D loss: -5.261576] [G loss: -2.090153]\n",
      "[Epoch 119/150] [D loss: -4.834439] [G loss: -1.606548]\n",
      "[Epoch 120/150] [D loss: -5.170127] [G loss: -1.825460]\n",
      "[Epoch 121/150] [D loss: -4.924187] [G loss: -3.150211]\n",
      "[Epoch 122/150] [D loss: -4.826977] [G loss: -3.117962]\n",
      "[Epoch 123/150] [D loss: -4.801471] [G loss: -3.184682]\n",
      "[Epoch 124/150] [D loss: -5.041052] [G loss: -1.471908]\n",
      "[Epoch 125/150] [D loss: -5.025535] [G loss: -3.037056]\n",
      "[Epoch 126/150] [D loss: -4.837263] [G loss: -3.056924]\n",
      "[Epoch 127/150] [D loss: -5.124594] [G loss: -4.010788]\n",
      "[Epoch 128/150] [D loss: -4.769396] [G loss: -1.970964]\n",
      "[Epoch 129/150] [D loss: -4.964653] [G loss: -1.822335]\n",
      "[Epoch 130/150] [D loss: -4.946534] [G loss: 0.393825]\n",
      "[Epoch 131/150] [D loss: -5.015132] [G loss: -0.393317]\n",
      "[Epoch 132/150] [D loss: -5.215001] [G loss: -1.494666]\n",
      "[Epoch 133/150] [D loss: -4.565912] [G loss: -1.375793]\n",
      "[Epoch 134/150] [D loss: -4.945991] [G loss: -2.704773]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 135/150] [D loss: -5.077820] [G loss: -2.774669]\n",
      "[Epoch 136/150] [D loss: -5.040736] [G loss: -3.120801]\n",
      "[Epoch 137/150] [D loss: -4.679348] [G loss: -3.787840]\n",
      "[Epoch 138/150] [D loss: -5.269039] [G loss: -3.827911]\n",
      "[Epoch 139/150] [D loss: -5.338739] [G loss: -2.537917]\n",
      "[Epoch 140/150] [D loss: -5.003823] [G loss: -2.842631]\n",
      "[Epoch 141/150] [D loss: -4.865599] [G loss: -1.737848]\n",
      "[Epoch 142/150] [D loss: -5.049326] [G loss: -2.444032]\n",
      "[Epoch 143/150] [D loss: -5.128186] [G loss: -3.469351]\n",
      "[Epoch 144/150] [D loss: -5.009744] [G loss: -2.283162]\n",
      "[Epoch 145/150] [D loss: -4.946242] [G loss: -2.638453]\n",
      "[Epoch 146/150] [D loss: -5.021830] [G loss: -3.847171]\n",
      "[Epoch 147/150] [D loss: -5.559969] [G loss: -2.009144]\n",
      "[Epoch 148/150] [D loss: -5.268880] [G loss: -1.509955]\n",
      "[Epoch 149/150] [D loss: -5.335052] [G loss: -1.712147]\n",
      "[Epoch 150/150] [D loss: -5.200483] [G loss: -0.896362]\n",
      "Merging dataset Feng (2015) to Other\n",
      "Calculating Anchor Pairs...\n",
      "Calculating Query Pairs...\n",
      "Calculating KNN Pairs...\n",
      "Calculating Random Walk Pairs...\n",
      "Done.\n",
      "[Epoch 1/150] [D loss: 2.653532] [G loss: 0.018426]\n",
      "[Epoch 2/150] [D loss: -4.692192] [G loss: 1.174136]\n",
      "[Epoch 3/150] [D loss: -8.430017] [G loss: 5.326532]\n",
      "[Epoch 4/150] [D loss: -11.490133] [G loss: 8.565311]\n",
      "[Epoch 5/150] [D loss: -14.395700] [G loss: 9.810848]\n",
      "[Epoch 6/150] [D loss: -17.272034] [G loss: 9.395624]\n",
      "[Epoch 7/150] [D loss: -20.516348] [G loss: 10.142797]\n",
      "[Epoch 8/150] [D loss: -23.349524] [G loss: 11.450392]\n",
      "[Epoch 9/150] [D loss: -26.425249] [G loss: 12.309886]\n",
      "[Epoch 10/150] [D loss: -27.797916] [G loss: 10.258717]\n",
      "[Epoch 11/150] [D loss: -29.543251] [G loss: 12.673466]\n",
      "[Epoch 12/150] [D loss: -30.693615] [G loss: 11.577271]\n",
      "[Epoch 13/150] [D loss: -30.554657] [G loss: 10.307774]\n",
      "[Epoch 14/150] [D loss: -30.237570] [G loss: 9.660828]\n",
      "[Epoch 15/150] [D loss: -27.758005] [G loss: 11.116099]\n",
      "[Epoch 16/150] [D loss: -28.454197] [G loss: 9.304721]\n",
      "[Epoch 17/150] [D loss: -27.339077] [G loss: 8.994450]\n",
      "[Epoch 18/150] [D loss: -26.356270] [G loss: 7.166522]\n",
      "[Epoch 19/150] [D loss: -25.346331] [G loss: 7.354926]\n",
      "[Epoch 20/150] [D loss: -25.685474] [G loss: 5.279667]\n",
      "[Epoch 21/150] [D loss: -25.527321] [G loss: 5.339372]\n",
      "[Epoch 22/150] [D loss: -25.476559] [G loss: 5.605538]\n",
      "[Epoch 23/150] [D loss: -26.292477] [G loss: 5.556066]\n",
      "[Epoch 24/150] [D loss: -25.630867] [G loss: 5.247135]\n",
      "[Epoch 25/150] [D loss: -24.756279] [G loss: 5.806494]\n",
      "[Epoch 26/150] [D loss: -23.755064] [G loss: 5.319786]\n",
      "[Epoch 27/150] [D loss: -22.959677] [G loss: 5.258614]\n",
      "[Epoch 28/150] [D loss: -23.465292] [G loss: 4.158418]\n",
      "[Epoch 29/150] [D loss: -24.378033] [G loss: 3.434227]\n",
      "[Epoch 30/150] [D loss: -22.295891] [G loss: 2.683906]\n",
      "[Epoch 31/150] [D loss: -22.017712] [G loss: 3.636254]\n",
      "[Epoch 32/150] [D loss: -22.551615] [G loss: 3.195328]\n",
      "[Epoch 33/150] [D loss: -21.531013] [G loss: 2.716371]\n",
      "[Epoch 34/150] [D loss: -21.140911] [G loss: 1.830023]\n",
      "[Epoch 35/150] [D loss: -20.898569] [G loss: 1.994926]\n",
      "[Epoch 36/150] [D loss: -21.349974] [G loss: 0.284291]\n",
      "[Epoch 37/150] [D loss: -20.750748] [G loss: 0.698314]\n",
      "[Epoch 38/150] [D loss: -20.120880] [G loss: 0.528496]\n",
      "[Epoch 39/150] [D loss: -20.021948] [G loss: -0.316315]\n",
      "[Epoch 40/150] [D loss: -19.331291] [G loss: 0.043912]\n",
      "[Epoch 41/150] [D loss: -19.490530] [G loss: -0.178959]\n",
      "[Epoch 42/150] [D loss: -17.928755] [G loss: 0.092896]\n",
      "[Epoch 43/150] [D loss: -17.824780] [G loss: -1.169831]\n",
      "[Epoch 44/150] [D loss: -18.429222] [G loss: -0.423235]\n",
      "[Epoch 45/150] [D loss: -17.935913] [G loss: -1.739933]\n",
      "[Epoch 46/150] [D loss: -17.767855] [G loss: -2.249087]\n",
      "[Epoch 47/150] [D loss: -18.586540] [G loss: -1.831804]\n",
      "[Epoch 48/150] [D loss: -17.363987] [G loss: -1.888466]\n",
      "[Epoch 49/150] [D loss: -16.880129] [G loss: -1.278135]\n",
      "[Epoch 50/150] [D loss: -17.654381] [G loss: -0.843557]\n",
      "[Epoch 51/150] [D loss: -17.657660] [G loss: -2.231257]\n",
      "[Epoch 52/150] [D loss: -17.279348] [G loss: -2.059402]\n",
      "[Epoch 53/150] [D loss: -17.738564] [G loss: -2.000254]\n",
      "[Epoch 54/150] [D loss: -17.347507] [G loss: -2.835247]\n",
      "[Epoch 55/150] [D loss: -14.736605] [G loss: -2.829904]\n",
      "[Epoch 56/150] [D loss: -15.850353] [G loss: -3.139267]\n",
      "[Epoch 57/150] [D loss: -15.422587] [G loss: -3.622022]\n",
      "[Epoch 58/150] [D loss: -16.058155] [G loss: -1.951519]\n",
      "[Epoch 59/150] [D loss: -16.368683] [G loss: -2.892225]\n",
      "[Epoch 60/150] [D loss: -12.941546] [G loss: -2.932031]\n",
      "[Epoch 61/150] [D loss: -16.041224] [G loss: -3.818819]\n",
      "[Epoch 62/150] [D loss: -14.397036] [G loss: -2.922436]\n",
      "[Epoch 63/150] [D loss: -14.295547] [G loss: -2.208711]\n",
      "[Epoch 64/150] [D loss: -14.902997] [G loss: -3.517948]\n",
      "[Epoch 65/150] [D loss: -12.060284] [G loss: -2.992296]\n",
      "[Epoch 66/150] [D loss: -13.467538] [G loss: -2.803593]\n",
      "[Epoch 67/150] [D loss: -13.100420] [G loss: -1.439345]\n",
      "[Epoch 68/150] [D loss: -13.557751] [G loss: -2.410973]\n",
      "[Epoch 69/150] [D loss: -13.444831] [G loss: -3.435682]\n",
      "[Epoch 70/150] [D loss: -13.823063] [G loss: -3.455414]\n",
      "[Epoch 71/150] [D loss: -15.212081] [G loss: -2.552446]\n",
      "[Epoch 72/150] [D loss: -13.837873] [G loss: -3.379413]\n",
      "[Epoch 73/150] [D loss: -12.585050] [G loss: -1.971179]\n",
      "[Epoch 74/150] [D loss: -13.390045] [G loss: -3.702950]\n",
      "[Epoch 75/150] [D loss: -12.904972] [G loss: -3.953034]\n",
      "[Epoch 76/150] [D loss: -12.668082] [G loss: -4.852820]\n",
      "[Epoch 77/150] [D loss: -12.657353] [G loss: -3.105678]\n",
      "[Epoch 78/150] [D loss: -13.413350] [G loss: -3.467375]\n",
      "[Epoch 79/150] [D loss: -12.151855] [G loss: -3.376062]\n",
      "[Epoch 80/150] [D loss: -10.068439] [G loss: -3.394899]\n",
      "[Epoch 81/150] [D loss: -10.927761] [G loss: -1.800027]\n",
      "[Epoch 82/150] [D loss: -11.461704] [G loss: -2.536191]\n",
      "[Epoch 83/150] [D loss: -12.023229] [G loss: -1.690895]\n",
      "[Epoch 84/150] [D loss: -11.967700] [G loss: -3.689432]\n",
      "[Epoch 85/150] [D loss: -10.735956] [G loss: -2.267905]\n",
      "[Epoch 86/150] [D loss: -10.071815] [G loss: -2.103874]\n",
      "[Epoch 87/150] [D loss: -10.288692] [G loss: -2.479469]\n",
      "[Epoch 88/150] [D loss: -10.776474] [G loss: -2.166230]\n",
      "[Epoch 89/150] [D loss: -11.653728] [G loss: -2.648027]\n",
      "[Epoch 90/150] [D loss: -10.101040] [G loss: -2.415811]\n",
      "[Epoch 91/150] [D loss: -10.506130] [G loss: -3.096204]\n",
      "[Epoch 92/150] [D loss: -9.927204] [G loss: -2.242548]\n",
      "[Epoch 93/150] [D loss: -9.768656] [G loss: -0.893021]\n",
      "[Epoch 94/150] [D loss: -9.777442] [G loss: -3.123725]\n",
      "[Epoch 95/150] [D loss: -10.942180] [G loss: -1.855039]\n",
      "[Epoch 96/150] [D loss: -10.515919] [G loss: -0.813380]\n",
      "[Epoch 97/150] [D loss: -9.156504] [G loss: -2.424365]\n",
      "[Epoch 98/150] [D loss: -8.988972] [G loss: -2.084590]\n",
      "[Epoch 99/150] [D loss: -10.636620] [G loss: -1.536721]\n",
      "[Epoch 100/150] [D loss: -9.699657] [G loss: -2.206223]\n",
      "[Epoch 101/150] [D loss: -10.020820] [G loss: -2.104113]\n",
      "[Epoch 102/150] [D loss: -9.655146] [G loss: -4.601311]\n",
      "[Epoch 103/150] [D loss: -9.833050] [G loss: -2.712590]\n",
      "[Epoch 104/150] [D loss: -8.974297] [G loss: -3.188881]\n",
      "[Epoch 105/150] [D loss: -10.655981] [G loss: -2.454536]\n",
      "[Epoch 106/150] [D loss: -9.198275] [G loss: -3.302646]\n",
      "[Epoch 107/150] [D loss: -9.987520] [G loss: -3.323943]\n",
      "[Epoch 108/150] [D loss: -9.036375] [G loss: -2.014904]\n",
      "[Epoch 109/150] [D loss: -8.483269] [G loss: -3.258360]\n",
      "[Epoch 110/150] [D loss: -9.219448] [G loss: -4.620835]\n",
      "[Epoch 111/150] [D loss: -9.100824] [G loss: -6.444458]\n",
      "[Epoch 112/150] [D loss: -9.153004] [G loss: -5.797980]\n",
      "[Epoch 113/150] [D loss: -8.710352] [G loss: -5.641394]\n",
      "[Epoch 114/150] [D loss: -10.305336] [G loss: -7.636516]\n",
      "[Epoch 115/150] [D loss: -7.654239] [G loss: -6.723690]\n",
      "[Epoch 116/150] [D loss: -7.222885] [G loss: -8.336191]\n",
      "[Epoch 117/150] [D loss: -8.593801] [G loss: -9.092706]\n",
      "[Epoch 118/150] [D loss: -7.945636] [G loss: -8.794704]\n",
      "[Epoch 119/150] [D loss: -7.823678] [G loss: -9.053603]\n",
      "[Epoch 120/150] [D loss: -7.476665] [G loss: -9.110534]\n",
      "[Epoch 121/150] [D loss: -7.757765] [G loss: -9.414046]\n",
      "[Epoch 122/150] [D loss: -8.843220] [G loss: -9.192885]\n",
      "[Epoch 123/150] [D loss: -8.381689] [G loss: -9.051063]\n",
      "[Epoch 124/150] [D loss: -8.491458] [G loss: -9.705105]\n",
      "[Epoch 125/150] [D loss: -7.443604] [G loss: -8.940272]\n",
      "[Epoch 126/150] [D loss: -7.455347] [G loss: -9.328467]\n",
      "[Epoch 127/150] [D loss: -7.687522] [G loss: -7.105594]\n",
      "[Epoch 128/150] [D loss: -7.471526] [G loss: -7.759059]\n",
      "[Epoch 129/150] [D loss: -6.602422] [G loss: -7.338635]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 130/150] [D loss: -6.600838] [G loss: -6.963813]\n",
      "[Epoch 131/150] [D loss: -6.421518] [G loss: -8.650974]\n",
      "[Epoch 132/150] [D loss: -5.956381] [G loss: -8.904876]\n",
      "[Epoch 133/150] [D loss: -6.082608] [G loss: -9.420974]\n",
      "[Epoch 134/150] [D loss: -5.569641] [G loss: -9.761418]\n",
      "[Epoch 135/150] [D loss: -4.801637] [G loss: -8.517113]\n",
      "[Epoch 136/150] [D loss: -4.965639] [G loss: -8.964037]\n",
      "[Epoch 137/150] [D loss: -5.450614] [G loss: -8.043010]\n",
      "[Epoch 138/150] [D loss: -4.392063] [G loss: -8.361324]\n",
      "[Epoch 139/150] [D loss: -4.942701] [G loss: -7.576364]\n",
      "[Epoch 140/150] [D loss: -4.114256] [G loss: -6.028533]\n",
      "[Epoch 141/150] [D loss: -4.337460] [G loss: -4.477823]\n",
      "[Epoch 142/150] [D loss: -4.427132] [G loss: -5.862222]\n",
      "[Epoch 143/150] [D loss: -4.237522] [G loss: -5.386871]\n",
      "[Epoch 144/150] [D loss: -4.410846] [G loss: -5.443810]\n",
      "[Epoch 145/150] [D loss: -3.914043] [G loss: -7.022650]\n",
      "[Epoch 146/150] [D loss: -4.435160] [G loss: -5.475119]\n",
      "[Epoch 147/150] [D loss: -4.096092] [G loss: -3.929987]\n",
      "[Epoch 148/150] [D loss: -4.393763] [G loss: -3.778356]\n",
      "[Epoch 149/150] [D loss: -4.336385] [G loss: -5.798058]\n",
      "[Epoch 150/150] [D loss: -4.556984] [G loss: -5.075275]\n",
      "Merging dataset Nielsen (2014) to Other\n",
      "Calculating Anchor Pairs...\n",
      "Calculating Query Pairs...\n",
      "Calculating KNN Pairs...\n",
      "Calculating Random Walk Pairs...\n",
      "Done.\n",
      "[Epoch 1/150] [D loss: 2.775610] [G loss: 0.100041]\n",
      "[Epoch 2/150] [D loss: -4.284824] [G loss: 1.100644]\n",
      "[Epoch 3/150] [D loss: -7.619068] [G loss: 4.839657]\n",
      "[Epoch 4/150] [D loss: -10.546782] [G loss: 7.446707]\n",
      "[Epoch 5/150] [D loss: -12.827682] [G loss: 8.231356]\n",
      "[Epoch 6/150] [D loss: -15.978064] [G loss: 8.004731]\n",
      "[Epoch 7/150] [D loss: -20.998035] [G loss: 9.114017]\n",
      "[Epoch 8/150] [D loss: -26.215052] [G loss: 8.999962]\n",
      "[Epoch 9/150] [D loss: -28.513695] [G loss: 9.774856]\n",
      "[Epoch 10/150] [D loss: -29.980249] [G loss: 10.314249]\n",
      "[Epoch 11/150] [D loss: -32.269722] [G loss: 10.273997]\n",
      "[Epoch 12/150] [D loss: -31.067574] [G loss: 8.443027]\n",
      "[Epoch 13/150] [D loss: -30.259541] [G loss: 7.465610]\n",
      "[Epoch 14/150] [D loss: -28.987816] [G loss: 6.422082]\n",
      "[Epoch 15/150] [D loss: -27.616844] [G loss: 3.438926]\n",
      "[Epoch 16/150] [D loss: -26.138639] [G loss: 3.979230]\n",
      "[Epoch 17/150] [D loss: -28.615276] [G loss: 2.090851]\n",
      "[Epoch 18/150] [D loss: -26.628216] [G loss: 2.278275]\n",
      "[Epoch 19/150] [D loss: -24.383015] [G loss: 1.683922]\n",
      "[Epoch 20/150] [D loss: -24.996201] [G loss: 0.278933]\n",
      "[Epoch 21/150] [D loss: -24.680809] [G loss: -0.779868]\n",
      "[Epoch 22/150] [D loss: -22.479277] [G loss: -1.310831]\n",
      "[Epoch 23/150] [D loss: -23.079454] [G loss: -1.459959]\n",
      "[Epoch 24/150] [D loss: -24.464260] [G loss: -3.586200]\n",
      "[Epoch 25/150] [D loss: -23.435808] [G loss: -2.898910]\n",
      "[Epoch 26/150] [D loss: -23.127213] [G loss: -4.091088]\n",
      "[Epoch 27/150] [D loss: -22.201532] [G loss: -0.585000]\n",
      "[Epoch 28/150] [D loss: -22.415220] [G loss: -3.848956]\n",
      "[Epoch 29/150] [D loss: -20.877476] [G loss: -3.327440]\n",
      "[Epoch 30/150] [D loss: -20.828524] [G loss: -4.155757]\n",
      "[Epoch 31/150] [D loss: -20.825119] [G loss: -4.845235]\n",
      "[Epoch 32/150] [D loss: -19.823181] [G loss: -4.221646]\n",
      "[Epoch 33/150] [D loss: -19.498180] [G loss: -5.539399]\n",
      "[Epoch 34/150] [D loss: -20.400795] [G loss: -5.587445]\n",
      "[Epoch 35/150] [D loss: -17.716425] [G loss: -7.659651]\n",
      "[Epoch 36/150] [D loss: -20.545973] [G loss: -9.093796]\n",
      "[Epoch 37/150] [D loss: -17.843060] [G loss: -7.923871]\n",
      "[Epoch 38/150] [D loss: -16.409887] [G loss: -8.893229]\n",
      "[Epoch 39/150] [D loss: -14.833078] [G loss: -7.996777]\n",
      "[Epoch 40/150] [D loss: -15.256231] [G loss: -8.600398]\n",
      "[Epoch 41/150] [D loss: -15.734969] [G loss: -9.050067]\n",
      "[Epoch 42/150] [D loss: -13.740829] [G loss: -8.018637]\n",
      "[Epoch 43/150] [D loss: -14.739350] [G loss: -7.416667]\n",
      "[Epoch 44/150] [D loss: -14.145290] [G loss: -9.431433]\n",
      "[Epoch 45/150] [D loss: -12.583405] [G loss: -10.784303]\n",
      "[Epoch 46/150] [D loss: -13.500141] [G loss: -9.745734]\n",
      "[Epoch 47/150] [D loss: -11.219998] [G loss: -11.046518]\n",
      "[Epoch 48/150] [D loss: -12.239319] [G loss: -11.436307]\n",
      "[Epoch 49/150] [D loss: -10.524349] [G loss: -10.316178]\n",
      "[Epoch 50/150] [D loss: -11.363043] [G loss: -12.486341]\n",
      "[Epoch 51/150] [D loss: -11.003114] [G loss: -10.986581]\n",
      "[Epoch 52/150] [D loss: -9.508634] [G loss: -10.833232]\n",
      "[Epoch 53/150] [D loss: -9.589560] [G loss: -12.172733]\n",
      "[Epoch 54/150] [D loss: -8.845239] [G loss: -11.590172]\n",
      "[Epoch 55/150] [D loss: -7.125237] [G loss: -11.268790]\n",
      "[Epoch 56/150] [D loss: -8.536434] [G loss: -12.004313]\n",
      "[Epoch 57/150] [D loss: -7.842649] [G loss: -12.142755]\n",
      "[Epoch 58/150] [D loss: -7.141031] [G loss: -12.542577]\n",
      "[Epoch 59/150] [D loss: -8.151984] [G loss: -11.041823]\n",
      "[Epoch 60/150] [D loss: -5.895903] [G loss: -10.403790]\n",
      "[Epoch 61/150] [D loss: -5.803563] [G loss: -13.096777]\n",
      "[Epoch 62/150] [D loss: -6.686830] [G loss: -11.743358]\n",
      "[Epoch 63/150] [D loss: -7.327288] [G loss: -10.971938]\n",
      "[Epoch 64/150] [D loss: -5.527859] [G loss: -12.316984]\n",
      "[Epoch 65/150] [D loss: -5.008423] [G loss: -13.673904]\n",
      "[Epoch 66/150] [D loss: -5.585325] [G loss: -11.662400]\n",
      "[Epoch 67/150] [D loss: -5.062497] [G loss: -11.024284]\n",
      "[Epoch 68/150] [D loss: -5.343364] [G loss: -12.137132]\n",
      "[Epoch 69/150] [D loss: -4.721548] [G loss: -10.462368]\n",
      "[Epoch 70/150] [D loss: -4.466800] [G loss: -10.880523]\n",
      "[Epoch 71/150] [D loss: -5.311707] [G loss: -12.349753]\n",
      "[Epoch 72/150] [D loss: -4.135631] [G loss: -11.830739]\n",
      "[Epoch 73/150] [D loss: -4.663914] [G loss: -11.232713]\n",
      "[Epoch 74/150] [D loss: -3.761010] [G loss: -10.206882]\n",
      "[Epoch 75/150] [D loss: -3.675346] [G loss: -10.128785]\n",
      "[Epoch 76/150] [D loss: -3.708524] [G loss: -11.002372]\n",
      "[Epoch 77/150] [D loss: -3.912004] [G loss: -11.409410]\n",
      "[Epoch 78/150] [D loss: -2.882473] [G loss: -12.715847]\n",
      "[Epoch 79/150] [D loss: -2.535073] [G loss: -11.562382]\n",
      "[Epoch 80/150] [D loss: -3.321757] [G loss: -11.094266]\n",
      "[Epoch 81/150] [D loss: -3.162307] [G loss: -9.598776]\n",
      "[Epoch 82/150] [D loss: -3.174863] [G loss: -8.422885]\n",
      "[Epoch 83/150] [D loss: -3.523925] [G loss: -8.342039]\n",
      "[Epoch 84/150] [D loss: -2.595665] [G loss: -8.364471]\n",
      "[Epoch 85/150] [D loss: -2.135904] [G loss: -8.109636]\n",
      "[Epoch 86/150] [D loss: -2.127528] [G loss: -6.985312]\n",
      "[Epoch 87/150] [D loss: -2.188568] [G loss: -9.155184]\n",
      "[Epoch 88/150] [D loss: -2.626023] [G loss: -9.816664]\n",
      "[Epoch 89/150] [D loss: -2.417809] [G loss: -7.605499]\n",
      "[Epoch 90/150] [D loss: -2.474593] [G loss: -5.782295]\n",
      "[Epoch 91/150] [D loss: -2.270867] [G loss: -7.619963]\n",
      "[Epoch 92/150] [D loss: -1.789737] [G loss: -9.919208]\n",
      "[Epoch 93/150] [D loss: -1.483921] [G loss: -8.047127]\n",
      "[Epoch 94/150] [D loss: -2.440331] [G loss: -7.822783]\n",
      "[Epoch 95/150] [D loss: -2.656365] [G loss: -8.589122]\n",
      "[Epoch 96/150] [D loss: -1.978626] [G loss: -6.921306]\n",
      "[Epoch 97/150] [D loss: -2.424198] [G loss: -6.243511]\n",
      "[Epoch 98/150] [D loss: -2.186069] [G loss: -5.944703]\n",
      "[Epoch 99/150] [D loss: -2.380808] [G loss: -5.598516]\n",
      "[Epoch 100/150] [D loss: -2.068542] [G loss: -7.276977]\n",
      "[Epoch 101/150] [D loss: -2.270580] [G loss: -6.618433]\n",
      "[Epoch 102/150] [D loss: -2.064520] [G loss: -4.855994]\n",
      "[Epoch 103/150] [D loss: -2.439664] [G loss: -4.148795]\n",
      "[Epoch 104/150] [D loss: -2.300765] [G loss: -3.079990]\n",
      "[Epoch 105/150] [D loss: -2.130290] [G loss: -3.339592]\n",
      "[Epoch 106/150] [D loss: -2.272851] [G loss: -1.977440]\n",
      "[Epoch 107/150] [D loss: -2.146984] [G loss: -3.328959]\n",
      "[Epoch 108/150] [D loss: -2.736024] [G loss: -3.105623]\n",
      "[Epoch 109/150] [D loss: -2.628202] [G loss: -3.785122]\n",
      "[Epoch 110/150] [D loss: -2.259630] [G loss: -4.413878]\n",
      "[Epoch 111/150] [D loss: -2.308965] [G loss: -4.439752]\n",
      "[Epoch 112/150] [D loss: -2.084036] [G loss: -5.136589]\n",
      "[Epoch 113/150] [D loss: -2.380725] [G loss: -3.799701]\n",
      "[Epoch 114/150] [D loss: -2.303806] [G loss: 0.370531]\n",
      "[Epoch 115/150] [D loss: -2.173628] [G loss: -0.225251]\n",
      "[Epoch 116/150] [D loss: -2.183177] [G loss: -1.580893]\n",
      "[Epoch 117/150] [D loss: -2.579556] [G loss: -1.008579]\n",
      "[Epoch 118/150] [D loss: -2.084796] [G loss: -0.323726]\n",
      "[Epoch 119/150] [D loss: -2.135044] [G loss: -0.458845]\n",
      "[Epoch 120/150] [D loss: -2.045086] [G loss: -2.819376]\n",
      "[Epoch 121/150] [D loss: -2.386675] [G loss: -1.865149]\n",
      "[Epoch 122/150] [D loss: -2.022487] [G loss: -1.212018]\n",
      "[Epoch 123/150] [D loss: -2.361187] [G loss: -0.496044]\n",
      "[Epoch 124/150] [D loss: -2.187946] [G loss: -2.168619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 125/150] [D loss: -2.188093] [G loss: -2.922372]\n",
      "[Epoch 126/150] [D loss: -2.411885] [G loss: -4.346983]\n",
      "[Epoch 127/150] [D loss: -2.395798] [G loss: -4.284204]\n",
      "[Epoch 128/150] [D loss: -2.083354] [G loss: -4.425739]\n",
      "[Epoch 129/150] [D loss: -2.193103] [G loss: -3.229205]\n",
      "[Epoch 130/150] [D loss: -2.817819] [G loss: -3.073701]\n",
      "[Epoch 131/150] [D loss: -2.562043] [G loss: -2.481215]\n",
      "[Epoch 132/150] [D loss: -2.456436] [G loss: -2.461132]\n",
      "[Epoch 133/150] [D loss: -2.405882] [G loss: -2.335457]\n",
      "[Epoch 134/150] [D loss: -2.017991] [G loss: -2.741501]\n",
      "[Epoch 135/150] [D loss: -1.923932] [G loss: -3.661996]\n",
      "[Epoch 136/150] [D loss: -2.407387] [G loss: -4.365159]\n",
      "[Epoch 137/150] [D loss: -2.607802] [G loss: -3.428320]\n",
      "[Epoch 138/150] [D loss: -2.548063] [G loss: -3.201672]\n",
      "[Epoch 139/150] [D loss: -1.991327] [G loss: -3.237089]\n",
      "[Epoch 140/150] [D loss: -2.508366] [G loss: -3.669039]\n",
      "[Epoch 141/150] [D loss: -2.129419] [G loss: -1.999306]\n",
      "[Epoch 142/150] [D loss: -2.230400] [G loss: -1.422861]\n",
      "[Epoch 143/150] [D loss: -2.133476] [G loss: -2.013943]\n",
      "[Epoch 144/150] [D loss: -2.150211] [G loss: -2.734177]\n",
      "[Epoch 145/150] [D loss: -2.666968] [G loss: -2.422560]\n",
      "[Epoch 146/150] [D loss: -2.446592] [G loss: -2.205869]\n",
      "[Epoch 147/150] [D loss: -2.017840] [G loss: -2.516667]\n",
      "[Epoch 148/150] [D loss: -2.565596] [G loss: -3.046860]\n",
      "[Epoch 149/150] [D loss: -2.349746] [G loss: -3.071737]\n",
      "[Epoch 150/150] [D loss: -2.081464] [G loss: -2.594110]\n",
      "Merging dataset Karlsson (2013) to Other\n",
      "Calculating Anchor Pairs...\n",
      "Calculating Query Pairs...\n",
      "Calculating KNN Pairs...\n",
      "Calculating Random Walk Pairs...\n",
      "Done.\n",
      "[Epoch 1/150] [D loss: 1.940938] [G loss: -0.055922]\n",
      "[Epoch 2/150] [D loss: -4.289568] [G loss: 0.955578]\n",
      "[Epoch 3/150] [D loss: -6.996948] [G loss: 4.757512]\n",
      "[Epoch 4/150] [D loss: -8.184774] [G loss: 7.246293]\n",
      "[Epoch 5/150] [D loss: -9.459809] [G loss: 7.400181]\n",
      "[Epoch 6/150] [D loss: -11.480047] [G loss: 6.508561]\n",
      "[Epoch 7/150] [D loss: -13.818404] [G loss: 6.507913]\n",
      "[Epoch 8/150] [D loss: -16.887604] [G loss: 7.354386]\n",
      "[Epoch 9/150] [D loss: -19.408346] [G loss: 8.417702]\n",
      "[Epoch 10/150] [D loss: -19.937939] [G loss: 8.715898]\n",
      "[Epoch 11/150] [D loss: -20.326450] [G loss: 8.865762]\n",
      "[Epoch 12/150] [D loss: -19.682386] [G loss: 7.705643]\n",
      "[Epoch 13/150] [D loss: -18.855476] [G loss: 7.431545]\n",
      "[Epoch 14/150] [D loss: -17.576700] [G loss: 6.130017]\n",
      "[Epoch 15/150] [D loss: -16.880350] [G loss: 4.773909]\n",
      "[Epoch 16/150] [D loss: -15.581329] [G loss: 3.711508]\n",
      "[Epoch 17/150] [D loss: -14.677896] [G loss: 2.728682]\n",
      "[Epoch 18/150] [D loss: -13.201654] [G loss: 2.601697]\n",
      "[Epoch 19/150] [D loss: -13.504688] [G loss: 1.981588]\n",
      "[Epoch 20/150] [D loss: -11.718722] [G loss: 1.144585]\n",
      "[Epoch 21/150] [D loss: -11.181698] [G loss: 0.135491]\n",
      "[Epoch 22/150] [D loss: -10.702483] [G loss: 0.436087]\n",
      "[Epoch 23/150] [D loss: -10.058805] [G loss: 0.004121]\n",
      "[Epoch 24/150] [D loss: -9.900812] [G loss: 0.658782]\n",
      "[Epoch 25/150] [D loss: -8.968367] [G loss: -0.636557]\n",
      "[Epoch 26/150] [D loss: -8.674050] [G loss: -0.204781]\n",
      "[Epoch 27/150] [D loss: -8.058406] [G loss: -0.947558]\n",
      "[Epoch 28/150] [D loss: -7.647756] [G loss: -1.130879]\n",
      "[Epoch 29/150] [D loss: -6.544840] [G loss: -1.644892]\n",
      "[Epoch 30/150] [D loss: -7.115286] [G loss: -1.470020]\n",
      "[Epoch 31/150] [D loss: -6.704642] [G loss: -2.013737]\n",
      "[Epoch 32/150] [D loss: -6.640882] [G loss: -2.107476]\n",
      "[Epoch 33/150] [D loss: -5.789235] [G loss: -2.193206]\n",
      "[Epoch 34/150] [D loss: -5.630569] [G loss: -2.607343]\n",
      "[Epoch 35/150] [D loss: -4.783160] [G loss: -2.290615]\n",
      "[Epoch 36/150] [D loss: -5.086120] [G loss: -1.815839]\n",
      "[Epoch 37/150] [D loss: -4.303596] [G loss: -1.959943]\n",
      "[Epoch 38/150] [D loss: -4.971307] [G loss: -2.400223]\n",
      "[Epoch 39/150] [D loss: -4.321503] [G loss: -2.167703]\n",
      "[Epoch 40/150] [D loss: -4.379760] [G loss: -3.159404]\n",
      "[Epoch 41/150] [D loss: -4.027184] [G loss: -2.163810]\n",
      "[Epoch 42/150] [D loss: -3.840298] [G loss: -2.833894]\n",
      "[Epoch 43/150] [D loss: -4.095462] [G loss: -3.132356]\n",
      "[Epoch 44/150] [D loss: -4.002839] [G loss: -2.446655]\n",
      "[Epoch 45/150] [D loss: -3.428161] [G loss: -2.286302]\n",
      "[Epoch 46/150] [D loss: -3.377689] [G loss: -3.106079]\n",
      "[Epoch 47/150] [D loss: -2.989747] [G loss: -2.770286]\n",
      "[Epoch 48/150] [D loss: -2.688579] [G loss: -2.115106]\n",
      "[Epoch 49/150] [D loss: -3.381262] [G loss: -3.284507]\n",
      "[Epoch 50/150] [D loss: -2.941847] [G loss: -3.021612]\n",
      "[Epoch 51/150] [D loss: -2.970244] [G loss: -2.073262]\n",
      "[Epoch 52/150] [D loss: -2.797745] [G loss: -1.246716]\n",
      "[Epoch 53/150] [D loss: -2.569953] [G loss: -1.313842]\n",
      "[Epoch 54/150] [D loss: -3.135929] [G loss: -1.264114]\n",
      "[Epoch 55/150] [D loss: -2.733876] [G loss: -0.852312]\n",
      "[Epoch 56/150] [D loss: -2.263300] [G loss: -0.327246]\n",
      "[Epoch 57/150] [D loss: -2.073521] [G loss: -0.881807]\n",
      "[Epoch 58/150] [D loss: -1.857093] [G loss: -1.225985]\n",
      "[Epoch 59/150] [D loss: -1.410002] [G loss: -0.935787]\n",
      "[Epoch 60/150] [D loss: -1.515138] [G loss: -0.568587]\n",
      "[Epoch 61/150] [D loss: -1.584708] [G loss: -0.661834]\n",
      "[Epoch 62/150] [D loss: -1.627843] [G loss: -0.363302]\n",
      "[Epoch 63/150] [D loss: -1.597754] [G loss: 0.266559]\n",
      "[Epoch 64/150] [D loss: -1.817124] [G loss: 0.607013]\n",
      "[Epoch 65/150] [D loss: -1.694759] [G loss: -0.342638]\n",
      "[Epoch 66/150] [D loss: -1.892526] [G loss: -0.450983]\n",
      "[Epoch 67/150] [D loss: -1.624814] [G loss: 0.312467]\n",
      "[Epoch 68/150] [D loss: -1.839895] [G loss: 0.258427]\n",
      "[Epoch 69/150] [D loss: -1.755086] [G loss: 0.716625]\n",
      "[Epoch 70/150] [D loss: -1.801880] [G loss: 0.128409]\n",
      "[Epoch 71/150] [D loss: -1.816124] [G loss: 0.856262]\n",
      "[Epoch 72/150] [D loss: -1.732809] [G loss: 0.975020]\n",
      "[Epoch 73/150] [D loss: -1.742288] [G loss: 1.671689]\n",
      "[Epoch 74/150] [D loss: -2.118265] [G loss: 1.428983]\n",
      "[Epoch 75/150] [D loss: -1.912270] [G loss: 1.068027]\n",
      "[Epoch 76/150] [D loss: -2.059484] [G loss: 0.186956]\n",
      "[Epoch 77/150] [D loss: -1.909748] [G loss: 0.386617]\n",
      "[Epoch 78/150] [D loss: -1.889046] [G loss: 1.347288]\n",
      "[Epoch 79/150] [D loss: -2.021906] [G loss: 2.047081]\n",
      "[Epoch 80/150] [D loss: -2.059961] [G loss: 1.869741]\n",
      "[Epoch 81/150] [D loss: -2.026006] [G loss: 1.192351]\n",
      "[Epoch 82/150] [D loss: -2.015035] [G loss: 0.687635]\n",
      "[Epoch 83/150] [D loss: -1.889616] [G loss: 0.722115]\n",
      "[Epoch 84/150] [D loss: -2.012153] [G loss: 0.757652]\n",
      "[Epoch 85/150] [D loss: -2.058135] [G loss: 0.387065]\n",
      "[Epoch 86/150] [D loss: -2.204799] [G loss: 0.166829]\n",
      "[Epoch 87/150] [D loss: -2.028938] [G loss: 0.214480]\n",
      "[Epoch 88/150] [D loss: -2.257096] [G loss: -0.223153]\n",
      "[Epoch 89/150] [D loss: -2.190846] [G loss: -0.445688]\n",
      "[Epoch 90/150] [D loss: -2.277364] [G loss: -0.351877]\n",
      "[Epoch 91/150] [D loss: -2.378342] [G loss: 0.119314]\n",
      "[Epoch 92/150] [D loss: -2.027295] [G loss: 0.173270]\n",
      "[Epoch 93/150] [D loss: -2.032254] [G loss: 0.057386]\n",
      "[Epoch 94/150] [D loss: -2.008877] [G loss: -0.182625]\n",
      "[Epoch 95/150] [D loss: -1.982261] [G loss: 0.286601]\n",
      "[Epoch 96/150] [D loss: -2.412524] [G loss: 0.810272]\n",
      "[Epoch 97/150] [D loss: -2.388918] [G loss: 1.307880]\n",
      "[Epoch 98/150] [D loss: -2.264723] [G loss: 0.943208]\n",
      "[Epoch 99/150] [D loss: -2.561452] [G loss: -0.150967]\n",
      "[Epoch 100/150] [D loss: -2.417253] [G loss: -0.900923]\n",
      "[Epoch 101/150] [D loss: -2.456532] [G loss: -0.959725]\n",
      "[Epoch 102/150] [D loss: -2.427740] [G loss: -0.564209]\n",
      "[Epoch 103/150] [D loss: -2.162903] [G loss: -0.231759]\n",
      "[Epoch 104/150] [D loss: -2.212409] [G loss: -0.243717]\n",
      "[Epoch 105/150] [D loss: -2.071392] [G loss: 0.256201]\n",
      "[Epoch 106/150] [D loss: -2.248049] [G loss: 0.633488]\n",
      "[Epoch 107/150] [D loss: -2.151036] [G loss: 1.337120]\n",
      "[Epoch 108/150] [D loss: -2.353830] [G loss: 1.354535]\n",
      "[Epoch 109/150] [D loss: -2.274652] [G loss: 1.487126]\n",
      "[Epoch 110/150] [D loss: -2.362043] [G loss: 0.248705]\n",
      "[Epoch 111/150] [D loss: -2.159241] [G loss: -1.016190]\n",
      "[Epoch 112/150] [D loss: -2.355113] [G loss: -1.331690]\n",
      "[Epoch 113/150] [D loss: -2.628280] [G loss: -2.005662]\n",
      "[Epoch 114/150] [D loss: -2.490710] [G loss: -1.378608]\n",
      "[Epoch 115/150] [D loss: -2.243789] [G loss: -0.579322]\n",
      "[Epoch 116/150] [D loss: -2.274982] [G loss: 0.570768]\n",
      "[Epoch 117/150] [D loss: -2.116655] [G loss: 0.683128]\n",
      "[Epoch 118/150] [D loss: -2.302905] [G loss: -0.187706]\n",
      "[Epoch 119/150] [D loss: -2.367196] [G loss: -0.955163]\n",
      "[Epoch 120/150] [D loss: -2.525769] [G loss: -1.650638]\n",
      "[Epoch 121/150] [D loss: -2.440636] [G loss: -1.404210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 122/150] [D loss: -2.236860] [G loss: -0.549646]\n",
      "[Epoch 123/150] [D loss: -2.652869] [G loss: 0.017008]\n",
      "[Epoch 124/150] [D loss: -2.343039] [G loss: 0.630740]\n",
      "[Epoch 125/150] [D loss: -2.413611] [G loss: 0.526171]\n",
      "[Epoch 126/150] [D loss: -2.587402] [G loss: -0.997939]\n",
      "[Epoch 127/150] [D loss: -2.289528] [G loss: -1.386266]\n",
      "[Epoch 128/150] [D loss: -2.288023] [G loss: -0.968568]\n",
      "[Epoch 129/150] [D loss: -1.924323] [G loss: -0.832170]\n",
      "[Epoch 130/150] [D loss: -2.461164] [G loss: -0.640040]\n",
      "[Epoch 131/150] [D loss: -2.382743] [G loss: -1.032893]\n",
      "[Epoch 132/150] [D loss: -2.432757] [G loss: -1.861722]\n",
      "[Epoch 133/150] [D loss: -2.430608] [G loss: -1.707263]\n",
      "[Epoch 134/150] [D loss: -2.164179] [G loss: -1.108292]\n",
      "[Epoch 135/150] [D loss: -2.446087] [G loss: -0.780252]\n",
      "[Epoch 136/150] [D loss: -2.127028] [G loss: -0.095571]\n",
      "[Epoch 137/150] [D loss: -2.468103] [G loss: 0.317473]\n",
      "[Epoch 138/150] [D loss: -2.441617] [G loss: 0.219344]\n",
      "[Epoch 139/150] [D loss: -2.655423] [G loss: -0.565913]\n",
      "[Epoch 140/150] [D loss: -2.687288] [G loss: -0.788815]\n",
      "[Epoch 141/150] [D loss: -2.774026] [G loss: -0.858419]\n",
      "[Epoch 142/150] [D loss: -2.696635] [G loss: 0.040763]\n",
      "[Epoch 143/150] [D loss: -2.605014] [G loss: -0.096679]\n",
      "[Epoch 144/150] [D loss: -2.703006] [G loss: -1.011209]\n",
      "[Epoch 145/150] [D loss: -2.385357] [G loss: -1.319722]\n",
      "[Epoch 146/150] [D loss: -2.473033] [G loss: -1.075819]\n",
      "[Epoch 147/150] [D loss: -2.415804] [G loss: -1.454835]\n",
      "[Epoch 148/150] [D loss: -2.641929] [G loss: -1.564878]\n",
      "[Epoch 149/150] [D loss: -2.362366] [G loss: -0.668594]\n",
      "[Epoch 150/150] [D loss: -2.686660] [G loss: -0.197495]\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, len(scd.dataset)):\n",
    "    print(f'Merging dataset {batches[orders[i]]} to {batches[orders[0]]}')\n",
    "    fake_data = train(scd, i, n_epochs=n_epochs)\n",
    "    scd.transform = np.r_[scd.transform, fake_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame(scd.transform)\n",
    "output.columns=train_p.columns.tolist()[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_index =[]\n",
    "for i in orders:\n",
    "    out_index += train_p[train_p['batch']==batches[i]].index.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.insert(0,'ID',out_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ec_obs_names)==out_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata.insert(0,'ID',train.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.insert(1,'batch',output['ID'].replace(train['batch'].to_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.insert(1,'Type',output['ID'].str.split('_',expand=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Type</th>\n",
       "      <th>batch</th>\n",
       "      <th>s__Abiotrophia_defectiva</th>\n",
       "      <th>s__Acetobacter_unclassified</th>\n",
       "      <th>s__Achromobacter_piechaudii</th>\n",
       "      <th>s__Achromobacter_unclassified</th>\n",
       "      <th>s__Achromobacter_xylosoxidans</th>\n",
       "      <th>s__Acidaminococcus_fermentans</th>\n",
       "      <th>s__Acidaminococcus_intestini</th>\n",
       "      <th>...</th>\n",
       "      <th>s__Vibrio_furnissii</th>\n",
       "      <th>s__Vibrio_kanaloae</th>\n",
       "      <th>s__Weissella_cibaria</th>\n",
       "      <th>s__Weissella_confusa</th>\n",
       "      <th>s__Weissella_halotolerans</th>\n",
       "      <th>s__Weissella_koreensis</th>\n",
       "      <th>s__Weissella_paramesenteroides</th>\n",
       "      <th>s__Weissella_unclassified</th>\n",
       "      <th>s__Wohlfahrtiimonas_chitiniclastica</th>\n",
       "      <th>s__Yersinia_enterocolitica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overweight_3619</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Zeller (2014)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Overweight_3620</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Zeller (2014)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Overweight_3621</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Zeller (2014)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Overweight_3622</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Zeller (2014)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00084</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Overweight_3623</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Zeller (2014)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Overweight_3691</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Karlsson (2013)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>Overweight_3692</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Karlsson (2013)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>Overweight_3693</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Karlsson (2013)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Overweight_3694</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Karlsson (2013)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Overweight_3695</td>\n",
       "      <td>Overweight</td>\n",
       "      <td>Karlsson (2013)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows Ã— 906 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  ID        Type            batch  s__Abiotrophia_defectiva  \\\n",
       "0    Overweight_3619  Overweight    Zeller (2014)                       0.0   \n",
       "1    Overweight_3620  Overweight    Zeller (2014)                       0.0   \n",
       "2    Overweight_3621  Overweight    Zeller (2014)                       0.0   \n",
       "3    Overweight_3622  Overweight    Zeller (2014)                       0.0   \n",
       "4    Overweight_3623  Overweight    Zeller (2014)                       0.0   \n",
       "..               ...         ...              ...                       ...   \n",
       "233  Overweight_3691  Overweight  Karlsson (2013)                       0.0   \n",
       "234  Overweight_3692  Overweight  Karlsson (2013)                       0.0   \n",
       "235  Overweight_3693  Overweight  Karlsson (2013)                       0.0   \n",
       "236  Overweight_3694  Overweight  Karlsson (2013)                       0.0   \n",
       "237  Overweight_3695  Overweight  Karlsson (2013)                       0.0   \n",
       "\n",
       "     s__Acetobacter_unclassified  s__Achromobacter_piechaudii  \\\n",
       "0                       0.000000                          0.0   \n",
       "1                       0.000000                          0.0   \n",
       "2                       0.000000                          0.0   \n",
       "3                       0.000000                          0.0   \n",
       "4                       0.000000                          0.0   \n",
       "..                           ...                          ...   \n",
       "233                     0.000000                          0.0   \n",
       "234                     0.000000                          0.0   \n",
       "235                     0.021887                          0.0   \n",
       "236                     0.000000                          0.0   \n",
       "237                     0.000000                          0.0   \n",
       "\n",
       "     s__Achromobacter_unclassified  s__Achromobacter_xylosoxidans  \\\n",
       "0                              0.0                            0.0   \n",
       "1                              0.0                            0.0   \n",
       "2                              0.0                            0.0   \n",
       "3                              0.0                            0.0   \n",
       "4                              0.0                            0.0   \n",
       "..                             ...                            ...   \n",
       "233                            0.0                            0.0   \n",
       "234                            0.0                            0.0   \n",
       "235                            0.0                            0.0   \n",
       "236                            0.0                            0.0   \n",
       "237                            0.0                            0.0   \n",
       "\n",
       "     s__Acidaminococcus_fermentans  s__Acidaminococcus_intestini  ...  \\\n",
       "0                         0.000000                       0.00000  ...   \n",
       "1                         0.000000                       0.00000  ...   \n",
       "2                         0.025272                       0.00000  ...   \n",
       "3                         0.000000                       0.00084  ...   \n",
       "4                         0.000000                       0.00000  ...   \n",
       "..                             ...                           ...  ...   \n",
       "233                       0.000000                       0.00000  ...   \n",
       "234                       0.000000                       0.00000  ...   \n",
       "235                       0.000000                       0.00000  ...   \n",
       "236                       0.000000                       0.00000  ...   \n",
       "237                       0.000000                       0.00000  ...   \n",
       "\n",
       "     s__Vibrio_furnissii  s__Vibrio_kanaloae  s__Weissella_cibaria  \\\n",
       "0                    0.0                 0.0              0.000000   \n",
       "1                    0.0                 0.0              0.000000   \n",
       "2                    0.0                 0.0              0.000000   \n",
       "3                    0.0                 0.0              0.000000   \n",
       "4                    0.0                 0.0              0.000000   \n",
       "..                   ...                 ...                   ...   \n",
       "233                  0.0                 0.0              0.000000   \n",
       "234                  0.0                 0.0              0.014736   \n",
       "235                  0.0                 0.0              0.000000   \n",
       "236                  0.0                 0.0              0.000000   \n",
       "237                  0.0                 0.0              0.000000   \n",
       "\n",
       "     s__Weissella_confusa  s__Weissella_halotolerans  s__Weissella_koreensis  \\\n",
       "0                     0.0                        0.0                     0.0   \n",
       "1                     0.0                        0.0                     0.0   \n",
       "2                     0.0                        0.0                     0.0   \n",
       "3                     0.0                        0.0                     0.0   \n",
       "4                     0.0                        0.0                     0.0   \n",
       "..                    ...                        ...                     ...   \n",
       "233                   0.0                        0.0                     0.0   \n",
       "234                   0.0                        0.0                     0.0   \n",
       "235                   0.0                        0.0                     0.0   \n",
       "236                   0.0                        0.0                     0.0   \n",
       "237                   0.0                        0.0                     0.0   \n",
       "\n",
       "     s__Weissella_paramesenteroides  s__Weissella_unclassified  \\\n",
       "0                               0.0                   0.000000   \n",
       "1                               0.0                   0.000000   \n",
       "2                               0.0                   0.000000   \n",
       "3                               0.0                   0.000000   \n",
       "4                               0.0                   0.000000   \n",
       "..                              ...                        ...   \n",
       "233                             0.0                   0.000000   \n",
       "234                             0.0                   0.000000   \n",
       "235                             0.0                   0.034965   \n",
       "236                             0.0                   0.000000   \n",
       "237                             0.0                   0.000000   \n",
       "\n",
       "     s__Wohlfahrtiimonas_chitiniclastica  s__Yersinia_enterocolitica  \n",
       "0                                    0.0                         0.0  \n",
       "1                                    0.0                         0.0  \n",
       "2                                    0.0                         0.0  \n",
       "3                                    0.0                         0.0  \n",
       "4                                    0.0                         0.0  \n",
       "..                                   ...                         ...  \n",
       "233                                  0.0                         0.0  \n",
       "234                                  0.0                         0.0  \n",
       "235                                  0.0                         0.0  \n",
       "236                                  0.0                         0.0  \n",
       "237                                  0.0                         0.0  \n",
       "\n",
       "[238 rows x 906 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('output'+phenotype+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data2umap(data, n_pca=0):\n",
    "    if n_pca > 0:\n",
    "        pca = PCA(n_components=n_pca)\n",
    "        embedding = pca.fit_transform(data)\n",
    "    else:\n",
    "        embedding = data\n",
    "    embedding_ = umap.UMAP(\n",
    "        n_neighbors=30,\n",
    "        min_dist=0.3,\n",
    "        metric='cosine',\n",
    "        n_components = 2,\n",
    "        learning_rate = 1.0,\n",
    "        spread = 1.0,\n",
    "        set_op_mix_ratio = 1.0,\n",
    "        local_connectivity = 1,\n",
    "        repulsion_strength = 1,\n",
    "        negative_sample_rate = 5,\n",
    "        angular_rp_forest = False,\n",
    "        verbose = False\n",
    "    ).fit_transform(embedding)\n",
    "    return embedding_\n",
    "def umap_plot(data, hue, title, save_path):\n",
    "    import seaborn as sns\n",
    "    fig = sns.lmplot(\n",
    "        x = 'UMAP_1',\n",
    "        y = 'UMAP_2',\n",
    "        data = data,\n",
    "        fit_reg = False,\n",
    "        legend = True,\n",
    "        size = 9,\n",
    "        hue = hue,\n",
    "        palette = sns.color_palette(\"husl\", len(set(hue))),\n",
    "        scatter_kws = {'s':4, \"alpha\":0.6}\n",
    "    )\n",
    "    plt.title(title, weight='bold').set_fontsize('20')\n",
    "    fig.savefig(save_path)\n",
    "    plt.close()\n",
    "def gplot(embedding_, batch_info, celltype_info, filename):\n",
    "    test = pd.DataFrame(embedding_, columns=['UMAP_1', 'UMAP_2'])\n",
    "    test['Label1'] = batch_info\n",
    "    test['Label2'] = celltype_info\n",
    "    title = f' '\n",
    "    for i in range(1,3):\n",
    "        hue = f'Label{i}'\n",
    "        save_path = './pic/'+filename + f'{i}.png'\n",
    "        umap_plot(test, hue, title, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s__Abiotrophia_defectiva</th>\n",
       "      <th>s__Acetobacter_unclassified</th>\n",
       "      <th>s__Achromobacter_piechaudii</th>\n",
       "      <th>s__Achromobacter_unclassified</th>\n",
       "      <th>s__Achromobacter_xylosoxidans</th>\n",
       "      <th>s__Acidaminococcus_fermentans</th>\n",
       "      <th>s__Acidaminococcus_intestini</th>\n",
       "      <th>s__Acidaminococcus_sp_BV3L6</th>\n",
       "      <th>s__Acidaminococcus_sp_D21</th>\n",
       "      <th>s__Acidaminococcus_sp_HPA0509</th>\n",
       "      <th>...</th>\n",
       "      <th>s__Vibrio_furnissii</th>\n",
       "      <th>s__Vibrio_kanaloae</th>\n",
       "      <th>s__Weissella_cibaria</th>\n",
       "      <th>s__Weissella_confusa</th>\n",
       "      <th>s__Weissella_halotolerans</th>\n",
       "      <th>s__Weissella_koreensis</th>\n",
       "      <th>s__Weissella_paramesenteroides</th>\n",
       "      <th>s__Weissella_unclassified</th>\n",
       "      <th>s__Wohlfahrtiimonas_chitiniclastica</th>\n",
       "      <th>s__Yersinia_enterocolitica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.025272</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014736</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021887</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows Ã— 903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     s__Abiotrophia_defectiva  s__Acetobacter_unclassified  \\\n",
       "0                         0.0                     0.000000   \n",
       "1                         0.0                     0.000000   \n",
       "2                         0.0                     0.000000   \n",
       "3                         0.0                     0.000000   \n",
       "4                         0.0                     0.000000   \n",
       "..                        ...                          ...   \n",
       "233                       0.0                     0.000000   \n",
       "234                       0.0                     0.000000   \n",
       "235                       0.0                     0.021887   \n",
       "236                       0.0                     0.000000   \n",
       "237                       0.0                     0.000000   \n",
       "\n",
       "     s__Achromobacter_piechaudii  s__Achromobacter_unclassified  \\\n",
       "0                            0.0                            0.0   \n",
       "1                            0.0                            0.0   \n",
       "2                            0.0                            0.0   \n",
       "3                            0.0                            0.0   \n",
       "4                            0.0                            0.0   \n",
       "..                           ...                            ...   \n",
       "233                          0.0                            0.0   \n",
       "234                          0.0                            0.0   \n",
       "235                          0.0                            0.0   \n",
       "236                          0.0                            0.0   \n",
       "237                          0.0                            0.0   \n",
       "\n",
       "     s__Achromobacter_xylosoxidans  s__Acidaminococcus_fermentans  \\\n",
       "0                              0.0                       0.000000   \n",
       "1                              0.0                       0.000000   \n",
       "2                              0.0                       0.025272   \n",
       "3                              0.0                       0.000000   \n",
       "4                              0.0                       0.000000   \n",
       "..                             ...                            ...   \n",
       "233                            0.0                       0.000000   \n",
       "234                            0.0                       0.000000   \n",
       "235                            0.0                       0.000000   \n",
       "236                            0.0                       0.000000   \n",
       "237                            0.0                       0.000000   \n",
       "\n",
       "     s__Acidaminococcus_intestini  s__Acidaminococcus_sp_BV3L6  \\\n",
       "0                         0.00000                          0.0   \n",
       "1                         0.00000                          0.0   \n",
       "2                         0.00000                          0.0   \n",
       "3                         0.00084                          0.0   \n",
       "4                         0.00000                          0.0   \n",
       "..                            ...                          ...   \n",
       "233                       0.00000                          0.0   \n",
       "234                       0.00000                          0.0   \n",
       "235                       0.00000                          0.0   \n",
       "236                       0.00000                          0.0   \n",
       "237                       0.00000                          0.0   \n",
       "\n",
       "     s__Acidaminococcus_sp_D21  s__Acidaminococcus_sp_HPA0509  ...  \\\n",
       "0                          0.0                            0.0  ...   \n",
       "1                          0.0                            0.0  ...   \n",
       "2                          0.0                            0.0  ...   \n",
       "3                          0.0                            0.0  ...   \n",
       "4                          0.0                            0.0  ...   \n",
       "..                         ...                            ...  ...   \n",
       "233                        0.0                            0.0  ...   \n",
       "234                        0.0                            0.0  ...   \n",
       "235                        0.0                            0.0  ...   \n",
       "236                        0.0                            0.0  ...   \n",
       "237                        0.0                            0.0  ...   \n",
       "\n",
       "     s__Vibrio_furnissii  s__Vibrio_kanaloae  s__Weissella_cibaria  \\\n",
       "0                    0.0                 0.0              0.000000   \n",
       "1                    0.0                 0.0              0.000000   \n",
       "2                    0.0                 0.0              0.000000   \n",
       "3                    0.0                 0.0              0.000000   \n",
       "4                    0.0                 0.0              0.000000   \n",
       "..                   ...                 ...                   ...   \n",
       "233                  0.0                 0.0              0.000000   \n",
       "234                  0.0                 0.0              0.014736   \n",
       "235                  0.0                 0.0              0.000000   \n",
       "236                  0.0                 0.0              0.000000   \n",
       "237                  0.0                 0.0              0.000000   \n",
       "\n",
       "     s__Weissella_confusa  s__Weissella_halotolerans  s__Weissella_koreensis  \\\n",
       "0                     0.0                        0.0                     0.0   \n",
       "1                     0.0                        0.0                     0.0   \n",
       "2                     0.0                        0.0                     0.0   \n",
       "3                     0.0                        0.0                     0.0   \n",
       "4                     0.0                        0.0                     0.0   \n",
       "..                    ...                        ...                     ...   \n",
       "233                   0.0                        0.0                     0.0   \n",
       "234                   0.0                        0.0                     0.0   \n",
       "235                   0.0                        0.0                     0.0   \n",
       "236                   0.0                        0.0                     0.0   \n",
       "237                   0.0                        0.0                     0.0   \n",
       "\n",
       "     s__Weissella_paramesenteroides  s__Weissella_unclassified  \\\n",
       "0                               0.0                   0.000000   \n",
       "1                               0.0                   0.000000   \n",
       "2                               0.0                   0.000000   \n",
       "3                               0.0                   0.000000   \n",
       "4                               0.0                   0.000000   \n",
       "..                              ...                        ...   \n",
       "233                             0.0                   0.000000   \n",
       "234                             0.0                   0.000000   \n",
       "235                             0.0                   0.034965   \n",
       "236                             0.0                   0.000000   \n",
       "237                             0.0                   0.000000   \n",
       "\n",
       "     s__Wohlfahrtiimonas_chitiniclastica  s__Yersinia_enterocolitica  \n",
       "0                                    0.0                         0.0  \n",
       "1                                    0.0                         0.0  \n",
       "2                                    0.0                         0.0  \n",
       "3                                    0.0                         0.0  \n",
       "4                                    0.0                         0.0  \n",
       "..                                   ...                         ...  \n",
       "233                                  0.0                         0.0  \n",
       "234                                  0.0                         0.0  \n",
       "235                                  0.0                         0.0  \n",
       "236                                  0.0                         0.0  \n",
       "237                                  0.0                         0.0  \n",
       "\n",
       "[238 rows x 903 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.iloc[:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s__Abiotrophia_defectiva</th>\n",
       "      <th>s__Acetobacter_unclassified</th>\n",
       "      <th>s__Achromobacter_piechaudii</th>\n",
       "      <th>s__Achromobacter_unclassified</th>\n",
       "      <th>s__Achromobacter_xylosoxidans</th>\n",
       "      <th>s__Acidaminococcus_fermentans</th>\n",
       "      <th>s__Acidaminococcus_intestini</th>\n",
       "      <th>s__Acidaminococcus_sp_BV3L6</th>\n",
       "      <th>s__Acidaminococcus_sp_D21</th>\n",
       "      <th>s__Acidaminococcus_sp_HPA0509</th>\n",
       "      <th>...</th>\n",
       "      <th>s__Vibrio_furnissii</th>\n",
       "      <th>s__Vibrio_kanaloae</th>\n",
       "      <th>s__Weissella_cibaria</th>\n",
       "      <th>s__Weissella_confusa</th>\n",
       "      <th>s__Weissella_halotolerans</th>\n",
       "      <th>s__Weissella_koreensis</th>\n",
       "      <th>s__Weissella_paramesenteroides</th>\n",
       "      <th>s__Weissella_unclassified</th>\n",
       "      <th>s__Wohlfahrtiimonas_chitiniclastica</th>\n",
       "      <th>s__Yersinia_enterocolitica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Overweight_3579</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3580</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00653</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3581</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02384</td>\n",
       "      <td>0.10129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3582</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3583</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3812</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3813</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3814</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3815</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Overweight_3816</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01592</td>\n",
       "      <td>0.04262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>238 rows Ã— 903 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 s__Abiotrophia_defectiva  s__Acetobacter_unclassified  \\\n",
       "Overweight_3579                       0.0                          0.0   \n",
       "Overweight_3580                       0.0                          0.0   \n",
       "Overweight_3581                       0.0                          0.0   \n",
       "Overweight_3582                       0.0                          0.0   \n",
       "Overweight_3583                       0.0                          0.0   \n",
       "...                                   ...                          ...   \n",
       "Overweight_3812                       0.0                          0.0   \n",
       "Overweight_3813                       0.0                          0.0   \n",
       "Overweight_3814                       0.0                          0.0   \n",
       "Overweight_3815                       0.0                          0.0   \n",
       "Overweight_3816                       0.0                          0.0   \n",
       "\n",
       "                 s__Achromobacter_piechaudii  s__Achromobacter_unclassified  \\\n",
       "Overweight_3579                          0.0                            0.0   \n",
       "Overweight_3580                          0.0                            0.0   \n",
       "Overweight_3581                          0.0                            0.0   \n",
       "Overweight_3582                          0.0                            0.0   \n",
       "Overweight_3583                          0.0                            0.0   \n",
       "...                                      ...                            ...   \n",
       "Overweight_3812                          0.0                            0.0   \n",
       "Overweight_3813                          0.0                            0.0   \n",
       "Overweight_3814                          0.0                            0.0   \n",
       "Overweight_3815                          0.0                            0.0   \n",
       "Overweight_3816                          0.0                            0.0   \n",
       "\n",
       "                 s__Achromobacter_xylosoxidans  s__Acidaminococcus_fermentans  \\\n",
       "Overweight_3579                            0.0                            0.0   \n",
       "Overweight_3580                            0.0                            0.0   \n",
       "Overweight_3581                            0.0                            0.0   \n",
       "Overweight_3582                            0.0                            0.0   \n",
       "Overweight_3583                            0.0                            0.0   \n",
       "...                                        ...                            ...   \n",
       "Overweight_3812                            0.0                            0.0   \n",
       "Overweight_3813                            0.0                            0.0   \n",
       "Overweight_3814                            0.0                            0.0   \n",
       "Overweight_3815                            0.0                            0.0   \n",
       "Overweight_3816                            0.0                            0.0   \n",
       "\n",
       "                 s__Acidaminococcus_intestini  s__Acidaminococcus_sp_BV3L6  \\\n",
       "Overweight_3579                       0.00000                          0.0   \n",
       "Overweight_3580                       0.00653                          0.0   \n",
       "Overweight_3581                       0.00000                          0.0   \n",
       "Overweight_3582                       0.00000                          0.0   \n",
       "Overweight_3583                       0.00000                          0.0   \n",
       "...                                       ...                          ...   \n",
       "Overweight_3812                       0.00000                          0.0   \n",
       "Overweight_3813                       0.00000                          0.0   \n",
       "Overweight_3814                       0.00000                          0.0   \n",
       "Overweight_3815                       0.00000                          0.0   \n",
       "Overweight_3816                       0.00000                          0.0   \n",
       "\n",
       "                 s__Acidaminococcus_sp_D21  s__Acidaminococcus_sp_HPA0509  \\\n",
       "Overweight_3579                        0.0                            0.0   \n",
       "Overweight_3580                        0.0                            0.0   \n",
       "Overweight_3581                        0.0                            0.0   \n",
       "Overweight_3582                        0.0                            0.0   \n",
       "Overweight_3583                        0.0                            0.0   \n",
       "...                                    ...                            ...   \n",
       "Overweight_3812                        0.0                            0.0   \n",
       "Overweight_3813                        0.0                            0.0   \n",
       "Overweight_3814                        0.0                            0.0   \n",
       "Overweight_3815                        0.0                            0.0   \n",
       "Overweight_3816                        0.0                            0.0   \n",
       "\n",
       "                 ...  s__Vibrio_furnissii  s__Vibrio_kanaloae  \\\n",
       "Overweight_3579  ...                  0.0                 0.0   \n",
       "Overweight_3580  ...                  0.0                 0.0   \n",
       "Overweight_3581  ...                  0.0                 0.0   \n",
       "Overweight_3582  ...                  0.0                 0.0   \n",
       "Overweight_3583  ...                  0.0                 0.0   \n",
       "...              ...                  ...                 ...   \n",
       "Overweight_3812  ...                  0.0                 0.0   \n",
       "Overweight_3813  ...                  0.0                 0.0   \n",
       "Overweight_3814  ...                  0.0                 0.0   \n",
       "Overweight_3815  ...                  0.0                 0.0   \n",
       "Overweight_3816  ...                  0.0                 0.0   \n",
       "\n",
       "                 s__Weissella_cibaria  s__Weissella_confusa  \\\n",
       "Overweight_3579               0.00000               0.00000   \n",
       "Overweight_3580               0.00000               0.00000   \n",
       "Overweight_3581               0.02384               0.10129   \n",
       "Overweight_3582               0.00000               0.00000   \n",
       "Overweight_3583               0.00000               0.00000   \n",
       "...                               ...                   ...   \n",
       "Overweight_3812               0.00000               0.00000   \n",
       "Overweight_3813               0.00000               0.00000   \n",
       "Overweight_3814               0.00000               0.00000   \n",
       "Overweight_3815               0.00000               0.00000   \n",
       "Overweight_3816               0.01592               0.04262   \n",
       "\n",
       "                 s__Weissella_halotolerans  s__Weissella_koreensis  \\\n",
       "Overweight_3579                        0.0                     0.0   \n",
       "Overweight_3580                        0.0                     0.0   \n",
       "Overweight_3581                        0.0                     0.0   \n",
       "Overweight_3582                        0.0                     0.0   \n",
       "Overweight_3583                        0.0                     0.0   \n",
       "...                                    ...                     ...   \n",
       "Overweight_3812                        0.0                     0.0   \n",
       "Overweight_3813                        0.0                     0.0   \n",
       "Overweight_3814                        0.0                     0.0   \n",
       "Overweight_3815                        0.0                     0.0   \n",
       "Overweight_3816                        0.0                     0.0   \n",
       "\n",
       "                 s__Weissella_paramesenteroides  s__Weissella_unclassified  \\\n",
       "Overweight_3579                             0.0                    0.00000   \n",
       "Overweight_3580                             0.0                    0.00000   \n",
       "Overweight_3581                             0.0                    0.00000   \n",
       "Overweight_3582                             0.0                    0.00000   \n",
       "Overweight_3583                             0.0                    0.00000   \n",
       "...                                         ...                        ...   \n",
       "Overweight_3812                             0.0                    0.00000   \n",
       "Overweight_3813                             0.0                    0.00000   \n",
       "Overweight_3814                             0.0                    0.00000   \n",
       "Overweight_3815                             0.0                    0.00000   \n",
       "Overweight_3816                             0.0                    0.01816   \n",
       "\n",
       "                 s__Wohlfahrtiimonas_chitiniclastica  \\\n",
       "Overweight_3579                                  0.0   \n",
       "Overweight_3580                                  0.0   \n",
       "Overweight_3581                                  0.0   \n",
       "Overweight_3582                                  0.0   \n",
       "Overweight_3583                                  0.0   \n",
       "...                                              ...   \n",
       "Overweight_3812                                  0.0   \n",
       "Overweight_3813                                  0.0   \n",
       "Overweight_3814                                  0.0   \n",
       "Overweight_3815                                  0.0   \n",
       "Overweight_3816                                  0.0   \n",
       "\n",
       "                 s__Yersinia_enterocolitica  \n",
       "Overweight_3579                         0.0  \n",
       "Overweight_3580                         0.0  \n",
       "Overweight_3581                         0.0  \n",
       "Overweight_3582                         0.0  \n",
       "Overweight_3583                         0.0  \n",
       "...                                     ...  \n",
       "Overweight_3812                         0.0  \n",
       "Overweight_3813                         0.0  \n",
       "Overweight_3814                         0.0  \n",
       "Overweight_3815                         0.0  \n",
       "Overweight_3816                         0.0  \n",
       "\n",
       "[238 rows x 903 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.iloc[:,2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biodb/.local/lib/python3.6/site-packages/seaborn/regression.py:574: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "embedding_ = data2umap(output.iloc[:,3:], n_pca=30)\n",
    "gplot(embedding_, np.array(train_p.iloc[:,:]['batch']), np.array(output.iloc[:,:]['Type']), 'iMAP2-OW-GHMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/biodb/.local/lib/python3.6/site-packages/seaborn/regression.py:574: UserWarning: The `size` parameter has been renamed to `height`; please update your code.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "embedding_ = data2umap(train_p.iloc[:2635,2:], n_pca=30)\n",
    "gplot(embedding_, np.array(train_p.iloc[:,:]['batch']), np.array(output.iloc[:,:]['Type']), 'OW-GHMI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
